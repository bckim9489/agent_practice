{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "VNgdPBbNxdKh",
        "rHIPs8XTcfpR",
        "2znB-998RCON",
        "EnxBn7oKyXnp",
        "_jzOCYQwy4wm",
        "VGAWF2-HzAbP",
        "O2rgyWFkzSU7",
        "PenpfQEozrHO",
        "AcuUKrsWz5s0",
        "NiSZry960Mh3",
        "I1aqzgNKnmsM",
        "JQfU0ZwCnz_o",
        "TT35tciCpIRs"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOxo9DulYHZDwty9RXTRD8f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bckim9489/agent_practice/blob/main/agent_pattern.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Common Setup\n",
        "\n",
        "참고 : 아래 Secret으로 Key 등록해서 실습함\n",
        "1.   LLM API Key (GPT, claude 등) : OPENAI-KEY 로 등록했음\n",
        "2.   Tavily Serach API Key (https://app.tavily.com/home) : TAVIL-KEY 로 등록했음\n",
        "\n"
      ],
      "metadata": {
        "id": "ERCG8LefaX33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install -U \"requests==2.32.5\" \"pydantic==2.12.3\" \"httpx==0.28.1\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yweuvVZwv7C",
        "outputId": "c18ca651-8228-4ec1-a459-da41b009fd34"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "xaaHPNB-JuRU"
      },
      "outputs": [],
      "source": [
        "!pip -q install -U langgraph langchain-openai langchain-community wikipedia numexpr tavily-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "# LLM API Key\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI-KEY\")\n",
        "\n",
        "# Tools\n",
        "# Search API Key\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get(\"TAVILY-KEY\")\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n"
      ],
      "metadata": {
        "id": "0of3EhdAK8Wt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ㄴ 0. TEST"
      ],
      "metadata": {
        "id": "VNgdPBbNxdKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, httpx, pydantic\n",
        "import langchain_community, langgraph\n",
        "from langgraph.graph import StateGraph\n",
        "\n",
        "print(\"requests:\", requests.__version__)\n",
        "print(\"httpx:\", httpx.__version__)\n",
        "print(\"pydantic:\", pydantic.__version__)\n",
        "print(\"langchain-community:\", langchain_community.__version__)\n",
        "print(\"LangGraph import OK\")\n",
        "print(\"StateGraph:\", StateGraph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBEwa4scxj9w",
        "outputId": "cce713e6-20e2-4929-f1ae-078800aac9d2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "requests: 2.32.5\n",
            "httpx: 0.28.1\n",
            "pydantic: 2.12.3\n",
            "langchain-community: 0.4.1\n",
            "LangGraph import OK\n",
            "StateGraph: <class 'langgraph.graph.state.StateGraph'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ㄴ 1. Tools"
      ],
      "metadata": {
        "id": "rHIPs8XTcfpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "from langchain_community.tools import WikipediaQueryRun\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "from langchain_core.tools import tool\n",
        "import numexpr\n",
        "\n",
        "# Wikipedia tool\n",
        "wiki = WikipediaQueryRun(\n",
        "    api_wrapper=WikipediaAPIWrapper(top_k_results=3, doc_content_chars_max=2000)\n",
        ")\n",
        "\n",
        "# 기존 wiki wrapper 재사용\n",
        "wiki_lookup_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=4000)\n",
        "\n",
        "@tool\n",
        "def docstore_lookup(title: str) -> str:\n",
        "    \"\"\"\n",
        "    Lookup a specific document by title from the docstore (Wikipedia).\n",
        "    Input should be a precise title or entity name.\n",
        "    \"\"\"\n",
        "    return wiki_lookup_wrapper.run(title)\n",
        "\n",
        "# Tavily Search tool\n",
        "search_tool = TavilySearchResults(max_results=5)\n",
        "\n",
        "# Calculator tool (llm-math 대체)\n",
        "@tool\n",
        "def calculator(expression: str) -> str:\n",
        "    \"\"\"\n",
        "    Evaluate a mathematical expression.\n",
        "    Input must be a valid expression like '345*872' or '12/4+9'.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return str(numexpr.evaluate(expression))\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "\n",
        "tools = [wiki, calculator, search_tool, docstore_lookup]\n",
        "print(\"=== Tools ===\")\n",
        "for t in tools:\n",
        "    print(\"-\", t.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyVc3d97jxUh",
        "outputId": "c5bdb75e-7193-4980-9fff-d081bb1948b0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Tools ===\n",
            "- wikipedia\n",
            "- calculator\n",
            "- tavily_search_results_json\n",
            "- docstore_lookup\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1012767205.py:25: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the `langchain-tavily package and should be used instead. To use it run `pip install -U `langchain-tavily` and import as `from `langchain_tavily import TavilySearch``.\n",
            "  search_tool = TavilySearchResults(max_results=5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Gen 1] Prompt-driven Tool-Using Agents(ReAct-based Agents)\n",
        "> **LLM**이 매 순간 다음 행동을 **즉흥 결정**\n",
        "*   **LLM-Driven Agents**\n",
        "*   LLM이 생각(Reasoning) 하고\n",
        "*   외부 도구를 행동(Act) 으로 호출하며\n",
        "*   그 결과를 다시 보고 추론을 이어가는 \"Tool-using LLM Loop\"\n",
        "*   2022 ~ 2024\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2znB-998RCON"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ㄴ 1. Zero-Shot ReAct\n",
        "*   기억 없음(Stateless)\n",
        "*   **LLM + Tools**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ehIezWEaajKR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 1.1 Description"
      ],
      "metadata": {
        "id": "YAnx3hYxpLVg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 1.1.1 Workflow\n"
      ],
      "metadata": {
        "id": "hYUi-RFIpe9p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```javascript\n",
        "Client\n",
        "  ↓\n",
        "User Question 전송\n",
        "  ↓\n",
        "API / Backend (Agent Endpoint)\n",
        "  ↓\n",
        "LangGraph Runtime 시작\n",
        "  ↓\n",
        "LLM: 질문 해석 (Thought / Reasoning)\n",
        "  ↓\n",
        "Tool 필요 여부 판단\n",
        "  ├─ 필요 없음 → 바로 답 생성\n",
        "  └─ 필요 있음 → Tool 선택 (Action)\n",
        "                      ↓\n",
        "                Tool 실행 (Python / API / DB 등)\n",
        "                      ↓\n",
        "                결과 반환 (Observation)\n",
        "                      ↓\n",
        "LLM이 결과 반영하여 다시 Reasoning\n",
        "  ↓\n",
        "(필요 시 Thought → Action → Observation 반복)\n",
        "  ↓\n",
        "Final Answer 생성\n",
        "  ↓\n",
        "API가 응답 반환\n",
        "  ↓\n",
        "Client가 사용자에게 표시\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "9uI9XCOlqjvb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 1.1.2 Inner ReAct Loop"
      ],
      "metadata": {
        "id": "lFACiazxqBeK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "``` javascript\n",
        "while 문제 해결 전:\n",
        "    Thought      → 어떻게 풀지 스스로 판단\n",
        "    Action       → 사용할 Tool 선택\n",
        "    Observation  → Tool 실행 결과 받기\n",
        "    Thought      → 결과 보고 다음 행동 결정\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "gQYu7VPTqTip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 1.2 Code"
      ],
      "metadata": {
        "id": "rDXdgSpop1qb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "agent = create_react_agent(llm, tools)"
      ],
      "metadata": {
        "id": "4mcT3ELCjyDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = \"\"\"위키피디아에서 찾기 좋은 '검색어(제목형 키워드)'를 3개 만들어서,\n",
        "그 키워드로 Wikipedia tool을 사용해 검색하고 근거를 요약해줘.\n",
        "주제: Pinus densiflora 옮겨심기(이식) 적기\"\"\""
      ],
      "metadata": {
        "id": "vSI9contrFxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = agent.invoke({\"messages\": [(\"user\", q)]})\n",
        "\n",
        "print(result[\"messages\"][-1].content)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "tHHfmPKBrDtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 1.3 Verbose"
      ],
      "metadata": {
        "id": "7scQ69xTbS3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import AIMessage, ToolMessage\n",
        "\n",
        "for step in agent.stream(\n",
        "    {\"messages\": [(\"user\", q)]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    msg = step[\"messages\"][-1]\n",
        "\n",
        "    # LLM이 생각/결정한 내용\n",
        "    if isinstance(msg, AIMessage):\n",
        "        print(\"\\n AI MESSAGE\")\n",
        "        print(msg.content)\n",
        "\n",
        "        if getattr(msg, \"tool_calls\", None):\n",
        "            print(\" TOOL CALL:\", msg.tool_calls)\n",
        "\n",
        "    # Tool 실행 결과\n",
        "    elif isinstance(msg, ToolMessage):\n",
        "        print(\"\\n TOOL RESULT\")\n",
        "        print(\"tool:\", msg.name)\n",
        "        print(msg.content[:1000])  # 너무 길면 앞부분만\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mWt9u_sNjzzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BrN_rPDn1ohp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ㄴ 2. Conversational ReAct\n",
        "*   메모리 사용\n",
        "*   **LLM + Tools + Checkpointer**\n",
        "\n"
      ],
      "metadata": {
        "id": "kP16oCAwawq2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 2.1 Description"
      ],
      "metadata": {
        "id": "QtEy1_mMrxoX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 2.1.1 Workflow"
      ],
      "metadata": {
        "id": "43pV-jAmsAZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```javascript\n",
        "Client\n",
        "  ↓\n",
        "User Question 전송\n",
        "  ↓\n",
        "API / Backend (Agent Endpoint)\n",
        "  ↓\n",
        "LangGraph Runtime 시작\n",
        "  ↓\n",
        "이전 대화 기록(Memory / State) 로드\n",
        "  ↓\n",
        "LLM: 현재 질문 + 대화 히스토리 함께 해석\n",
        "  ↓\n",
        "사용자의 의도 파악 (맥락 기반 Reasoning)\n",
        "  ↓\n",
        "Tool 필요 여부 판단\n",
        "  ├─ 필요 없음 → 바로 답 생성\n",
        "  └─ 필요 있음 → Tool 선택 (Action)\n",
        "                      ↓\n",
        "                Tool 실행 (Python / API / DB 등)\n",
        "                      ↓\n",
        "                결과 반환 (Observation)\n",
        "                      ↓\n",
        "LLM이 결과 + 이전 대화 맥락을 반영하여 다시 Reasoning\n",
        "  ↓\n",
        "(필요 시 Thought → Action → Observation 반복)\n",
        "  ↓\n",
        "Final Answer 생성\n",
        "  ↓\n",
        "대화 Memory(State)에 이번 메시지 저장\n",
        "  ↓\n",
        "API가 응답 반환\n",
        "  ↓\n",
        "Client가 사용자에게 표시\n",
        "```"
      ],
      "metadata": {
        "id": "0E4iTxHisGtf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 2.1.2 Inner ReAct Loop"
      ],
      "metadata": {
        "id": "sksFSADgsLM3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```javascript\n",
        "while 문제 해결 전:\n",
        "    Load Memory        → 이전 대화 불러오기\n",
        "    Thought            → 맥락 기반으로 판단\n",
        "    Action             → Tool 필요하면 실행\n",
        "    Observation        → Tool 결과 받기\n",
        "    Update Memory      → 새 정보 저장\n",
        "```"
      ],
      "metadata": {
        "id": "uvgeHLPnsOn2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 2.2 Code"
      ],
      "metadata": {
        "id": "BZJtKmFur3ly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "\n",
        "checkpointer = InMemorySaver()\n",
        "agent = create_react_agent(llm, tools, checkpointer=checkpointer)"
      ],
      "metadata": {
        "id": "_5j7GyaUZjqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"chat-001\"}}\n",
        "q1 = \"내 출생년도는 1994년이야. 지금은 계산하지 말고 이 정보만 기억해.\"\n",
        "q2 = \"그럼 내가 2026년에 몇 살인지 계산기를 꼭 사용해서 나이를 계산해서 알려줘\"\n",
        "q3 = \"올해는 무슨 해이며 나는 무슨 띠인지 알려줘\""
      ],
      "metadata": {
        "id": "gMf3OMaGZ7ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = agent.invoke({\"messages\": [(\"user\", q1)]}, config=config)\n",
        "print(result[\"messages\"][-1].content)\n",
        "result = agent.invoke({\"messages\": [(\"user\", q2)]}, config=config)\n",
        "print(result[\"messages\"][-1].content)\n",
        "result = agent.invoke({\"messages\": [(\"user\", q3)]}, config=config)\n",
        "print(result[\"messages\"][-1].content)\n"
      ],
      "metadata": {
        "id": "EUUVKU_wZpaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 2.3 Verbose"
      ],
      "metadata": {
        "id": "fVi1sXZ-bgqf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 2.3.1 Test Setup"
      ],
      "metadata": {
        "id": "zA7HHzH8kuhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import AIMessage, ToolMessage\n",
        "import time\n",
        "from openai import RateLimitError\n",
        "\n",
        "from langchain_core.messages import AIMessage, ToolMessage\n",
        "\n",
        "def stream_with_retry(agent, payload, config, stream_mode=\"values\", max_retries=6):\n",
        "    \"\"\"\n",
        "    agent.stream(...) 를 RateLimitError(429) 발생 시 backoff 재시도.\n",
        "    \"\"\"\n",
        "    attempt = 0\n",
        "    while True:\n",
        "        try:\n",
        "            for step in agent.stream(payload, config=config, stream_mode=stream_mode):\n",
        "                yield step\n",
        "            return  # 정상 종료\n",
        "        except RateLimitError as e:\n",
        "            attempt += 1\n",
        "            if attempt > max_retries:\n",
        "                raise\n",
        "\n",
        "            # 간단 backoff (점점 더 기다림)\n",
        "            wait = min(20, 1.5 * attempt)\n",
        "            print(f\"\\n RateLimit(429). retry in {wait:.1f}s ...\")\n",
        "            time.sleep(wait)\n",
        "\n",
        "\n",
        "\n",
        "def run_verbose(question: str, label: str, thread_id: str):\n",
        "    print(\"\\n\" + \"=\"*20 + f\" {label} (thread_id={thread_id}) \" + \"=\"*20)\n",
        "    print(\"USER:\", question)\n",
        "\n",
        "    cfg = {\"configurable\": {\"thread_id\": thread_id}}\n",
        "\n",
        "    payload = {\"messages\": [(\"user\", question)]}\n",
        "\n",
        "    last_ai = None\n",
        "    for step in stream_with_retry(agent, payload, cfg, stream_mode=\"values\"):\n",
        "        msg = step[\"messages\"][-1]\n",
        "\n",
        "        if isinstance(msg, AIMessage):\n",
        "            last_ai = msg\n",
        "            if msg.content:\n",
        "                print(\"\\nAI:\", msg.content)\n",
        "            if getattr(msg, \"tool_calls\", None):\n",
        "                print(\"tool_calls:\", msg.tool_calls)\n",
        "\n",
        "        elif isinstance(msg, ToolMessage):\n",
        "            print(\"\\nTOOL RESULT:\", msg.name)\n",
        "            print(msg.content[:800])\n",
        "\n",
        "    return last_ai.content if last_ai else None\n",
        "\n",
        "#메모리 사용하는지 A/B 테스트\n",
        "def ab_test(q1: str, q2: str, q3:str, thread_a: str=\"mem-A\", thread_b: str=\"mem-B\", thread_c: str=\"mem-C\"):\n",
        "    print(\"\\n\\n\" + \"#\"*10 + \" A/B MEMORY TEST START \" + \"#\"*10)\n",
        "\n",
        "    # A: q1 using thread_id a\n",
        "    run_verbose(q1, \"A-1: seed memory (q1)\", thread_a)\n",
        "\n",
        "\n",
        "    # B: q2 using thread_id b\n",
        "    run_verbose(q2, \"B-1: q2 only (no memory)\", thread_b)\n",
        "\n",
        "\n",
        "    # B: q3 using thread_id c\n",
        "    run_verbose(q3, \"C-1: q3 only (no memory)\", thread_c)\n",
        "\n",
        "    print(\"\\n\" + \"#\"*10 + \" A/B MEMORY TEST END \" + \"#\"*10)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "2LB9H_IbaSK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 2.3.2 Test A (같은 thread_id)\n",
        "\n",
        "*   Q1을 thread_id A 에 저장\n",
        "*   Q2를 thread_id A 에 질의\n",
        "----------------------------\n",
        "| Q2에서 메모리에 저장한 Q1을 활용하여 답변할 것으로 예상"
      ],
      "metadata": {
        "id": "PN7owphAlH3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 같은 thread_id\n",
        "run_verbose(q1, \"Q1\", \"chat-001\")\n",
        "run_verbose(q2, \"Q2\", \"chat-001\")\n",
        "run_verbose(q3, \"Q3\", \"chat-001\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "nwQbCVIOlA3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 2.3.3 TEST B (다른 thread_id)\n",
        "\n",
        "*   Q1을 thread_id A 에 저장\n",
        "*   Q2를 thread_id B에 질의\n",
        "----------------------------\n",
        "| Q2에서 질의 에 대한 정보 요구 예상\n",
        "\n"
      ],
      "metadata": {
        "id": "y1eAeR0BlLcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ab_test(q1, q2, q3, thread_a=\"chat-003\", thread_b=\"chat-004\", thread_c=\"chat-005\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "0Qi1B1S2lM3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ㄴ 3. Search-augmented ReAct (Self-ask with search)\n",
        "\n",
        "*   질문 분해 중심\n",
        "*   **RAG와 매우 유사**\n",
        "*   사실상 Self-Ask = 초기 형태의 RAG\n",
        "\n"
      ],
      "metadata": {
        "id": "alqHd1KutqEv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 3.1 Description"
      ],
      "metadata": {
        "id": "ZsEO8BqCxETT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 3.1.1. Workflow"
      ],
      "metadata": {
        "id": "V7rLljfvxLfh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```javascript\n",
        "Client\n",
        "  ↓\n",
        "User Question 전송\n",
        "  ↓\n",
        "API / Backend (Agent Endpoint)\n",
        "  ↓\n",
        "LangGraph / Agent Runtime 시작\n",
        "  ↓\n",
        "LLM이 질문을 \"하위 질문(Sub-questions)\"으로 분해\n",
        "  ↓\n",
        "각 하위 질문을 Search Tool로 순차 조회\n",
        "  ↓\n",
        "검색 결과(Observation)를 모아 중간 결론 생성\n",
        "  ↓\n",
        "필요하면 추가 하위 질문 생성 → 다시 Search\n",
        "  ↓\n",
        "모든 정보가 충분해지면 최종 답 생성\n",
        "  ↓\n",
        "API가 응답 반환\n",
        "  ↓\n",
        "Client가 사용자에게 표시\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "fy4VuWnJxPWb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 3.1.2 Inner ReAct Loop"
      ],
      "metadata": {
        "id": "Bj2GTjr4xTCv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```javascript\n",
        "while 답을 만들 정보가 부족하면:\n",
        "    Follow-up Question 생성\n",
        "    Search Tool 실행\n",
        "    Observation 수집\n",
        "    현재까지의 사실 정리\n",
        "```"
      ],
      "metadata": {
        "id": "EoMIb-d0xYXs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 3.2 Code"
      ],
      "metadata": {
        "id": "vuRDO56bxdTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage\n",
        "\n",
        "# Self-Ask의 핵심 포맷을 강제\n",
        "SELF_ASK_POLICY = SystemMessage(content=\"\"\"\n",
        "You are a Self-Ask-with-Search agent.\n",
        "\n",
        "Hard rules:\n",
        "- For EACH follow-up question, you MUST call the tavily_search_results_json tool.\n",
        "- After the tool returns, you MUST write an Intermediate answer that uses the tool result.\n",
        "- Intermediate answer must include 2-3 bullet points and mention the source titles (from tool results).\n",
        "- Do NOT write placeholders like \"...\". If info is missing, do another search.\n",
        "\n",
        "Output format (exact):\n",
        "Follow-up 1: ...\n",
        "Intermediate answer 1:\n",
        "- ...\n",
        "- ...\n",
        "Sources: <title1>, <title2>\n",
        "\n",
        "Follow-up 2: ...\n",
        "Intermediate answer 2:\n",
        "- ...\n",
        "- ...\n",
        "Sources: ...\n",
        "\n",
        "Final answer: ...\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "id": "aBV7rR953T53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "agent = create_react_agent(llm, tools)"
      ],
      "metadata": {
        "id": "-iImBDY1xhqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = \"\"\"AI Agent를 3문장으로 설명해줘.\n",
        "단, 2025~2026년 기준으로 최신 경향을 반영하기 위해 반드시 tavily_search_results_json을 최소 2번 사용하고,\n",
        "각 검색 결과를 근거로 Intermediate answer를 작성한 뒤 Final answer를 써.\"\"\""
      ],
      "metadata": {
        "id": "aSD-JJbi19tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"self-ask-01\"}}\n",
        "\n",
        "result = agent.invoke({\"messages\": [SELF_ASK_POLICY, (\"user\", q)]},config=config)\n",
        "\n",
        "print(result[\"messages\"][-1].content)"
      ],
      "metadata": {
        "id": "9JKLGdqQ11pJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 3.3. Verbose"
      ],
      "metadata": {
        "id": "LrTWqWT0xjtq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import AIMessage, ToolMessage\n",
        "\n",
        "def run_self_ask_verbose(question: str, thread_id=\"self-ask-03\", tool_preview=600):\n",
        "    cfg = {\"configurable\": {\"thread_id\": thread_id}}\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"USER:\", question)\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    for step in agent.stream(\n",
        "        {\"messages\": [SELF_ASK_POLICY, (\"user\", question)]},\n",
        "        config=cfg,\n",
        "        stream_mode=\"values\",\n",
        "    ):\n",
        "        msg = step[\"messages\"][-1]\n",
        "\n",
        "        # 1) 모델이 말한 텍스트(중간 출력 포함)\n",
        "        if isinstance(msg, AIMessage):\n",
        "            if msg.content:  # content가 있는 경우만 출력\n",
        "                print(\"\\n AI MESSAGE:\\n\", msg.content)\n",
        "\n",
        "            # 2) 도구 호출 로그\n",
        "            if getattr(msg, \"tool_calls\", None):\n",
        "                print(\"\\n TOOL CALLS:\")\n",
        "                for tc in msg.tool_calls:\n",
        "                    print(\" -\", tc)\n",
        "\n",
        "        # 3) 도구 결과\n",
        "        elif isinstance(msg, ToolMessage):\n",
        "            print(\"\\n TOOL RESULT:\", msg.name)\n",
        "            print(msg.content[:tool_preview])\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"END\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "run_self_ask_verbose(q)\n"
      ],
      "metadata": {
        "id": "XMEImNybxuzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ㄴ 4. ReAct docstore\n",
        "\n",
        "*   LLM이 문서 저장소를 스스로 탐색\n",
        "*   필요한 문서를 조회(Lookup)하여 근거 기반 답변을 생성\n",
        "\n"
      ],
      "metadata": {
        "id": "BV3CJLc87yf1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 4.1 Description"
      ],
      "metadata": {
        "id": "InnjMGqM-anr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 4.1.1 Workflow"
      ],
      "metadata": {
        "id": "6YZ6Asa8-gQ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```javascript\n",
        "Client\n",
        "  ↓\n",
        "User Question 전송\n",
        "  ↓\n",
        "API / Backend (Agent Endpoint)\n",
        "  ↓\n",
        "LangGraph Runtime 시작\n",
        "  ↓\n",
        "LLM: 질문 해석 (문서 탐색 필요 판단)\n",
        "  ↓\n",
        "Docstore Search Tool 호출 (Search Action)\n",
        "  ↓\n",
        "관련 문서 후보 목록 반환 (Observation)\n",
        "  ↓\n",
        "LLM: 어떤 문서를 읽을지 Reasoning\n",
        "  ↓\n",
        "Docstore Lookup Tool 호출 (Lookup Action)\n",
        "  ↓\n",
        "선택된 문서 실제 내용 반환 (Observation)\n",
        "  ↓\n",
        "LLM이 문서 내용을 기반으로 재해석 / 근거 정리\n",
        "  ↓\n",
        "(필요 시 Search → Lookup 반복)\n",
        "  ↓\n",
        "충분한 근거 확보 후 Final Answer 생성\n",
        "  ↓\n",
        "API가 응답 반환\n",
        "  ↓\n",
        "Client가 사용자에게 표시\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "DCYLWB1f-mDf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 4.1.2 Inner ReAct Loop"
      ],
      "metadata": {
        "id": "irEIUmY5-p7q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```javascript\n",
        "while (답변에 필요한 근거가 충분하지 않다):\n",
        "    Thought: 질문을 해결하려면 어떤 문서를 찾아야 하는가?\n",
        "    Action: Search(query)\n",
        "    Observation: 관련 문서 후보 목록 반환\n",
        "    Thought: 어떤 문서를 읽어야 하는가?\n",
        "    Action: Lookup(document_id)\n",
        "    Observation: 문서 내용 확보\n",
        "    Thought:이 정보로 답변 가능한가?\n",
        "            ├─ NO → 다른 문서 다시 Search\n",
        "            └─ YES → 반복 종료\n",
        "```"
      ],
      "metadata": {
        "id": "moO_SZRR-ubk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 4.2 Code"
      ],
      "metadata": {
        "id": "Pjc24Na8-yza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "agent = create_react_agent(llm, tools)"
      ],
      "metadata": {
        "id": "yUNy0ToZ-o0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = \"\"\"\n",
        "규칙:\n",
        "- wikipedia 도구를 1회 호출해서 후보 제목을 찾는다.\n",
        "- 그 다음 docstore_lookup 도구를 반드시 1회 이상 호출한다.\n",
        "- docstore_lookup 결과를 근거로 최종 답변을 작성한다.\n",
        "\n",
        "질문: 밍크 선인장(Mammillaria)은 어떤 식물인지 설명해줘.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Scbnrykx-ecp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "config = {\"configurable\": {\"thread_id\": \"docstore-01\"}}\n",
        "result = agent.invoke({\"messages\": [(\"user\", q)]},config=config)\n",
        "\n",
        "print(result[\"messages\"][-1].content)\n"
      ],
      "metadata": {
        "id": "HHLW_HGiBPLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 4.3 Verbose"
      ],
      "metadata": {
        "id": "Lr3TMvzl-2Q-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import AIMessage, ToolMessage\n",
        "\n",
        "def run_docstore_verbose(question: str, thread_id=\"docstore-debug\"):\n",
        "    cfg = {\"configurable\": {\"thread_id\": thread_id}}\n",
        "\n",
        "    print(\"\\n================ USER ================\")\n",
        "    print(question)\n",
        "\n",
        "    for step in agent.stream(\n",
        "        {\"messages\": [(\"user\", question)]},\n",
        "        config=cfg,\n",
        "        stream_mode=\"values\",   # 상태 변화 전부 받기\n",
        "    ):\n",
        "        msg = step[\"messages\"][-1]\n",
        "\n",
        "        # LLM이 생각한 내용 (Thought / Action 결정)\n",
        "        if isinstance(msg, AIMessage):\n",
        "            if msg.content:\n",
        "                print(\"\\n AI THOUGHT:\")\n",
        "                print(msg.content)\n",
        "\n",
        "            if getattr(msg, \"tool_calls\", None):\n",
        "                print(\"\\n TOOL CALL:\")\n",
        "                print(msg.tool_calls)\n",
        "\n",
        "        # Tool 실행 결과 (Observation)\n",
        "        elif isinstance(msg, ToolMessage):\n",
        "            print(\"\\n TOOL RESULT:\", msg.name)\n",
        "            print(msg.content[:1000])  # 너무 길어서 제한\n",
        "\n",
        "    print(\"\\n================ END ================\\n\")\n",
        "\n",
        "run_docstore_verbose(q)\n"
      ],
      "metadata": {
        "id": "V5LEMXZFDYvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Gen 2] LLM Orchestrated Systems(Post-ReAct Agent Architectures)\n",
        "> Workflow Engine이 **순서를 결정**, LLM은 **필요할 때만 호출**\n",
        "*   **System-Driven Agents**\n",
        "*   계획 수립 / 의도 해석   ← LLM\n",
        "*   실행 흐름은 시스템이 통제 ← Runtime / Graph / Process\n",
        "*   Tool 실행은 강제된 구조로 수행\n",
        "*   상태(State)를 외부에서 관리\n",
        "*   2024 ~ 현재\n",
        "\n",
        "```javascript\n",
        "User → Orchestrator → Planner → Executor → Validator → State Update\n",
        "                        ↓\n",
        "                      LLM (as function)\n",
        "```\n"
      ],
      "metadata": {
        "id": "OfRLzAbpPzdu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ㄴ 1. Pure Plan-Then-Execute Core Pattern\n",
        "> Plan → **Freeze** Plan → **Execute** Deterministically\n",
        ">"
      ],
      "metadata": {
        "id": "rNEdkyFfV8N6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 1.1 Description"
      ],
      "metadata": {
        "id": "EYy3pdEssWBy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```javascript\n",
        "Planner LLM → Execution Graph 생성\n",
        "Execution Engine:\n",
        "    Step1\n",
        "    Step2\n",
        "    Step3\n",
        "```\n",
        "*    **Planner(LLM)** 는 계획(어떤 툴을 어떤 순서로 쓸지)를 JSON Plan으로만 만듬 (실행 금지)\n",
        "*    **Executor(시스템)** 가 계획을 결정론적으로 실행 (툴을 실제로 호출)\n",
        "*    **Writer(LLM)** 가 결과를 자연어로 정리 및 답변\n",
        "\n",
        "```javascript\n",
        "User Input\n",
        "   ↓\n",
        "Planner (LLM 1회)\n",
        "   ↓\n",
        "Executor (Deterministic Tool Calls)\n",
        "   ↓\n",
        "Writer (LLM 정리)\n",
        "   ↓\n",
        "End\n",
        "```"
      ],
      "metadata": {
        "id": "a_yJV58NolGk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 1.2 Code"
      ],
      "metadata": {
        "id": "mkD5lKiwuAPA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 1.2.1 Tool Registry"
      ],
      "metadata": {
        "id": "EnxBn7oKyXnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from typing import List, Literal, Dict, Any\n",
        "\n",
        "# 우리가 Plan에서 쓸 \"툴 alias\"\n",
        "TOOL_REGISTRY = {\n",
        "    \"wiki\": wiki,\n",
        "    \"search\": search_tool,\n",
        "    \"lookup\": docstore_lookup,\n",
        "    \"calc\": calculator,\n",
        "}\n",
        "\n",
        "ToolAlias = Literal[\"wiki\", \"search\", \"lookup\", \"calc\", \"final_answer\"]"
      ],
      "metadata": {
        "id": "DqZMdHYduEZN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 1.2.2 Contract (Plan Schema)"
      ],
      "metadata": {
        "id": "QbX58N3yysnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class Step(BaseModel):\n",
        "    tool: ToolAlias\n",
        "    input: str\n",
        "\n",
        "class Plan(BaseModel):\n",
        "    goal: str\n",
        "    steps: List[Step] = Field(min_items=1, max_items=6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nr9odFvtyoF5",
        "outputId": "910b0155-5875-4740-ce8a-7097a0684cdb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3491100315.py:9: PydanticDeprecatedSince20: `min_items` is deprecated and will be removed, use `min_length` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
            "  steps: List[Step] = Field(min_items=1, max_items=6)\n",
            "/tmp/ipython-input-3491100315.py:9: PydanticDeprecatedSince20: `max_items` is deprecated and will be removed, use `max_length` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
            "  steps: List[Step] = Field(min_items=1, max_items=6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 1.2.3 System Prompt"
      ],
      "metadata": {
        "id": "_jzOCYQwy4wm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ㄴ 1.2.3.1 Planner System Prompt"
      ],
      "metadata": {
        "id": "VGAWF2-HzAbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "\n",
        "PLANNER_SYS = SystemMessage(content=\n",
        "\"\"\"You are a Planner.\n",
        "Return ONLY valid JSON matching this schema:\n",
        "\n",
        "{\n",
        "  \"goal\": string,\n",
        "  \"steps\": [{\"tool\": \"wiki\"|\"search\"|\"lookup\"|\"calc\"|\"final_answer\", \"input\": string}, ...]\n",
        "}\n",
        "\n",
        "Rules:\n",
        "- Do NOT execute tools.\n",
        "- Prefer \"search\" for up-to-date web info when needed.\n",
        "- Use \"wiki\" for general grounding.\n",
        "- Use \"lookup\" only when you know the exact Wikipedia title/entity.\n",
        "- Use \"calc\" only for arithmetic.\n",
        "- Keep steps minimal (<=4 if possible).\n",
        "- The last step MUST be \"final_answer\".\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "ZHdypHYlzMqj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ㄴ 1.2.3.2 Writer System Prompt"
      ],
      "metadata": {
        "id": "O2rgyWFkzSU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "WRITER_SYS = SystemMessage(content=\n",
        "\"\"\"You are a Writer.\n",
        "\n",
        "You will receive:\n",
        "- user_question\n",
        "- plan (JSON)\n",
        "- tool_results (JSON)\n",
        "\n",
        "Rules:\n",
        "- Write the final answer in Korean only (한국어로만 작성).\n",
        "- Use tool_results as evidence. If you reference web search results, summarize them in Korean.\n",
        "- Keep it concise and structured (bullets ok).\n",
        "- If any tool output contains \"Error\" or \"ERROR\", explain briefly in Korean and propose a corrected plan.\n",
        "\n",
        "Return ONLY JSON:\n",
        "{\"final\": string}\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "id": "sw8H3LGvzX3q"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 1.2.4 Planner Function"
      ],
      "metadata": {
        "id": "PenpfQEozrHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re, json\n",
        "\n",
        "def extract_json(text: str) -> str:\n",
        "    \"\"\"LLM 응답에서 JSON만 뽑아낸다 (```json``` 코드블록/앞뒤 잡문 방어).\"\"\"\n",
        "    if text is None:\n",
        "        return \"\"\n",
        "    t = text.strip()\n",
        "\n",
        "    # 1) ```json ... ``` 블록 우선 추출\n",
        "    m = re.search(r\"```(?:json)?\\s*(\\{.*\\})\\s*```\", t, flags=re.DOTALL | re.IGNORECASE)\n",
        "    if m:\n",
        "        return m.group(1).strip()\n",
        "\n",
        "    # 2) 첫 { 부터 마지막 } 까지 잘라내기\n",
        "    start = t.find(\"{\")\n",
        "    end = t.rfind(\"}\")\n",
        "    if start != -1 and end != -1 and end > start:\n",
        "        return t[start:end+1].strip()\n",
        "\n",
        "    return t\n",
        "\n",
        "\n",
        "def make_plan(user_question: str) -> Plan:\n",
        "    resp = llm.invoke([PLANNER_SYS, HumanMessage(content=user_question)])\n",
        "    json_str = extract_json(resp.content)\n",
        "    data = json.loads(resp.content)\n",
        "    return Plan.model_validate(data)"
      ],
      "metadata": {
        "id": "t-nyfguEz0gM"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 1.2.5 Executor Function"
      ],
      "metadata": {
        "id": "AcuUKrsWz5s0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _invoke_tool(alias: str, tool_input: str) -> Any:\n",
        "    tool = TOOL_REGISTRY[alias]\n",
        "\n",
        "    # TavilySearchResults는 보통 {\"query\": \"...\"} 형태가 안정적\n",
        "    if alias == \"search\":\n",
        "        try:\n",
        "            return tool.invoke({\"query\": tool_input})\n",
        "        except Exception:\n",
        "            return tool.invoke(tool_input)\n",
        "\n",
        "    # 나머지는 보통 문자열 입력\n",
        "    try:\n",
        "        return tool.invoke(tool_input)\n",
        "    except Exception:\n",
        "        return tool.run(tool_input)\n",
        "\n",
        "def execute_plan(plan: Plan) -> List[Dict[str, Any]]:\n",
        "    results = []\n",
        "    for idx, step in enumerate(plan.steps):\n",
        "        if step.tool == \"final_answer\":\n",
        "            results.append({\n",
        "                \"step_index\": idx,\n",
        "                \"tool\": step.tool,\n",
        "                \"input\": step.input,\n",
        "                \"output\": \"(final step - no tool execution)\"\n",
        "            })\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            out = _invoke_tool(step.tool, step.input)\n",
        "        except Exception as e:\n",
        "            out = f\"ERROR: {type(e).__name__}: {e}\"\n",
        "\n",
        "        results.append({\n",
        "            \"step_index\": idx,\n",
        "            \"tool\": step.tool,\n",
        "            \"input\": step.input,\n",
        "            \"output\": out\n",
        "        })\n",
        "    return results"
      ],
      "metadata": {
        "id": "qfW-aA72z-gc"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 1.2.6 Writer Function"
      ],
      "metadata": {
        "id": "NiSZry960Mh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def write_final(user_question: str, plan: Plan, tool_results: List[Dict[str, Any]]) -> str:\n",
        "    payload = {\n",
        "        \"user_question\": user_question,\n",
        "        \"plan\": plan.model_dump(),\n",
        "        \"tool_results\": tool_results,\n",
        "    }\n",
        "    resp = llm.invoke([WRITER_SYS, HumanMessage(content=json.dumps(payload, ensure_ascii=False))])\n",
        "    data = json.loads(resp.content)\n",
        "    return data[\"final\"]"
      ],
      "metadata": {
        "id": "TtXMsUhw0UR5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 1.2.7 User Prompt"
      ],
      "metadata": {
        "id": "v0AP8eGEzgu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Plan-Then-Execute 패턴이 뭐고 ReAct랑 차이를 예시 포함해서 설명해줘. 최신 관점이면 search도 활용해.\""
      ],
      "metadata": {
        "id": "QMgx52ozzmva"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 1.2.8 Result"
      ],
      "metadata": {
        "id": "367WrFnS0e17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_plan_then_execute(question: str) -> str:\n",
        "    # 1) Plan 생성\n",
        "    plan = make_plan(question)\n",
        "\n",
        "    # 2) 계획 실행 (결정론적)\n",
        "    tool_results = execute_plan(plan)\n",
        "\n",
        "    # 3) 최종 답변 생성\n",
        "    final = write_final(question, plan, tool_results)\n",
        "\n",
        "    return final\n",
        "\n",
        "answer = run_plan_then_execute(question)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ymeFl4g0kos",
        "outputId": "fd25d0b5-0ebd-4b7c-9080-09404c5b8975"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plan-Then-Execute 패턴과 ReAct 패턴은 AI 에이전트의 작업 수행 방식에서 차이를 보입니다.\n",
            "\n",
            "- **Plan-Then-Execute 패턴**\n",
            "  - **설명**: 이 패턴은 작업을 시작하기 전에 전체 계획을 세우고, 그 계획에 따라 순차적으로 실행하는 방식입니다. 주로 복잡한 작업이나 여러 단계가 필요한 작업에 적합합니다.\n",
            "  - **예시**: 대량의 데이터를 분석하고 보고서를 생성하는 작업에서, 먼저 전체 분석 계획을 세운 후 각 단계별로 실행합니다.\n",
            "\n",
            "- **ReAct 패턴**\n",
            "  - **설명**: ReAct는 'Reasoning and Acting'의 약자로, 작업을 수행하면서 단계별로 사고하고 행동하는 방식입니다. 각 단계에서 결과를 보고 다음 행동을 결정합니다. 주로 단순하고 상호작용이 많은 작업에 적합합니다.\n",
            "  - **예시**: 데이터베이스에서 정보를 검색하고, 그 결과에 따라 추가적인 쿼리를 수행하는 작업에서, 각 쿼리 후 결과를 바탕으로 다음 쿼리를 결정합니다.\n",
            "\n",
            "- **차이점**\n",
            "  - **계획의 유무**: Plan-Then-Execute는 사전 계획을 강조하며, ReAct는 즉각적인 반응과 적응을 중시합니다.\n",
            "  - **적용 분야**: Plan-Then-Execute는 복잡하고 장기적인 작업에, ReAct는 단기적이고 즉각적인 피드백이 필요한 작업에 적합합니다.\n",
            "\n",
            "이 두 패턴은 각각의 장단점이 있으며, 작업의 성격에 따라 적절한 패턴을 선택하는 것이 중요합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 1.2.9 Debuging"
      ],
      "metadata": {
        "id": "j-BkqhIj2bC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def debug_make_plan(user_question: str):\n",
        "    resp = llm.invoke([PLANNER_SYS, HumanMessage(content=user_question)])\n",
        "    print(\"=== RAW PLANNER OUTPUT ===\")\n",
        "    print(repr(resp.content))\n",
        "    return resp.content\n",
        "\n",
        "def debug_write_final(user_question: str, plan, tool_results):\n",
        "    payload = {\n",
        "        \"user_question\": user_question,\n",
        "        \"plan\": plan.model_dump(),\n",
        "        \"tool_results\": tool_results,\n",
        "    }\n",
        "    resp = llm.invoke([WRITER_SYS, HumanMessage(content=json.dumps(payload, ensure_ascii=False))])\n",
        "    print(\"=== RAW WRITER OUTPUT ===\")\n",
        "    print(repr(resp.content))\n",
        "    return resp.content\n"
      ],
      "metadata": {
        "id": "J3s6h4Oi2gzx"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Plan-Then-Execute 패턴이 뭐고 ReAct랑 차이를 예시 포함해서 설명해줘. 최신 관점이면 search도 활용해.\"\n",
        "\n",
        "plan = make_plan(question)\n",
        "tool_results = execute_plan(plan)\n",
        "\n",
        "raw_writer = debug_write_final(question, plan, tool_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOBkCcT_20kE",
        "outputId": "1bcb33ea-e8f0-4060-cb87-5861841e2acc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== RAW WRITER OUTPUT ===\n",
            "'{\"final\": \"The Plan-Then-Execute pattern and the ReAct pattern are two distinct approaches used in AI and software development, particularly for managing tasks and processes.\\\\n\\\\n1. **Plan-Then-Execute Pattern**: This approach involves a clear separation between planning and execution phases. Initially, a comprehensive plan is developed, breaking down tasks into subtasks and creating a detailed execution strategy. Once the plan is set, the execution phase follows, where tasks are carried out in sequence. This pattern is well-suited for complex, multi-step tasks that require strategic planning and coordination, as it allows for a structured and predictable approach. An example could be a project management tool that first outlines all project phases before any work begins.\\\\n\\\\n2. **ReAct Pattern**: The ReAct (Reason-Act) pattern operates in a tight, iterative loop where the system continuously alternates between reasoning (thinking about the next step) and acting (performing an action). This pattern is highly adaptive and effective for dynamic tasks that require real-time decision-making. It is suitable for simpler tasks that can be addressed with immediate actions and feedback loops. An example is a chatbot that responds to user queries by reasoning about the best response and then delivering it, adjusting based on user feedback.\\\\n\\\\n**Differences**: The primary difference lies in their approach to task management. Plan-Then-Execute is strategic and structured, ideal for tasks with dependencies and long-term goals. In contrast, ReAct is tactical and flexible, excelling in environments where quick, iterative responses are needed. The choice between these patterns depends on the complexity and nature of the task at hand.\"}'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 1.3 Verbose"
      ],
      "metadata": {
        "id": "miRH6CEK5CyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_plan_then_execute_verbose(user_question: str, print_chars: int = 800):\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"USER QUESTION:\")\n",
        "    print(user_question)\n",
        "\n",
        "    # PLAN 단계\n",
        "    print(\"\\n\" + \"-\"*30 + \" PLANNING \" + \"-\"*30)\n",
        "\n",
        "    plan = make_plan(user_question)\n",
        "\n",
        "    print(\"GOAL:\", plan.goal)\n",
        "    print(\"\\nSTEPS:\")\n",
        "    for i, step in enumerate(plan.steps):\n",
        "        print(f\"  [{i}] tool={step.tool} | input={step.input}\")\n",
        "\n",
        "    # EXECUTE 단계\n",
        "    print(\"\\n\" + \"-\"*30 + \" EXECUTION \" + \"-\"*30)\n",
        "\n",
        "    tool_results = execute_plan(plan)\n",
        "\n",
        "    for r in tool_results:\n",
        "        print(f\"\\n[STEP {r['step_index']}] TOOL: {r['tool']}\")\n",
        "        print(\"INPUT:\", r[\"input\"])\n",
        "\n",
        "        out = r[\"output\"]\n",
        "        if not isinstance(out, str):\n",
        "            out = json.dumps(out, ensure_ascii=False)\n",
        "\n",
        "        print(\"OUTPUT (truncated):\")\n",
        "        print(out[:print_chars])\n",
        "\n",
        "    # WRITE 단계\n",
        "    print(\"\\n\" + \"-\"*30 + \" WRITING FINAL ANSWER \" + \"-\"*30)\n",
        "\n",
        "    final = write_final(user_question, plan, tool_results)\n",
        "\n",
        "    print(\"\\nFINAL ANSWER:\")\n",
        "    print(final)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "    return {\n",
        "        \"plan\": plan,\n",
        "        \"tool_results\": tool_results,\n",
        "        \"final\": final\n",
        "    }\n"
      ],
      "metadata": {
        "id": "SvNib6ry5F3M"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_plan_then_execute_verbose(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYr-nYTd5S6c",
        "outputId": "2de73aca-6681-4a00-e70d-63834ee1056d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "USER QUESTION:\n",
            "Plan-Then-Execute 패턴이 뭐고 ReAct랑 차이를 예시 포함해서 설명해줘. 최신 관점이면 search도 활용해.\n",
            "\n",
            "------------------------------ PLANNING ------------------------------\n",
            "GOAL: Explain the Plan-Then-Execute pattern and its differences from ReAct, including examples.\n",
            "\n",
            "STEPS:\n",
            "  [0] tool=wiki | input=Plan-Then-Execute pattern\n",
            "  [1] tool=wiki | input=ReAct pattern\n",
            "  [2] tool=search | input=Plan-Then-Execute vs ReAct pattern 2023\n",
            "  [3] tool=final_answer | input=Provide a detailed explanation of the Plan-Then-Execute pattern and how it differs from the ReAct pattern, including examples from the latest sources.\n",
            "\n",
            "------------------------------ EXECUTION ------------------------------\n",
            "\n",
            "[STEP 0] TOOL: wiki\n",
            "INPUT: Plan-Then-Execute pattern\n",
            "OUTPUT (truncated):\n",
            "Page: Strategic planning\n",
            "Summary: Strategic planning or corporate planning is an activity undertaken by an organization through which it seeks to define its future direction and makes decisions such as resource allocation aimed at achieving its intended goals. \"Strategy\" has many definitions, but it generally involves setting major goals, determining actions to achieve these goals, setting a timeline, and mobilizing resources to execute the actions. A strategy describes how the ends (goals) will be achieved by the means (resources) in a given span of time. Often, strategic planning is long term and organizational action steps are established from two to five years in the future. Strategy can be planned (\"intended\") or can be observed as a pattern of activity (\"emergent\") as the organizatio\n",
            "\n",
            "[STEP 1] TOOL: wiki\n",
            "INPUT: ReAct pattern\n",
            "OUTPUT (truncated):\n",
            "Page: React (software)\n",
            "Summary: React (also known as React.js or ReactJS) is a free and open-source front-end JavaScript library that aims to make building user interfaces based on components more \"seamless\". It is maintained by Meta (formerly Facebook) and a community of individual developers and companies. According to the 2025 Stack Overflow Developer Survey, React is one of the most commonly used web technologies.\n",
            "React can be used to develop single-page, mobile, or server-rendered applications with frameworks like Next.js and React Router. Because React is only concerned with the user interface and rendering components to the DOM, React applications often rely on libraries for routing and other client-side functionality. A key advantage of React is that it only re-renders those parts \n",
            "\n",
            "[STEP 2] TOOL: search\n",
            "INPUT: Plan-Then-Execute vs ReAct pattern 2023\n",
            "OUTPUT (truncated):\n",
            "[{\"title\": \"[PDF] Architecting Resilient LLM Agents: A Guide to Secure Plan-then ...\", \"url\": \"https://arxiv.org/pdf/2509.08646\", \"content\": \"1.3 Comparative Analysis: Plan-then-Execute vs. ReAct To fully appreciate the strategic value of the P-t-E pattern, it is essential to contrast it with the ReAct (Reason-Act) pattern, one of the most common and foundational designs for LLM agents. The ReAct pattern operates as a tight, iterative loop: the agent generates a Thought about what to do next, performs an Action (typically a tool call), observes the Observation (the result of the action), and then feeds that observation back into the loop to generate the next Thought (LangChain, 2024). This step-by-step process makes ReAct 3 agents highly adaptive and effective for simple, dynamic tasks. Ho\n",
            "\n",
            "[STEP 3] TOOL: final_answer\n",
            "INPUT: Provide a detailed explanation of the Plan-Then-Execute pattern and how it differs from the ReAct pattern, including examples from the latest sources.\n",
            "OUTPUT (truncated):\n",
            "(final step - no tool execution)\n",
            "\n",
            "------------------------------ WRITING FINAL ANSWER ------------------------------\n",
            "\n",
            "FINAL ANSWER:\n",
            "Plan-Then-Execute 패턴과 ReAct 패턴은 AI 에이전트 설계에서 두 가지 주요 접근 방식입니다. \n",
            "\n",
            "- **Plan-Then-Execute 패턴**:\n",
            "  - **계획 단계**: 먼저 전체 작업을 분석하고 세부 단계로 나누어 실행 계획을 수립합니다.\n",
            "  - **실행 단계**: 계획된 순서에 따라 각 단계를 실행하며, 필요에 따라 계획을 조정합니다.\n",
            "  - **장점**: 복잡한 작업이나 여러 단계가 필요한 작업에 적합하며, 각 단계의 의존성을 고려하여 체계적으로 진행할 수 있습니다.\n",
            "  - **예시**: 대규모 연구 프로젝트나 장기적인 전략 수립에 유리합니다.\n",
            "\n",
            "- **ReAct 패턴**:\n",
            "  - **반복적 루프**: 생각(Reasoning)과 행동(Acting)을 번갈아 수행하며, 각 행동의 결과를 관찰하여 다음 행동을 결정합니다.\n",
            "  - **장점**: 단순하고 동적인 작업에 적합하며, 빠른 적응이 가능합니다.\n",
            "  - **단점**: 장기적인 계획이 부족하여 복잡한 작업에서는 비효율적일 수 있습니다.\n",
            "  - **예시**: 실시간 데이터 처리나 간단한 문제 해결에 적합합니다.\n",
            "\n",
            "최신 자료에 따르면, Plan-Then-Execute는 복잡한 작업에 적합하며, ReAct는 단순한 작업에 적합하다는 점에서 차이가 있습니다. 두 패턴을 결합하여 전략적 수준에서는 Plan-Then-Execute를, 전술적 수준에서는 ReAct를 사용하는 하이브리드 접근도 가능합니다.\n",
            "\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'plan': Plan(goal='Explain the Plan-Then-Execute pattern and its differences from ReAct, including examples.', steps=[Step(tool='wiki', input='Plan-Then-Execute pattern'), Step(tool='wiki', input='ReAct pattern'), Step(tool='search', input='Plan-Then-Execute vs ReAct pattern 2023'), Step(tool='final_answer', input='Provide a detailed explanation of the Plan-Then-Execute pattern and how it differs from the ReAct pattern, including examples from the latest sources.')]),\n",
              " 'tool_results': [{'step_index': 0,\n",
              "   'tool': 'wiki',\n",
              "   'input': 'Plan-Then-Execute pattern',\n",
              "   'output': 'Page: Strategic planning\\nSummary: Strategic planning or corporate planning is an activity undertaken by an organization through which it seeks to define its future direction and makes decisions such as resource allocation aimed at achieving its intended goals. \"Strategy\" has many definitions, but it generally involves setting major goals, determining actions to achieve these goals, setting a timeline, and mobilizing resources to execute the actions. A strategy describes how the ends (goals) will be achieved by the means (resources) in a given span of time. Often, strategic planning is long term and organizational action steps are established from two to five years in the future. Strategy can be planned (\"intended\") or can be observed as a pattern of activity (\"emergent\") as the organization adapts to its environment or competes in the market.\\nThe senior leadership of an organization is generally tasked with determining strategy. It is executed by strategic planners or strategists, who involve many parties and research sources in their analysis of the organization and its relationship to the environment in which it competes.\\nStrategy includes processes of formulation and implementation; strategic planning helps coordinate both. However, strategic planning is analytical in nature (i.e., it involves \"finding the dots\"); strategy formation itself involves synthesis (i.e., \"connecting the dots\") via strategic thinking. As such, strategic planning occurs around the strategy formation activity.\\n\\n\\n\\nPage: Strategy\\nSummary: Strategy (from Greek στρατηγία stratēgia, \"troop leadership; office of general, command, generalship\") is a general plan to achieve one or more long-term or overall goals under conditions of uncertainty. In the sense of the \"art of the general\", which included several subsets of skills including military tactics, siegecraft, logistics etc., the term came into use in the 6th century C.E. in Eastern Roman terminology, and was translated into Western vernacul'},\n",
              "  {'step_index': 1,\n",
              "   'tool': 'wiki',\n",
              "   'input': 'ReAct pattern',\n",
              "   'output': 'Page: React (software)\\nSummary: React (also known as React.js or ReactJS) is a free and open-source front-end JavaScript library that aims to make building user interfaces based on components more \"seamless\". It is maintained by Meta (formerly Facebook) and a community of individual developers and companies. According to the 2025 Stack Overflow Developer Survey, React is one of the most commonly used web technologies.\\nReact can be used to develop single-page, mobile, or server-rendered applications with frameworks like Next.js and React Router. Because React is only concerned with the user interface and rendering components to the DOM, React applications often rely on libraries for routing and other client-side functionality. A key advantage of React is that it only re-renders those parts of the page that have changed, avoiding unnecessary re-rendering of unchanged DOM elements. React is used by an estimated 6% of all websites.\\n\\nPage: Pattern matching\\nSummary: In computer science, pattern matching is the act of checking a given sequence of tokens for the presence of the constituents of some pattern. In contrast to pattern recognition, the match usually must be exact: \"either it will or will not be a  match.\" The patterns generally have the form of either sequences or tree structures. Uses of pattern matching include outputting the locations (if any) of a pattern within a token sequence, to output some component of the matched pattern, and to substitute the matching pattern with some other token sequence (i.e., search and replace).\\nSequence patterns (e.g., a text string) are often described using regular expressions and matched using techniques such as backtracking.\\nTree patterns are used in some programming languages as a general tool to process data based on its structure, e.g. C#, F#, Haskell, Java, ML, Python, Racket, Ruby, Rust, Scala, Swift and the symbolic mathematics language Mathematica have special syntax for expressing tree patterns and a language construc'},\n",
              "  {'step_index': 2,\n",
              "   'tool': 'search',\n",
              "   'input': 'Plan-Then-Execute vs ReAct pattern 2023',\n",
              "   'output': [{'title': '[PDF] Architecting Resilient LLM Agents: A Guide to Secure Plan-then ...',\n",
              "     'url': 'https://arxiv.org/pdf/2509.08646',\n",
              "     'content': '1.3 Comparative Analysis: Plan-then-Execute vs. ReAct To fully appreciate the strategic value of the P-t-E pattern, it is essential to contrast it with the ReAct (Reason-Act) pattern, one of the most common and foundational designs for LLM agents. The ReAct pattern operates as a tight, iterative loop: the agent generates a Thought about what to do next, performs an Action (typically a tool call), observes the Observation (the result of the action), and then feeds that observation back into the loop to generate the next Thought (LangChain, 2024). This step-by-step process makes ReAct 3 agents highly adaptive and effective for simple, dynamic tasks. However, this same characteristic exposes them to a key weakness: “short-term thinking” (LangChain, 2024). Because the agent only plans one [...] Task Complexity ReAct is well-suited for simple, direct tasks that can be solved with a few tool calls and do not require long-term strategic planning. P-t-E, conversely, is designed for and excels at complex, multi-step tasks, particularly those with dependencies between steps where the outcome of one step informs the input of another (Shen et al., 2023). [...] the Executor itself can be a fully-fledged ReAct agent. This creates a powerful hybrid pattern where P-t-E operates at the strategic level, defining the overall mission, while ReAct is employed at the tactical level to handle the nuances of executing each individual step (LangChain, 2024). This modularity allows architects to tailor the complexity of the Executor to the complexity of the sub-tasks it is expected to perform.',\n",
              "     'score': 0.9997868},\n",
              "    {'title': 'ReAct vs Plan-and-Execute: A Practical Comparison of LLM Agent ...',\n",
              "     'url': 'https://dev.to/jamesli/react-vs-plan-and-execute-a-practical-comparison-of-llm-agent-patterns-4gh9',\n",
              "     'content': '### 1.2 Plan-and-Execute Pattern\\n\\nPlan-and-Execute pattern adopts a \"plan first, execute later\" strategy, dividing tasks into two distinct phases:\\n\\n1. Planning Phase:\\n\\n    Analyze task objectives\\n    Break down into subtasks\\n    Develop execution plan\\n2. Execution Phase:\\n\\n    Execute subtasks in sequence\\n    Process execution results\\n    Adjust plan if needed\\n\\nTypical Plan-and-Execute Prompt Template: [...] Skip to content\\n\\nLog in    Create account\\n\\n## DEV Community\\n\\nJames Lee\\n\\nPosted on\\n\\n# ReAct vs Plan-and-Execute: A Practical Comparison of LLM Agent Patterns\\n\\n#llm #ai #langchain #agents\\n\\nWhen building LLM Agent systems, choosing the right reasoning pattern is crucial. This article provides an in-depth comparison of two mainstream Agent reasoning patterns: ReAct (Reasoning and Acting) and Plan-and-Execute, helping you make informed technical decisions through practical cases.\\n\\n## Key Takeaways\\n\\n Understanding Two Major Agent Patterns\\n\\n  + ReAct\\'s reasoning-action loop mechanism\\n  + Plan-and-Execute\\'s planning-execution separation strategy\\n LangChain-based Implementation [...] + ReAct pattern code implementation and best practices\\n  + Plan-and-Execute pattern engineering solutions\\n Performance and Cost Analysis\\n\\n  + Quantitative analysis of response time and accuracy\\n  + Detailed calculation of token consumption and API costs\\n Practical Cases and Applications\\n\\n  + Real-world data analysis tasks\\n  + Optimal pattern selection for different scenarios\\n Systematic Selection Methodology\\n\\n  + Scene characteristics and pattern matching guidelines\\n  + Hybrid strategy implementation recommendations\\n\\n## 1. Working Principles of Both Patterns\\n\\n### 1.1 ReAct Pattern\\n\\nReAct (Reasoning and Acting) pattern is an iterative approach that alternates between thinking and acting. Its core workflow includes:',\n",
              "     'score': 0.9997851},\n",
              "    {'title': 'Planning vs ReAct AI Agents: Choosing the Right Approach - LinkedIn',\n",
              "     'url': 'https://www.linkedin.com/posts/lewisowain_how-to-build-an-ai-agent-activity-7402339630764941312-_G5h',\n",
              "     'content': 'This is why Deep Research produces comprehensive reports in minutes. 5. Know when to use which ReAct agents are great for simpler tasks. Planning agents are for complex/long-running work. The distinction is task length, not sophistication. If you want to build this yourself, start with LangGraph\\'s plan-and-execute tutorial. It walks through exactly this pattern. \\\\_\\\\_ Enjoy this? ♻️ Repost it to your network and follow Owain Lewis for more. Want to master AI engineering? Join thousands of professionals from top tech companies (Google, Amazon, Oracle) and level up your AI skills for free: [...] Two ways to build an AI agent (and when to use each): Most AI agents use a simple loop. Reason. Act. Observe. Repeat (ReAct) This works fine for many tasks. But for long-running research? It falls apart. The problem is context drift. After many tool calls, the context window fills with search results. The original goal gets buried. The agent loses focus. Planning agents (Claude Code, Deep Research) solve this with a different architecture. Here\\'s how it works: 1. Plan first and store it Create a plan first. Store it outside chat history. The LLM can\\'t accidentally forget what it\\'s doing. 2. Split the work The Architect creates the plan. It breaks the task into sections before any real work begins. You see this with deep research tools where it creates a detailed plan upfront. A Worker [...] tools where it creates a detailed plan upfront. A Worker researches one section at a time. It has tunnel vision by design. It can\\'t get distracted by other sections. The Manager compiles results and handles conflicts. If Worker A says 2023 and Worker B says 2024, it can flag or resolve the discrepancy. 3. Make each worker self-correcting The Worker doesn\\'t just search once. It asks: \"What\\'s missing?\" If there are gaps, it loops back. It keeps refining until the section is solid. 4. Run parallel workflows, not just parallel tools ReAct agents can call multiple tools at once. That\\'s useful but limited. Planning agents run entire research processes in parallel. Five sections. Five workers. Each running 10-15 tool calls simultaneously. This is why Deep Research produces comprehensive reports',\n",
              "     'score': 0.99948466},\n",
              "    {'title': 'Agent Architectures: ReAct, Self-Ask, Plan-and-Execute',\n",
              "     'url': 'https://apxml.com/courses/langchain-production-llm/chapter-2-sophisticated-agents-tools/agent-architectures',\n",
              "     'content': '1. Planning: Given the user\\'s objective, a dedicated \"Planner\" component (usually powered by an LLM) analyzes the request and generates a step-by-step plan. Each step typically describes an action to be taken.\\n2. Execution: An \"Executor\" component takes the generated plan and carries out each step sequentially. The executor might involve simpler LLM calls focused only on executing a specific step, or it might directly invoke tools specified in the plan step. The results from one step are typically fed into the next.\\n\\n> The Plan-and-Execute architecture separates plan generation (Planner) from step-by-step execution (Executor).\\n\\nStrengths: [...] All Courses [...] Strengths:\\n\\n Structured Tasks: Well-suited for tasks that have a clear, logical sequence of operations.\\n Predictability: The plan is generated upfront, making the agent\\'s overall approach more predictable (though execution details might vary).\\n State Management: Can be easier to manage state between steps, as the plan provides a clear structure.\\n Efficiency: Might require fewer high-level reasoning LLM calls compared to ReAct, as the main reasoning happens during the planning phase. Execution steps might use simpler logic or focused LLM calls.\\n\\nLimitations:',\n",
              "     'score': 0.9992022},\n",
              "    {'title': 'Implement Planning Agentic Pattern from Scratch',\n",
              "     'url': 'https://blog.dailydoseofds.com/p/implement-planning-agentic-pattern',\n",
              "     'content': '# Daily Dose of Data Science\\n\\n# Implement Planning Agentic Pattern from Scratch\\n\\n### ...using pure Python and an LLM.\\n\\nAvi Chawla\\n\\nApr 22, 2025\\n\\nPart 11 of the AI Agents crash course is available.\\n\\nHere, we implemented the ReAct pattern from scratch (using just pure Python and an LLM).\\n\\nRead here: \\u200bAI Agents Crash Course Part 11 →\\n\\nImplement Planning Pattern from Scratch\\n\\nBut what exactly is the Planning pattern, and why is it so important?\\n\\nResearchers have observed that even when prompting an LLM to reason stepwise (chain-of-thought), it may skip critical steps or produce a flawed solution path.\\n\\nBy contrast, if we ask the model to devise a plan first and then execute it, we force it to think through the entire solution path, reducing the chance of skipping steps.',\n",
              "     'score': 0.9981756}]},\n",
              "  {'step_index': 3,\n",
              "   'tool': 'final_answer',\n",
              "   'input': 'Provide a detailed explanation of the Plan-Then-Execute pattern and how it differs from the ReAct pattern, including examples from the latest sources.',\n",
              "   'output': '(final step - no tool execution)'}],\n",
              " 'final': 'Plan-Then-Execute 패턴과 ReAct 패턴은 AI 에이전트 설계에서 두 가지 주요 접근 방식입니다. \\n\\n- **Plan-Then-Execute 패턴**:\\n  - **계획 단계**: 먼저 전체 작업을 분석하고 세부 단계로 나누어 실행 계획을 수립합니다.\\n  - **실행 단계**: 계획된 순서에 따라 각 단계를 실행하며, 필요에 따라 계획을 조정합니다.\\n  - **장점**: 복잡한 작업이나 여러 단계가 필요한 작업에 적합하며, 각 단계의 의존성을 고려하여 체계적으로 진행할 수 있습니다.\\n  - **예시**: 대규모 연구 프로젝트나 장기적인 전략 수립에 유리합니다.\\n\\n- **ReAct 패턴**:\\n  - **반복적 루프**: 생각(Reasoning)과 행동(Acting)을 번갈아 수행하며, 각 행동의 결과를 관찰하여 다음 행동을 결정합니다.\\n  - **장점**: 단순하고 동적인 작업에 적합하며, 빠른 적응이 가능합니다.\\n  - **단점**: 장기적인 계획이 부족하여 복잡한 작업에서는 비효율적일 수 있습니다.\\n  - **예시**: 실시간 데이터 처리나 간단한 문제 해결에 적합합니다.\\n\\n최신 자료에 따르면, Plan-Then-Execute는 복잡한 작업에 적합하며, ReAct는 단순한 작업에 적합하다는 점에서 차이가 있습니다. 두 패턴을 결합하여 전략적 수준에서는 Plan-Then-Execute를, 전술적 수준에서는 ReAct를 사용하는 하이브리드 접근도 가능합니다.'}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ㄴ 2. State Machine Pattern\n",
        "> LLM은 **상태를 읽고 판단만** 함."
      ],
      "metadata": {
        "id": "I1aqzgNKnmsM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```javascript\n",
        "TaskState:\n",
        "    goal\n",
        "    progress\n",
        "    artifacts\n",
        "    failures\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "pL0qVChIodGp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ㄴ 3. Graph Execution Pattern\n",
        "> Agent는 더 이상 **Loop**가 아닌 **Directed Graph** 임"
      ],
      "metadata": {
        "id": "JQfU0ZwCnz_o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```javascript\n",
        "[Plan]\n",
        "  ↓\n",
        "[Search] → [Analyze]\n",
        "  ↓\n",
        "[Write]\n",
        "  ↓\n",
        "[Validate]\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "FzHcvNTkoI4z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ㄴ 4. Role-Specialized Multi-Agent Pattern\n",
        "\n",
        "\n",
        "*   **System**이 **역할**을 **정의**\n",
        "*   **LLM**은 **Role Function**으로 **호출**\n",
        "\n"
      ],
      "metadata": {
        "id": "TT35tciCpIRs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```javascript\n",
        "ResearchAgent = LLM(prompt=X)\n",
        "WriterAgent   = LLM(prompt=Y)\n",
        "CriticAgent   = LLM(prompt=Z)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Q5sqUR8jpWwx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ㄴ 5. Deterministic Guardrail Pattern\n",
        "\n",
        "**Post-ReAct에서는 반드시 아래 항목이 존재**\n",
        "*   Validation Step\n",
        "*   Structured Output\n",
        "*   JSON Contracts\n",
        "*   Retry Policy\n",
        "\n"
      ],
      "metadata": {
        "id": "uIT-Z7HPppHM"
      }
    }
  ]
}