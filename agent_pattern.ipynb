{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "VNgdPBbNxdKh",
        "rHIPs8XTcfpR",
        "kP16oCAwawq2",
        "alqHd1KutqEv",
        "BV3CJLc87yf1",
        "EYy3pdEssWBy",
        "fByclIo8VLyy",
        "hjBrEQ1kuBte",
        "ANzsEwAduiYW",
        "kPShHFTExSZl",
        "LevAC_J9-cmF",
        "uVxtzNAx-bSI",
        "6PeHqJgXD2u3",
        "xR4HMPbUD9kc",
        "QyrYX_loFS7r"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPZIEXhdGN3d/11CY9qXFDb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bckim9489/agent_practice/blob/main/agent_pattern.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Common Setup\n",
        "\n",
        "참고 : 아래 Secret으로 Key 등록해서 실습함\n",
        "1.   LLM API Key (GPT, claude 등) : OPENAI-KEY 로 등록했음\n",
        "2.   Tavily Serach API Key (https://app.tavily.com/home) : TAVIL-KEY 로 등록했음\n",
        "\n"
      ],
      "metadata": {
        "id": "ERCG8LefaX33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install -U \"requests==2.32.5\" \"pydantic==2.12.3\" \"httpx==0.28.1\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yweuvVZwv7C",
        "outputId": "710be75c-7a66-4653-e57a-f2efd39f9daf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "xaaHPNB-JuRU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "158dc59e-8aa3-4d7b-9cd5-3d382638e1e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m500.5/500.5 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip -q install -U langgraph langchain-openai langchain-community wikipedia numexpr tavily-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "# LLM API Key\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI-KEY\")\n",
        "\n",
        "# Tools\n",
        "# Search API Key\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get(\"TAVILY-KEY\")\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n"
      ],
      "metadata": {
        "id": "0of3EhdAK8Wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ㄴ 0. TEST"
      ],
      "metadata": {
        "id": "VNgdPBbNxdKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, httpx, pydantic\n",
        "import langchain_community, langgraph\n",
        "from langgraph.graph import StateGraph\n",
        "\n",
        "print(\"requests:\", requests.__version__)\n",
        "print(\"httpx:\", httpx.__version__)\n",
        "print(\"pydantic:\", pydantic.__version__)\n",
        "print(\"langchain-community:\", langchain_community.__version__)\n",
        "print(\"LangGraph import OK\")\n",
        "print(\"StateGraph:\", StateGraph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBEwa4scxj9w",
        "outputId": "21713c25-16a2-40b4-81f7-767789e1a438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "requests: 2.32.4\n",
            "httpx: 0.28.1\n",
            "pydantic: 2.12.3\n",
            "langchain-community: 0.4.1\n",
            "LangGraph import OK\n",
            "StateGraph: <class 'langgraph.graph.state.StateGraph'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ㄴ 1. Tools"
      ],
      "metadata": {
        "id": "rHIPs8XTcfpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "from langchain_community.tools import WikipediaQueryRun\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "from langchain_core.tools import tool\n",
        "import numexpr\n",
        "\n",
        "# Wikipedia tool\n",
        "wiki = WikipediaQueryRun(\n",
        "    api_wrapper=WikipediaAPIWrapper(top_k_results=3, doc_content_chars_max=2000)\n",
        ")\n",
        "\n",
        "# 기존 wiki wrapper 재사용\n",
        "wiki_lookup_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=4000)\n",
        "\n",
        "@tool\n",
        "def docstore_lookup(title: str) -> str:\n",
        "    \"\"\"\n",
        "    Lookup a specific document by title from the docstore (Wikipedia).\n",
        "    Input should be a precise title or entity name.\n",
        "    \"\"\"\n",
        "    return wiki_lookup_wrapper.run(title)\n",
        "\n",
        "# Tavily Search tool\n",
        "search_tool = TavilySearchResults(max_results=5)\n",
        "\n",
        "# Calculator tool (llm-math 대체)\n",
        "@tool\n",
        "def calculator(expression: str) -> str:\n",
        "    \"\"\"\n",
        "    Evaluate a mathematical expression.\n",
        "    Input must be a valid expression like '345*872' or '12/4+9'.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return str(numexpr.evaluate(expression))\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "\n",
        "tools = [wiki, calculator, search_tool, docstore_lookup]\n",
        "print(\"=== Tools ===\")\n",
        "for t in tools:\n",
        "    print(\"-\", t.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyVc3d97jxUh",
        "outputId": "b91ff0dd-852a-4914-a08a-3db166445762"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Tools ===\n",
            "- wikipedia\n",
            "- calculator\n",
            "- tavily_search_results_json\n",
            "- docstore_lookup\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1012767205.py:25: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the `langchain-tavily package and should be used instead. To use it run `pip install -U `langchain-tavily` and import as `from `langchain_tavily import TavilySearch``.\n",
            "  search_tool = TavilySearchResults(max_results=5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#\n",
        "----------------------------------------------------------"
      ],
      "metadata": {
        "id": "XN4UkyewGTwT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Gen 1] Prompt-driven Tool-Using Agents (ReAct-based Agents)\n",
        "> **LLM**이 매 순간 다음 행동을 **즉흥 결정**\n",
        "*   **LLM-Driven Agents**\n",
        "*   LLM이 생각(Reasoning) 하고\n",
        "*   외부 도구를 행동(Act) 으로 호출하며\n",
        "*   그 결과를 다시 보고 추론을 이어가는 \"Tool-using LLM Loop\"\n",
        "*   2022 ~ 2024\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2znB-998RCON"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ㄴ 1. Zero-Shot ReAct\n",
        "*   기억 없음(Stateless)\n",
        "*   **LLM + Tools**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ehIezWEaajKR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 1.1 Description"
      ],
      "metadata": {
        "id": "YAnx3hYxpLVg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 1.1.1 Workflow\n"
      ],
      "metadata": {
        "id": "hYUi-RFIpe9p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```javascript\n",
        "Client\n",
        "  ↓\n",
        "User Question 전송\n",
        "  ↓\n",
        "API / Backend (Agent Endpoint)\n",
        "  ↓\n",
        "LangGraph Runtime 시작\n",
        "  ↓\n",
        "LLM: 질문 해석 (Thought / Reasoning)\n",
        "  ↓\n",
        "Tool 필요 여부 판단\n",
        "  ├─ 필요 없음 → 바로 답 생성\n",
        "  └─ 필요 있음 → Tool 선택 (Action)\n",
        "                      ↓\n",
        "                Tool 실행 (Python / API / DB 등)\n",
        "                      ↓\n",
        "                결과 반환 (Observation)\n",
        "                      ↓\n",
        "LLM이 결과 반영하여 다시 Reasoning\n",
        "  ↓\n",
        "(필요 시 Thought → Action → Observation 반복)\n",
        "  ↓\n",
        "Final Answer 생성\n",
        "  ↓\n",
        "API가 응답 반환\n",
        "  ↓\n",
        "Client가 사용자에게 표시\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "9uI9XCOlqjvb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 1.1.2 Inner ReAct Loop"
      ],
      "metadata": {
        "id": "lFACiazxqBeK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "``` javascript\n",
        "while 문제 해결 전:\n",
        "    Thought      → 어떻게 풀지 스스로 판단\n",
        "    Action       → 사용할 Tool 선택\n",
        "    Observation  → Tool 실행 결과 받기\n",
        "    Thought      → 결과 보고 다음 행동 결정\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "gQYu7VPTqTip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 1.2 Code"
      ],
      "metadata": {
        "id": "rDXdgSpop1qb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "agent = create_react_agent(llm, tools)"
      ],
      "metadata": {
        "id": "4mcT3ELCjyDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = \"\"\"위키피디아에서 찾기 좋은 '검색어(제목형 키워드)'를 3개 만들어서,\n",
        "그 키워드로 Wikipedia tool을 사용해 검색하고 근거를 요약해줘.\n",
        "주제: Pinus densiflora 옮겨심기(이식) 적기\"\"\""
      ],
      "metadata": {
        "id": "vSI9contrFxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = agent.invoke({\"messages\": [(\"user\", q)]})\n",
        "\n",
        "print(result[\"messages\"][-1].content)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "tHHfmPKBrDtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 1.3 Verbose"
      ],
      "metadata": {
        "id": "7scQ69xTbS3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import AIMessage, ToolMessage\n",
        "\n",
        "for step in agent.stream(\n",
        "    {\"messages\": [(\"user\", q)]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    msg = step[\"messages\"][-1]\n",
        "\n",
        "    # LLM이 생각/결정한 내용\n",
        "    if isinstance(msg, AIMessage):\n",
        "        print(\"\\n AI MESSAGE\")\n",
        "        print(msg.content)\n",
        "\n",
        "        if getattr(msg, \"tool_calls\", None):\n",
        "            print(\" TOOL CALL:\", msg.tool_calls)\n",
        "\n",
        "    # Tool 실행 결과\n",
        "    elif isinstance(msg, ToolMessage):\n",
        "        print(\"\\n TOOL RESULT\")\n",
        "        print(\"tool:\", msg.name)\n",
        "        print(msg.content[:1000])  # 너무 길면 앞부분만\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mWt9u_sNjzzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BrN_rPDn1ohp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ㄴ 2. Conversational ReAct\n",
        "*   메모리 사용\n",
        "*   **LLM + Tools + Checkpointer**\n",
        "\n"
      ],
      "metadata": {
        "id": "kP16oCAwawq2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 2.1 Description"
      ],
      "metadata": {
        "id": "QtEy1_mMrxoX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 2.1.1 Workflow"
      ],
      "metadata": {
        "id": "43pV-jAmsAZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```javascript\n",
        "Client\n",
        "  ↓\n",
        "User Question 전송\n",
        "  ↓\n",
        "API / Backend (Agent Endpoint)\n",
        "  ↓\n",
        "LangGraph Runtime 시작\n",
        "  ↓\n",
        "이전 대화 기록(Memory / State) 로드\n",
        "  ↓\n",
        "LLM: 현재 질문 + 대화 히스토리 함께 해석\n",
        "  ↓\n",
        "사용자의 의도 파악 (맥락 기반 Reasoning)\n",
        "  ↓\n",
        "Tool 필요 여부 판단\n",
        "  ├─ 필요 없음 → 바로 답 생성\n",
        "  └─ 필요 있음 → Tool 선택 (Action)\n",
        "                      ↓\n",
        "                Tool 실행 (Python / API / DB 등)\n",
        "                      ↓\n",
        "                결과 반환 (Observation)\n",
        "                      ↓\n",
        "LLM이 결과 + 이전 대화 맥락을 반영하여 다시 Reasoning\n",
        "  ↓\n",
        "(필요 시 Thought → Action → Observation 반복)\n",
        "  ↓\n",
        "Final Answer 생성\n",
        "  ↓\n",
        "대화 Memory(State)에 이번 메시지 저장\n",
        "  ↓\n",
        "API가 응답 반환\n",
        "  ↓\n",
        "Client가 사용자에게 표시\n",
        "```"
      ],
      "metadata": {
        "id": "0E4iTxHisGtf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 2.1.2 Inner ReAct Loop"
      ],
      "metadata": {
        "id": "sksFSADgsLM3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```javascript\n",
        "while 문제 해결 전:\n",
        "    Load Memory        → 이전 대화 불러오기\n",
        "    Thought            → 맥락 기반으로 판단\n",
        "    Action             → Tool 필요하면 실행\n",
        "    Observation        → Tool 결과 받기\n",
        "    Update Memory      → 새 정보 저장\n",
        "```"
      ],
      "metadata": {
        "id": "uvgeHLPnsOn2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 2.2 Code"
      ],
      "metadata": {
        "id": "BZJtKmFur3ly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "\n",
        "checkpointer = InMemorySaver()\n",
        "agent = create_react_agent(llm, tools, checkpointer=checkpointer)"
      ],
      "metadata": {
        "id": "_5j7GyaUZjqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"chat-001\"}}\n",
        "q1 = \"내 출생년도는 1994년이야. 지금은 계산하지 말고 이 정보만 기억해.\"\n",
        "q2 = \"그럼 내가 2026년에 몇 살인지 계산기를 꼭 사용해서 나이를 계산해서 알려줘\"\n",
        "q3 = \"올해는 무슨 해이며 나는 무슨 띠인지 알려줘\""
      ],
      "metadata": {
        "id": "gMf3OMaGZ7ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = agent.invoke({\"messages\": [(\"user\", q1)]}, config=config)\n",
        "print(result[\"messages\"][-1].content)\n",
        "result = agent.invoke({\"messages\": [(\"user\", q2)]}, config=config)\n",
        "print(result[\"messages\"][-1].content)\n",
        "result = agent.invoke({\"messages\": [(\"user\", q3)]}, config=config)\n",
        "print(result[\"messages\"][-1].content)\n"
      ],
      "metadata": {
        "id": "EUUVKU_wZpaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 2.3 Verbose"
      ],
      "metadata": {
        "id": "fVi1sXZ-bgqf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 2.3.1 Test Setup"
      ],
      "metadata": {
        "id": "zA7HHzH8kuhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import AIMessage, ToolMessage\n",
        "import time\n",
        "from openai import RateLimitError\n",
        "\n",
        "from langchain_core.messages import AIMessage, ToolMessage\n",
        "\n",
        "def stream_with_retry(agent, payload, config, stream_mode=\"values\", max_retries=6):\n",
        "    \"\"\"\n",
        "    agent.stream(...) 를 RateLimitError(429) 발생 시 backoff 재시도.\n",
        "    \"\"\"\n",
        "    attempt = 0\n",
        "    while True:\n",
        "        try:\n",
        "            for step in agent.stream(payload, config=config, stream_mode=stream_mode):\n",
        "                yield step\n",
        "            return  # 정상 종료\n",
        "        except RateLimitError as e:\n",
        "            attempt += 1\n",
        "            if attempt > max_retries:\n",
        "                raise\n",
        "\n",
        "            # 간단 backoff (점점 더 기다림)\n",
        "            wait = min(20, 1.5 * attempt)\n",
        "            print(f\"\\n RateLimit(429). retry in {wait:.1f}s ...\")\n",
        "            time.sleep(wait)\n",
        "\n",
        "\n",
        "\n",
        "def run_verbose(question: str, label: str, thread_id: str):\n",
        "    print(\"\\n\" + \"=\"*20 + f\" {label} (thread_id={thread_id}) \" + \"=\"*20)\n",
        "    print(\"USER:\", question)\n",
        "\n",
        "    cfg = {\"configurable\": {\"thread_id\": thread_id}}\n",
        "\n",
        "    payload = {\"messages\": [(\"user\", question)]}\n",
        "\n",
        "    last_ai = None\n",
        "    for step in stream_with_retry(agent, payload, cfg, stream_mode=\"values\"):\n",
        "        msg = step[\"messages\"][-1]\n",
        "\n",
        "        if isinstance(msg, AIMessage):\n",
        "            last_ai = msg\n",
        "            if msg.content:\n",
        "                print(\"\\nAI:\", msg.content)\n",
        "            if getattr(msg, \"tool_calls\", None):\n",
        "                print(\"tool_calls:\", msg.tool_calls)\n",
        "\n",
        "        elif isinstance(msg, ToolMessage):\n",
        "            print(\"\\nTOOL RESULT:\", msg.name)\n",
        "            print(msg.content[:800])\n",
        "\n",
        "    return last_ai.content if last_ai else None\n",
        "\n",
        "#메모리 사용하는지 A/B 테스트\n",
        "def ab_test(q1: str, q2: str, q3:str, thread_a: str=\"mem-A\", thread_b: str=\"mem-B\", thread_c: str=\"mem-C\"):\n",
        "    print(\"\\n\\n\" + \"#\"*10 + \" A/B MEMORY TEST START \" + \"#\"*10)\n",
        "\n",
        "    # A: q1 using thread_id a\n",
        "    run_verbose(q1, \"A-1: seed memory (q1)\", thread_a)\n",
        "\n",
        "\n",
        "    # B: q2 using thread_id b\n",
        "    run_verbose(q2, \"B-1: q2 only (no memory)\", thread_b)\n",
        "\n",
        "\n",
        "    # B: q3 using thread_id c\n",
        "    run_verbose(q3, \"C-1: q3 only (no memory)\", thread_c)\n",
        "\n",
        "    print(\"\\n\" + \"#\"*10 + \" A/B MEMORY TEST END \" + \"#\"*10)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "2LB9H_IbaSK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 2.3.2 Test A (같은 thread_id)\n",
        "\n",
        "*   Q1을 thread_id A 에 저장\n",
        "*   Q2를 thread_id A 에 질의\n",
        "----------------------------\n",
        "| Q2에서 메모리에 저장한 Q1을 활용하여 답변할 것으로 예상"
      ],
      "metadata": {
        "id": "PN7owphAlH3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 같은 thread_id\n",
        "run_verbose(q1, \"Q1\", \"chat-001\")\n",
        "run_verbose(q2, \"Q2\", \"chat-001\")\n",
        "run_verbose(q3, \"Q3\", \"chat-001\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "nwQbCVIOlA3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 2.3.3 TEST B (다른 thread_id)\n",
        "\n",
        "*   Q1을 thread_id A 에 저장\n",
        "*   Q2를 thread_id B에 질의\n",
        "----------------------------\n",
        "| Q2에서 질의 에 대한 정보 요구 예상\n",
        "\n"
      ],
      "metadata": {
        "id": "y1eAeR0BlLcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ab_test(q1, q2, q3, thread_a=\"chat-003\", thread_b=\"chat-004\", thread_c=\"chat-005\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "0Qi1B1S2lM3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ㄴ 3. Search-augmented ReAct (Self-ask with search)\n",
        "\n",
        "*   질문 분해 중심\n",
        "*   **RAG와 매우 유사**\n",
        "*   사실상 Self-Ask = 초기 형태의 RAG\n",
        "\n"
      ],
      "metadata": {
        "id": "alqHd1KutqEv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 3.1 Description"
      ],
      "metadata": {
        "id": "ZsEO8BqCxETT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 3.1.1. Workflow"
      ],
      "metadata": {
        "id": "V7rLljfvxLfh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```javascript\n",
        "Client\n",
        "  ↓\n",
        "User Question 전송\n",
        "  ↓\n",
        "API / Backend (Agent Endpoint)\n",
        "  ↓\n",
        "LangGraph / Agent Runtime 시작\n",
        "  ↓\n",
        "LLM이 질문을 \"하위 질문(Sub-questions)\"으로 분해\n",
        "  ↓\n",
        "각 하위 질문을 Search Tool로 순차 조회\n",
        "  ↓\n",
        "검색 결과(Observation)를 모아 중간 결론 생성\n",
        "  ↓\n",
        "필요하면 추가 하위 질문 생성 → 다시 Search\n",
        "  ↓\n",
        "모든 정보가 충분해지면 최종 답 생성\n",
        "  ↓\n",
        "API가 응답 반환\n",
        "  ↓\n",
        "Client가 사용자에게 표시\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "fy4VuWnJxPWb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 3.1.2 Inner ReAct Loop"
      ],
      "metadata": {
        "id": "Bj2GTjr4xTCv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```javascript\n",
        "while 답을 만들 정보가 부족하면:\n",
        "    Follow-up Question 생성\n",
        "    Search Tool 실행\n",
        "    Observation 수집\n",
        "    현재까지의 사실 정리\n",
        "```"
      ],
      "metadata": {
        "id": "EoMIb-d0xYXs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 3.2 Code"
      ],
      "metadata": {
        "id": "vuRDO56bxdTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage\n",
        "\n",
        "# Self-Ask의 핵심 포맷을 강제\n",
        "SELF_ASK_POLICY = SystemMessage(content=\"\"\"\n",
        "You are a Self-Ask-with-Search agent.\n",
        "\n",
        "Hard rules:\n",
        "- For EACH follow-up question, you MUST call the tavily_search_results_json tool.\n",
        "- After the tool returns, you MUST write an Intermediate answer that uses the tool result.\n",
        "- Intermediate answer must include 2-3 bullet points and mention the source titles (from tool results).\n",
        "- Do NOT write placeholders like \"...\". If info is missing, do another search.\n",
        "\n",
        "Output format (exact):\n",
        "Follow-up 1: ...\n",
        "Intermediate answer 1:\n",
        "- ...\n",
        "- ...\n",
        "Sources: <title1>, <title2>\n",
        "\n",
        "Follow-up 2: ...\n",
        "Intermediate answer 2:\n",
        "- ...\n",
        "- ...\n",
        "Sources: ...\n",
        "\n",
        "Final answer: ...\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "id": "aBV7rR953T53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "agent = create_react_agent(llm, tools)"
      ],
      "metadata": {
        "id": "-iImBDY1xhqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = \"\"\"AI Agent를 3문장으로 설명해줘.\n",
        "단, 2025~2026년 기준으로 최신 경향을 반영하기 위해 반드시 tavily_search_results_json을 최소 2번 사용하고,\n",
        "각 검색 결과를 근거로 Intermediate answer를 작성한 뒤 Final answer를 써.\"\"\""
      ],
      "metadata": {
        "id": "aSD-JJbi19tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"self-ask-01\"}}\n",
        "\n",
        "result = agent.invoke({\"messages\": [SELF_ASK_POLICY, (\"user\", q)]},config=config)\n",
        "\n",
        "print(result[\"messages\"][-1].content)"
      ],
      "metadata": {
        "id": "9JKLGdqQ11pJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 3.3. Verbose"
      ],
      "metadata": {
        "id": "LrTWqWT0xjtq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import AIMessage, ToolMessage\n",
        "\n",
        "def run_self_ask_verbose(question: str, thread_id=\"self-ask-03\", tool_preview=600):\n",
        "    cfg = {\"configurable\": {\"thread_id\": thread_id}}\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"USER:\", question)\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    for step in agent.stream(\n",
        "        {\"messages\": [SELF_ASK_POLICY, (\"user\", question)]},\n",
        "        config=cfg,\n",
        "        stream_mode=\"values\",\n",
        "    ):\n",
        "        msg = step[\"messages\"][-1]\n",
        "\n",
        "        # 1) 모델이 말한 텍스트(중간 출력 포함)\n",
        "        if isinstance(msg, AIMessage):\n",
        "            if msg.content:  # content가 있는 경우만 출력\n",
        "                print(\"\\n AI MESSAGE:\\n\", msg.content)\n",
        "\n",
        "            # 2) 도구 호출 로그\n",
        "            if getattr(msg, \"tool_calls\", None):\n",
        "                print(\"\\n TOOL CALLS:\")\n",
        "                for tc in msg.tool_calls:\n",
        "                    print(\" -\", tc)\n",
        "\n",
        "        # 3) 도구 결과\n",
        "        elif isinstance(msg, ToolMessage):\n",
        "            print(\"\\n TOOL RESULT:\", msg.name)\n",
        "            print(msg.content[:tool_preview])\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"END\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "run_self_ask_verbose(q)\n"
      ],
      "metadata": {
        "id": "XMEImNybxuzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ㄴ 4. ReAct docstore\n",
        "\n",
        "*   LLM이 문서 저장소를 스스로 탐색\n",
        "*   필요한 문서를 조회(Lookup)하여 근거 기반 답변을 생성\n",
        "\n"
      ],
      "metadata": {
        "id": "BV3CJLc87yf1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 4.1 Description"
      ],
      "metadata": {
        "id": "InnjMGqM-anr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 4.1.1 Workflow"
      ],
      "metadata": {
        "id": "6YZ6Asa8-gQ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```javascript\n",
        "Client\n",
        "  ↓\n",
        "User Question 전송\n",
        "  ↓\n",
        "API / Backend (Agent Endpoint)\n",
        "  ↓\n",
        "LangGraph Runtime 시작\n",
        "  ↓\n",
        "LLM: 질문 해석 (문서 탐색 필요 판단)\n",
        "  ↓\n",
        "Docstore Search Tool 호출 (Search Action)\n",
        "  ↓\n",
        "관련 문서 후보 목록 반환 (Observation)\n",
        "  ↓\n",
        "LLM: 어떤 문서를 읽을지 Reasoning\n",
        "  ↓\n",
        "Docstore Lookup Tool 호출 (Lookup Action)\n",
        "  ↓\n",
        "선택된 문서 실제 내용 반환 (Observation)\n",
        "  ↓\n",
        "LLM이 문서 내용을 기반으로 재해석 / 근거 정리\n",
        "  ↓\n",
        "(필요 시 Search → Lookup 반복)\n",
        "  ↓\n",
        "충분한 근거 확보 후 Final Answer 생성\n",
        "  ↓\n",
        "API가 응답 반환\n",
        "  ↓\n",
        "Client가 사용자에게 표시\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "DCYLWB1f-mDf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 4.1.2 Inner ReAct Loop"
      ],
      "metadata": {
        "id": "irEIUmY5-p7q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```javascript\n",
        "while (답변에 필요한 근거가 충분하지 않다):\n",
        "    Thought: 질문을 해결하려면 어떤 문서를 찾아야 하는가?\n",
        "    Action: Search(query)\n",
        "    Observation: 관련 문서 후보 목록 반환\n",
        "    Thought: 어떤 문서를 읽어야 하는가?\n",
        "    Action: Lookup(document_id)\n",
        "    Observation: 문서 내용 확보\n",
        "    Thought:이 정보로 답변 가능한가?\n",
        "            ├─ NO → 다른 문서 다시 Search\n",
        "            └─ YES → 반복 종료\n",
        "```"
      ],
      "metadata": {
        "id": "moO_SZRR-ubk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 4.2 Code"
      ],
      "metadata": {
        "id": "Pjc24Na8-yza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "agent = create_react_agent(llm, tools)"
      ],
      "metadata": {
        "id": "yUNy0ToZ-o0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = \"\"\"\n",
        "규칙:\n",
        "- wikipedia 도구를 1회 호출해서 후보 제목을 찾는다.\n",
        "- 그 다음 docstore_lookup 도구를 반드시 1회 이상 호출한다.\n",
        "- docstore_lookup 결과를 근거로 최종 답변을 작성한다.\n",
        "\n",
        "질문: 밍크 선인장(Mammillaria)은 어떤 식물인지 설명해줘.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Scbnrykx-ecp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "config = {\"configurable\": {\"thread_id\": \"docstore-01\"}}\n",
        "result = agent.invoke({\"messages\": [(\"user\", q)]},config=config)\n",
        "\n",
        "print(result[\"messages\"][-1].content)\n"
      ],
      "metadata": {
        "id": "HHLW_HGiBPLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 4.3 Verbose"
      ],
      "metadata": {
        "id": "Lr3TMvzl-2Q-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import AIMessage, ToolMessage\n",
        "\n",
        "def run_docstore_verbose(question: str, thread_id=\"docstore-debug\"):\n",
        "    cfg = {\"configurable\": {\"thread_id\": thread_id}}\n",
        "\n",
        "    print(\"\\n================ USER ================\")\n",
        "    print(question)\n",
        "\n",
        "    for step in agent.stream(\n",
        "        {\"messages\": [(\"user\", question)]},\n",
        "        config=cfg,\n",
        "        stream_mode=\"values\",   # 상태 변화 전부 받기\n",
        "    ):\n",
        "        msg = step[\"messages\"][-1]\n",
        "\n",
        "        # LLM이 생각한 내용 (Thought / Action 결정)\n",
        "        if isinstance(msg, AIMessage):\n",
        "            if msg.content:\n",
        "                print(\"\\n AI THOUGHT:\")\n",
        "                print(msg.content)\n",
        "\n",
        "            if getattr(msg, \"tool_calls\", None):\n",
        "                print(\"\\n TOOL CALL:\")\n",
        "                print(msg.tool_calls)\n",
        "\n",
        "        # Tool 실행 결과 (Observation)\n",
        "        elif isinstance(msg, ToolMessage):\n",
        "            print(\"\\n TOOL RESULT:\", msg.name)\n",
        "            print(msg.content[:1000])  # 너무 길어서 제한\n",
        "\n",
        "    print(\"\\n================ END ================\\n\")\n",
        "\n",
        "run_docstore_verbose(q)\n"
      ],
      "metadata": {
        "id": "V5LEMXZFDYvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#\n",
        "--------------------------------------------------------------"
      ],
      "metadata": {
        "id": "yfeSgeFTGF3F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Gen 2] LLM Orchestrated Systems (Post-ReAct Agents)\n",
        "> Workflow Engine이 **순서를 결정**, LLM은 **필요할 때만 호출**\n",
        "*   **System-Driven Agents**\n",
        "*   계획 수립 / 의도 해석   ← LLM\n",
        "*   실행 흐름은 시스템이 통제 ← Runtime / Graph / Process\n",
        "*   Tool 실행은 강제된 구조로 수행\n",
        "*   상태(State)를 외부에서 관리\n",
        "*   2024 ~ 현재\n",
        "\n",
        "```javascript\n",
        "User → Orchestrator → Planner → Executor → Validator → State Update\n",
        "                        ↓\n",
        "                      LLM (as function)\n",
        "```\n"
      ],
      "metadata": {
        "id": "OfRLzAbpPzdu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ㄴ 1. Plan-Then-Execute (Two-Phase Execution Architecture)\n",
        "> Plan → **Freeze** Plan → **Execute** Deterministically\n",
        ">"
      ],
      "metadata": {
        "id": "rNEdkyFfV8N6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 1.1 Description"
      ],
      "metadata": {
        "id": "EYy3pdEssWBy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```javascript\n",
        "Planner LLM → Execution Graph 생성\n",
        "Execution Engine:\n",
        "    Step1\n",
        "    Step2\n",
        "    Step3\n",
        "```\n",
        "*    **Planner(LLM)** 는 계획(어떤 툴을 어떤 순서로 쓸지)를 JSON Plan으로만 만듬 (실행 금지)\n",
        "*    **Executor(시스템)** 가 계획을 결정론적으로 실행 (툴을 실제로 호출)\n",
        "*    **Writer(LLM)** 가 결과를 자연어로 정리 및 답변\n",
        "\n",
        "```javascript\n",
        "User Input\n",
        "   ↓\n",
        "Planner (LLM 1회)\n",
        "   ↓\n",
        "Executor (Deterministic Tool Calls)\n",
        "   ↓\n",
        "Writer (LLM 정리)\n",
        "   ↓\n",
        "End\n",
        "```"
      ],
      "metadata": {
        "id": "a_yJV58NolGk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 1.2 Code"
      ],
      "metadata": {
        "id": "mkD5lKiwuAPA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 1.2.1 Tool Registry"
      ],
      "metadata": {
        "id": "EnxBn7oKyXnp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from typing import List, Literal, Dict, Any\n",
        "\n",
        "# 우리가 Plan에서 쓸 \"툴 alias\"\n",
        "TOOL_REGISTRY = {\n",
        "    \"wiki\": wiki,\n",
        "    \"search\": search_tool,\n",
        "    \"lookup\": docstore_lookup,\n",
        "    \"calc\": calculator,\n",
        "}\n",
        "\n",
        "ToolAlias = Literal[\"wiki\", \"search\", \"lookup\", \"calc\", \"final_answer\"]"
      ],
      "metadata": {
        "id": "DqZMdHYduEZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 1.2.2 Contract"
      ],
      "metadata": {
        "id": "QbX58N3yysnY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ㄴ 1.2.2.1 Plan Schema"
      ],
      "metadata": {
        "id": "LD777u2KS1rJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class Step(BaseModel):\n",
        "    tool: ToolAlias\n",
        "    input: str\n",
        "\n",
        "class Plan(BaseModel):\n",
        "    goal: str\n",
        "    steps: List[Step] = Field(min_items=1, max_items=6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nr9odFvtyoF5",
        "outputId": "55810e62-a52d-4968-f8ec-08a6e1361b3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3491100315.py:9: PydanticDeprecatedSince20: `min_items` is deprecated and will be removed, use `min_length` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
            "  steps: List[Step] = Field(min_items=1, max_items=6)\n",
            "/tmp/ipython-input-3491100315.py:9: PydanticDeprecatedSince20: `max_items` is deprecated and will be removed, use `max_length` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
            "  steps: List[Step] = Field(min_items=1, max_items=6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ㄴ 1.2.2.2 System Prompt"
      ],
      "metadata": {
        "id": "_jzOCYQwy4wm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### ㄴ 1.2.2.2.1 Planner System Prompt"
      ],
      "metadata": {
        "id": "VGAWF2-HzAbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "\n",
        "PLANNER_SYS = SystemMessage(content=\n",
        "\"\"\"You are a Planner.\n",
        "Return ONLY valid JSON matching this schema:\n",
        "\n",
        "{\n",
        "  \"goal\": string,\n",
        "  \"steps\": [{\"tool\": \"wiki\"|\"search\"|\"lookup\"|\"calc\"|\"final_answer\", \"input\": string}, ...]\n",
        "}\n",
        "\n",
        "Rules:\n",
        "- Do NOT execute tools.\n",
        "- Prefer \"search\" for up-to-date web info when needed.\n",
        "- Use \"wiki\" for general grounding.\n",
        "- Use \"lookup\" only when you know the exact Wikipedia title/entity.\n",
        "- Use \"calc\" only for arithmetic.\n",
        "- Keep steps minimal (<=4 if possible).\n",
        "- The last step MUST be \"final_answer\".\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "ZHdypHYlzMqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### ㄴ 1.2.2.2.2 Writer System Prompt"
      ],
      "metadata": {
        "id": "O2rgyWFkzSU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "WRITER_SYS = SystemMessage(content=\n",
        "\"\"\"You are a Writer.\n",
        "\n",
        "You will receive:\n",
        "- user_question\n",
        "- plan (JSON)\n",
        "- tool_results (JSON)\n",
        "\n",
        "Rules:\n",
        "- Write the final answer in Korean only (한국어로만 작성).\n",
        "- Use tool_results as evidence. If you reference web search results, summarize them in Korean.\n",
        "- Keep it concise and structured (bullets ok).\n",
        "- If any tool output contains \"Error\" or \"ERROR\", explain briefly in Korean and propose a corrected plan.\n",
        "\n",
        "Return ONLY JSON:\n",
        "{\"final\": string}\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "id": "sw8H3LGvzX3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 1.2.3 Planner Function"
      ],
      "metadata": {
        "id": "PenpfQEozrHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re, json\n",
        "\n",
        "def extract_json(text: str) -> str:\n",
        "    \"\"\"LLM 응답에서 JSON만 뽑아낸다 (```json``` 코드블록/앞뒤 잡문 방어).\"\"\"\n",
        "    if text is None:\n",
        "        return \"\"\n",
        "    t = text.strip()\n",
        "\n",
        "    # 1) ```json ... ``` 블록 우선 추출\n",
        "    m = re.search(r\"```(?:json)?\\s*(\\{.*\\})\\s*```\", t, flags=re.DOTALL | re.IGNORECASE)\n",
        "    if m:\n",
        "        return m.group(1).strip()\n",
        "\n",
        "    # 2) 첫 { 부터 마지막 } 까지 잘라내기\n",
        "    start = t.find(\"{\")\n",
        "    end = t.rfind(\"}\")\n",
        "    if start != -1 and end != -1 and end > start:\n",
        "        return t[start:end+1].strip()\n",
        "\n",
        "    return t\n",
        "\n",
        "\n",
        "def make_plan(user_question: str) -> Plan:\n",
        "    resp = llm.invoke([PLANNER_SYS, HumanMessage(content=user_question)])\n",
        "    json_str = extract_json(resp.content)\n",
        "    data = json.loads(resp.content)\n",
        "    return Plan.model_validate(data)"
      ],
      "metadata": {
        "id": "t-nyfguEz0gM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 1.2.4 Executor Function"
      ],
      "metadata": {
        "id": "AcuUKrsWz5s0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _invoke_tool(alias: str, tool_input: str) -> Any:\n",
        "    tool = TOOL_REGISTRY[alias]\n",
        "\n",
        "    # TavilySearchResults는 보통 {\"query\": \"...\"} 형태가 안정적\n",
        "    if alias == \"search\":\n",
        "        try:\n",
        "            return tool.invoke({\"query\": tool_input})\n",
        "        except Exception:\n",
        "            return tool.invoke(tool_input)\n",
        "\n",
        "    # 나머지는 보통 문자열 입력\n",
        "    try:\n",
        "        return tool.invoke(tool_input)\n",
        "    except Exception:\n",
        "        return tool.run(tool_input)\n",
        "\n",
        "def execute_plan(plan: Plan) -> List[Dict[str, Any]]:\n",
        "    results = []\n",
        "    for idx, step in enumerate(plan.steps):\n",
        "        if step.tool == \"final_answer\":\n",
        "            results.append({\n",
        "                \"step_index\": idx,\n",
        "                \"tool\": step.tool,\n",
        "                \"input\": step.input,\n",
        "                \"output\": \"(final step - no tool execution)\"\n",
        "            })\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            out = _invoke_tool(step.tool, step.input)\n",
        "        except Exception as e:\n",
        "            out = f\"ERROR: {type(e).__name__}: {e}\"\n",
        "\n",
        "        results.append({\n",
        "            \"step_index\": idx,\n",
        "            \"tool\": step.tool,\n",
        "            \"input\": step.input,\n",
        "            \"output\": out\n",
        "        })\n",
        "    return results"
      ],
      "metadata": {
        "id": "qfW-aA72z-gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 1.2.5 Writer Function"
      ],
      "metadata": {
        "id": "NiSZry960Mh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def write_final(user_question: str, plan: Plan, tool_results: List[Dict[str, Any]]) -> str:\n",
        "    payload = {\n",
        "        \"user_question\": user_question,\n",
        "        \"plan\": plan.model_dump(),\n",
        "        \"tool_results\": tool_results,\n",
        "    }\n",
        "    resp = llm.invoke([WRITER_SYS, HumanMessage(content=json.dumps(payload, ensure_ascii=False))])\n",
        "    data = json.loads(resp.content)\n",
        "    return data[\"final\"]"
      ],
      "metadata": {
        "id": "TtXMsUhw0UR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 1.2.6 User Prompt"
      ],
      "metadata": {
        "id": "v0AP8eGEzgu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Plan-Then-Execute 패턴이 뭐고 ReAct랑 차이를 예시 포함해서 설명해줘. 최신 관점이면 search도 활용해.\""
      ],
      "metadata": {
        "id": "QMgx52ozzmva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 1.2.7 Result"
      ],
      "metadata": {
        "id": "367WrFnS0e17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_plan_then_execute(question: str) -> str:\n",
        "    # 1) Plan 생성\n",
        "    plan = make_plan(question)\n",
        "\n",
        "    # 2) 계획 실행 (결정론적)\n",
        "    tool_results = execute_plan(plan)\n",
        "\n",
        "    # 3) 최종 답변 생성\n",
        "    final = write_final(question, plan, tool_results)\n",
        "\n",
        "    return final\n",
        "\n",
        "answer = run_plan_then_execute(question)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ymeFl4g0kos",
        "outputId": "10d32d99-83bc-4ee1-d33f-1ca379077617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plan-Then-Execute 패턴과 ReAct 패턴은 AI 에이전트 설계에서 자주 사용되는 두 가지 접근 방식입니다.\n",
            "\n",
            "- **Plan-Then-Execute 패턴**:\n",
            "  - **설명**: 이 패턴은 먼저 계획을 세운 후 실행하는 방식으로, 작업을 두 단계로 나눕니다. 계획 단계에서 목표를 설정하고 필요한 자원을 할당한 후, 실행 단계에서 계획을 수행합니다.\n",
            "  - **특징**: 장기적인 목표 달성에 적합하며, 복잡한 작업이나 긴 시간 동안 지속되는 프로젝트에 유리합니다.\n",
            "  - **예시**: 대규모 소프트웨어 개발 프로젝트에서 먼저 전체 아키텍처를 설계한 후, 각 모듈을 개발하는 방식.\n",
            "\n",
            "- **ReAct 패턴**:\n",
            "  - **설명**: ReAct는 Reasoning and Acting의 약자로, 실시간으로 상황을 분석하고 즉각적으로 반응하는 방식입니다.\n",
            "  - **특징**: 빠른 의사결정과 즉각적인 반응이 필요한 상황에 적합하며, 단기적인 작업에 유리합니다.\n",
            "  - **예시**: 고객 서비스 챗봇이 사용자 질문에 즉각적으로 답변하는 경우.\n",
            "\n",
            "- **차이점**:\n",
            "  - Plan-Then-Execute는 계획과 실행을 명확히 구분하여 체계적이고 장기적인 접근을 취하는 반면, ReAct는 실시간으로 상황에 대응하여 빠른 반응을 중시합니다.\n",
            "  - Plan-Then-Execute는 복잡한 문제 해결에 강점을 가지며, ReAct는 신속한 문제 해결에 적합합니다.\n",
            "\n",
            "이 두 패턴은 각각의 장단점이 있어, 상황에 따라 적절한 패턴을 선택하는 것이 중요합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 1.2.8 Debuging"
      ],
      "metadata": {
        "id": "j-BkqhIj2bC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def debug_make_plan(user_question: str):\n",
        "    resp = llm.invoke([PLANNER_SYS, HumanMessage(content=user_question)])\n",
        "    print(\"=== RAW PLANNER OUTPUT ===\")\n",
        "    print(repr(resp.content))\n",
        "    return resp.content\n",
        "\n",
        "def debug_write_final(user_question: str, plan, tool_results):\n",
        "    payload = {\n",
        "        \"user_question\": user_question,\n",
        "        \"plan\": plan.model_dump(),\n",
        "        \"tool_results\": tool_results,\n",
        "    }\n",
        "    resp = llm.invoke([WRITER_SYS, HumanMessage(content=json.dumps(payload, ensure_ascii=False))])\n",
        "    print(\"=== RAW WRITER OUTPUT ===\")\n",
        "    print(repr(resp.content))\n",
        "    return resp.content\n"
      ],
      "metadata": {
        "id": "J3s6h4Oi2gzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Plan-Then-Execute 패턴이 뭐고 ReAct랑 차이를 예시 포함해서 설명해줘. 최신 관점이면 search도 활용해.\"\n",
        "\n",
        "plan = make_plan(question)\n",
        "tool_results = execute_plan(plan)\n",
        "\n",
        "raw_writer = debug_write_final(question, plan, tool_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "dOBkCcT_20kE",
        "outputId": "affa0d59-ed07-46f5-e998-a807da14f07c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4025445349.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtool_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecute_plan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mraw_writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdebug_write_final\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtool_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-766188638.py\u001b[0m in \u001b[0;36mdebug_write_final\u001b[0;34m(user_question, plan, tool_results)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;34m\"tool_results\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtool_results\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     }\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mWRITER_SYS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHumanMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ascii\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=== RAW WRITER OUTPUT ===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m             cast(\n\u001b[1;32m    401\u001b[0m                 \u001b[0;34m\"ChatGeneration\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                 self.generate_prompt(\n\u001b[0m\u001b[1;32m    403\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1119\u001b[0m     ) -> LLMResult:\n\u001b[1;32m   1120\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m                 results.append(\n\u001b[0;32m--> 931\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    932\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1231\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_from_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1233\u001b[0;31m             result = self._generate(\n\u001b[0m\u001b[1;32m   1234\u001b[0m                 \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m                 )\n\u001b[1;32m   1467\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1468\u001b[0;31m                 \u001b[0mraw_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_raw_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1469\u001b[0m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1470\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBadRequestError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_legacy_response.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"extra_headers\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextra_headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLegacyAPIResponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1190\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m   1191\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1192\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m   1193\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, content, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1295\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m         )\n\u001b[0;32m-> 1297\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1003\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1005\u001b[0;31m                 response = self._client.send(\n\u001b[0m\u001b[1;32m   1006\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m                     \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stream_response_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0mauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_request_auth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         response = self._send_handling_auth(\n\u001b[0m\u001b[1;32m    915\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m                 response = self._send_handling_redirects(\n\u001b[0m\u001b[1;32m    943\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m                     \u001b[0mfollow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_redirects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    977\u001b[0m                 \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_single_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSyncByteStream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    248\u001b[0m         )\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_connections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;31m# Return the response. Note that in this case we still have to manage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m                     \u001b[0;31m# Send the request on the assigned connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                     response = connection.handle_request(\n\u001b[0m\u001b[1;32m    237\u001b[0m                         \u001b[0mpool_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/connection.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNetworkStream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"response_closed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;31m# Sending the request...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    104\u001b[0m                     \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mtrailing_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 ) = self._receive_response_headers(**kwargs)\n\u001b[0m\u001b[1;32m    107\u001b[0m                 trace.return_value = (\n\u001b[1;32m    108\u001b[0m                     \u001b[0mhttp_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEED_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 data = self._network_stream.read(\n\u001b[0m\u001b[1;32m    218\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_NUM_BYTES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1230\u001b[0m                     \u001b[0;34m\"non-zero flags not allowed in calls to recv() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m                     self.__class__)\n\u001b[0;32m-> 1232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1233\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1103\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 1.3 Verbose"
      ],
      "metadata": {
        "id": "miRH6CEK5CyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_plan_then_execute_verbose(user_question: str, print_chars: int = 800):\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"USER QUESTION:\")\n",
        "    print(user_question)\n",
        "\n",
        "    # PLAN 단계\n",
        "    print(\"\\n\" + \"-\"*30 + \" PLANNING \" + \"-\"*30)\n",
        "\n",
        "    plan = make_plan(user_question)\n",
        "\n",
        "    print(\"GOAL:\", plan.goal)\n",
        "    print(\"\\nSTEPS:\")\n",
        "    for i, step in enumerate(plan.steps):\n",
        "        print(f\"  [{i}] tool={step.tool} | input={step.input}\")\n",
        "\n",
        "    # EXECUTE 단계\n",
        "    print(\"\\n\" + \"-\"*30 + \" EXECUTION \" + \"-\"*30)\n",
        "\n",
        "    tool_results = execute_plan(plan)\n",
        "\n",
        "    for r in tool_results:\n",
        "        print(f\"\\n[STEP {r['step_index']}] TOOL: {r['tool']}\")\n",
        "        print(\"INPUT:\", r[\"input\"])\n",
        "\n",
        "        out = r[\"output\"]\n",
        "        if not isinstance(out, str):\n",
        "            out = json.dumps(out, ensure_ascii=False)\n",
        "\n",
        "        print(\"OUTPUT (truncated):\")\n",
        "        print(out[:print_chars])\n",
        "\n",
        "    # WRITE 단계\n",
        "    print(\"\\n\" + \"-\"*30 + \" WRITING FINAL ANSWER \" + \"-\"*30)\n",
        "\n",
        "    final = write_final(user_question, plan, tool_results)\n",
        "\n",
        "    print(\"\\nFINAL ANSWER:\")\n",
        "    print(final)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "    return {\n",
        "        \"plan\": plan,\n",
        "        \"tool_results\": tool_results,\n",
        "        \"final\": final\n",
        "    }\n"
      ],
      "metadata": {
        "id": "SvNib6ry5F3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_plan_then_execute_verbose(question)"
      ],
      "metadata": {
        "id": "XYr-nYTd5S6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ㄴ 2. State Machine (FSM-based Orchestration)\n",
        "\n",
        "*    LLM은 **상태를 읽고 판단만** 함.\n",
        "*    LLM은 이제 **행동 주체**가 아니라 **State**를 평가하는 **Decision Function**으로만 쓰임"
      ],
      "metadata": {
        "id": "I1aqzgNKnmsM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "***Plan-Then-Execute 코드는 그대로 재사용***"
      ],
      "metadata": {
        "id": "fU2IPj-ZF1QJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 2.1 Description"
      ],
      "metadata": {
        "id": "toJNC1LRAvOE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Plan-Then-Execute**는 **'무엇을 할지'** 정의한 패턴이고, <br>\n",
        "**State Machine**은 **'그걸 어떻게 실행할지'** 를 정의하는 실행 모델이다."
      ],
      "metadata": {
        "id": "prhr271PE9iD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plan-Then-Execute**와 **State Machine**의 차이\n",
        "| Plan-Then-Execute       | State Machine                      |\n",
        "| ------------ | -------------------------- |\n",
        "| 함수가 흐름을 결정   | 상태가 흐름을 결정                 |\n",
        "| 코드가 다음 단계 호출 | Transition Logic이 다음 상태 선택 |\n",
        "| LLM = 작업 수행자 | LLM = 상태 판단자               |\n",
        "\n",
        "<br>\n",
        "\n",
        "**Plan-Then-Execute**에서의 역할이 **State Machine** 에서 아래와 같이 역할이 재배치됨\n",
        "\n",
        "| 구성요소     | State Machine에서 역할     |\n",
        "| -------- | ---------------------- |\n",
        "| Planner  | `PLAN` 상태에서 호출되는 액션    |\n",
        "| Executor | `EXECUTE` 상태에서 호출되는 액션 |\n",
        "| Writer   | `WRITE` 상태에서 호출되는 액션   |\n"
      ],
      "metadata": {
        "id": "MvVUr-9JAzTO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```javascript\n",
        "TaskState:\n",
        "    goal\n",
        "    progress\n",
        "    artifacts\n",
        "    failures\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "pL0qVChIodGp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 2.1 Code"
      ],
      "metadata": {
        "id": "V64eabvRHLUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 2.1.0 Utils"
      ],
      "metadata": {
        "id": "gWWbEnBOS6rM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ㄴ 2.1.0.1 Replan 전용 Planner 래퍼"
      ],
      "metadata": {
        "id": "khRXL2OnTlxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "import json\n",
        "\n",
        "# (옵션) Replan 상황에서만 사용할 system prompt (기존 PLANNER_SYS를 안 건드리려면 별도 생성)\n",
        "REPLAN_PLANNER_SYS = SystemMessage(content=\n",
        "\"\"\"You are a Planner for an LLM agent system.\n",
        "\n",
        "You MUST output ONLY valid JSON that matches this schema:\n",
        "{\n",
        "  \"goal\": string,\n",
        "  \"steps\": [\n",
        "    {\"tool\": \"wiki|search|calculator|docstore_lookup|final_answer\", \"input\": string}\n",
        "  ]\n",
        "}\n",
        "\n",
        "Rules:\n",
        "- Do NOT use markdown fences.\n",
        "- If the user asks for an example, include a step that gathers info (wiki/search) AND ensure the final_answer step requests a concrete example with explicit state transitions.\n",
        "- Prefer search over wiki when the term is ambiguous or not a Wikipedia entry (e.g., Plan-and-Execute in LLM agents).\n",
        "\n",
        "Return ONLY JSON.\n",
        "\"\"\")\n",
        "\n",
        "# structured output으로 스키마 강제\n",
        "replan_planner_llm = llm.with_structured_output(Plan)\n",
        "\n",
        "def make_plan_replan(user_question: str, fix_hint: str | None = None) -> Plan:\n",
        "    \"\"\"\n",
        "    Replan 전용 Planner.\n",
        "    - fix_hint를 별도 채널로 주어 plan 스키마가 깨질 확률을 낮춤\n",
        "    - structured_output(Plan)로 강제\n",
        "    \"\"\"\n",
        "    payload = {\n",
        "        \"user_question\": user_question,\n",
        "        \"fix_hint\": fix_hint or \"\"\n",
        "    }\n",
        "    return replan_planner_llm.invoke([\n",
        "        REPLAN_PLANNER_SYS,\n",
        "        HumanMessage(content=json.dumps(payload, ensure_ascii=False))\n",
        "    ])\n"
      ],
      "metadata": {
        "id": "TcZJzO3eTt6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ㄴ 2.1.0.2 State Machine 전용 Writer 래퍼"
      ],
      "metadata": {
        "id": "JYvtjMkXZLWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "import json\n",
        "\n",
        "STATE_WRITER_SYS = SystemMessage(content=\n",
        "\"\"\"You are a Writer that produces the final answer for the user in Korean.\n",
        "\n",
        "You receive a JSON payload with:\n",
        "- user_question\n",
        "- plan\n",
        "- tool_results\n",
        "\n",
        "Write a clear answer that MUST include:\n",
        "1) 정의: Plan-Then-Execute와 State Machine 실행 모델의 관계\n",
        "2) 차이: 단순 파이프라인(plan→execute→write) vs 상태기반 전이(phase-driven)\n",
        "3) 구체 예시 1개 (연구/로봇/업무 자동화 중 아무거나)\n",
        "4) 상태 전이 로그(한 줄): 순서대로 어떻게 되는지\n",
        "\n",
        "Constraints:\n",
        "- Keep it practical and concrete.\n",
        "- Do not mention internal tool names.\n",
        "- Output plain text (no JSON), Korean only.\n",
        "\"\"\")\n",
        "\n",
        "def write_final_state_machine(user_question: str, plan, tool_results) -> str:\n",
        "    payload = {\n",
        "        \"user_question\": user_question,\n",
        "        \"plan\": plan.model_dump(),\n",
        "        \"tool_results\": tool_results,\n",
        "    }\n",
        "    resp = llm.invoke([\n",
        "        STATE_WRITER_SYS,\n",
        "        HumanMessage(content=json.dumps(payload, ensure_ascii=False))\n",
        "    ])\n",
        "    return (resp.content or \"\").strip()\n"
      ],
      "metadata": {
        "id": "uUS1ZkozZXeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 2.1.1 State Definition"
      ],
      "metadata": {
        "id": "QqN4ISemHT8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, Literal, List, Dict, Any, Optional\n",
        "\n",
        "Phase = Literal[\"PLAN\", \"EXECUTE\", \"VALIDATE\", \"WRITE\", \"DONE\", \"ERROR\"]\n",
        "\n",
        "class AgentState(TypedDict, total=False):\n",
        "    # inputs\n",
        "    user_question: str\n",
        "\n",
        "    # state machine\n",
        "    phase: Phase\n",
        "    error: Optional[str]\n",
        "\n",
        "    # artifacts (persisted across phases)\n",
        "    plan: Any                 # Plan (pydantic model)\n",
        "    tool_results: List[Dict[str, Any]]\n",
        "    final: str\n",
        "\n",
        "    # replan control\n",
        "    replan_count: int\n",
        "    max_replans: int\n",
        "\n",
        "    fix_hint: str\n",
        "\n",
        "    # debugging / tracing\n",
        "    trace: List[Dict[str, Any]]"
      ],
      "metadata": {
        "id": "G7KHDxPFHn-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 2.1.2 Validate Contract\n",
        "> 지금까지 **실행한 결과**가 **다음 단계**로 넘어가도 될 만큼 **\"신뢰 가능한 상태인가\"** 를 판정\n",
        "\n",
        "```javascript\n",
        "EXECUTE → VALIDATE → (OK) → WRITE\n",
        "                   → (FAIL) → REPLAN\n",
        "```"
      ],
      "metadata": {
        "id": "PJw5R3DBOy4l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### ㄴ 2.1.2.1 Validate Schema"
      ],
      "metadata": {
        "id": "b2SMxyZSPTme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel\n",
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "import json\n",
        "\n",
        "class ValidationOut(BaseModel):\n",
        "    ok: bool\n",
        "    reason: str\n",
        "    fix_hint: str  # replan을 한다면 planner에게 줄 힌트(짧게)"
      ],
      "metadata": {
        "id": "QoNQQJlIPytN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### ㄴ 2.1.2.2 Validate System Prompt"
      ],
      "metadata": {
        "id": "Ui3PT03CPH4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDATOR_SYS = SystemMessage(content=\n",
        "\"\"\"You are a Validator for an LLM agent.\n",
        "\n",
        "Input JSON contains:\n",
        "- user_question\n",
        "- plan\n",
        "- tool_results\n",
        "\n",
        "Decide if the information is sufficient to write a good answer.\n",
        "\n",
        "Mark ok=false ONLY if:\n",
        "- the retrieved content is clearly about the wrong concept (e.g., database query plan),\n",
        "- or there is no material to produce at least one concrete example and a state-transition trace.\n",
        "\n",
        "Otherwise ok=true.\n",
        "\n",
        "Return ONLY JSON:\n",
        "{\"ok\": boolean, \"reason\": string (Korean), \"fix_hint\": string (Korean)}\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "7FnpRUn_PN5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 2.1.3 FSM Execution Actions\n",
        "> ***Plan-Then-Execute에서 사용한 함수 재사용***"
      ],
      "metadata": {
        "id": "hShGJ81oIdxe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ㄴ 2.1.3.1 Plan Action"
      ],
      "metadata": {
        "id": "WbLUjoo3Igwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def action_plan(state: AgentState) -> AgentState:\n",
        "    q = state[\"user_question\"]\n",
        "    fix_hint = (state.get(\"fix_hint\") or \"\").strip()\n",
        "\n",
        "    try:\n",
        "        # replan일 때만 replan planner 사용\n",
        "        if fix_hint:\n",
        "            plan = make_plan_replan(q, fix_hint)\n",
        "            used_replan_planner = True\n",
        "        else:\n",
        "            plan = make_plan(q)  # 기존 core planner\n",
        "            used_replan_planner = False\n",
        "\n",
        "        state[\"plan\"] = plan\n",
        "        state[\"trace\"].append({\n",
        "            \"phase\": \"PLAN\",\n",
        "            \"ok\": True,\n",
        "            \"used_replan_planner\": used_replan_planner,\n",
        "            \"steps\": [s.model_dump() for s in plan.steps],\n",
        "        })\n",
        "\n",
        "        state[\"phase\"] = \"EXECUTE\"\n",
        "        state[\"fix_hint\"] = \"\"  # 힌트 소모\n",
        "        return state\n",
        "\n",
        "    except Exception as e:\n",
        "        state[\"error\"] = f\"PLAN_ERROR: {type(e).__name__}: {e}\"\n",
        "        state[\"trace\"].append({\"phase\": \"PLAN\", \"ok\": False, \"error\": state[\"error\"]})\n",
        "        state[\"phase\"] = \"ERROR\"\n",
        "        return state\n"
      ],
      "metadata": {
        "id": "N4ZCT8AbIkxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ㄴ 2.1.3.2 Execute Action"
      ],
      "metadata": {
        "id": "GrXF0OjnIyEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def action_execute(state: AgentState) -> AgentState:\n",
        "    try:\n",
        "        plan = state[\"plan\"]\n",
        "        tool_results = execute_plan(plan)  # Plan-Then-Execute 에서의 Executer 함수\n",
        "        state[\"tool_results\"] = tool_results\n",
        "        state[\"trace\"].append({\"phase\":\"EXECUTE\", \"ok\": True, \"num_results\": len(tool_results)})\n",
        "        state[\"phase\"] = \"VALIDATE\"\n",
        "    except Exception as e:\n",
        "        state[\"error\"] = f\"EXECUTE_ERROR: {type(e).__name__}: {e}\"\n",
        "        state[\"trace\"].append({\"phase\":\"EXECUTE\", \"ok\": False, \"error\": state[\"error\"]})\n",
        "        state[\"phase\"] = \"ERROR\"\n",
        "    return state"
      ],
      "metadata": {
        "id": "0u0cPzNFI3eF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ㄴ 2.1.3.3 Write Action"
      ],
      "metadata": {
        "id": "xFfjh7x9JWo9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def action_write(state: AgentState) -> AgentState:\n",
        "    try:\n",
        "        q = state[\"user_question\"]\n",
        "        plan = state[\"plan\"]\n",
        "        tool_results = state.get(\"tool_results\", [])\n",
        "        final = write_final_state_machine(q, plan, tool_results)\n",
        "        state[\"final\"] = final\n",
        "        state[\"trace\"].append({\"phase\":\"WRITE\", \"ok\": True, \"final_chars\": len(final)})\n",
        "        state[\"phase\"] = \"DONE\"\n",
        "    except Exception as e:\n",
        "        state[\"error\"] = f\"WRITE_ERROR: {type(e).__name__}: {e}\"\n",
        "        state[\"trace\"].append({\"phase\":\"WRITE\", \"ok\": False, \"error\": state[\"error\"]})\n",
        "        state[\"phase\"] = \"ERROR\"\n",
        "    return state"
      ],
      "metadata": {
        "id": "1ZVf2RUoJbKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ㄴ 2.1.3.4 Validate Action"
      ],
      "metadata": {
        "id": "58KsSwjlQ3Wk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def action_validate(state: AgentState) -> AgentState:\n",
        "    try:\n",
        "        payload = {\n",
        "            \"user_question\": state[\"user_question\"],\n",
        "            \"plan\": state[\"plan\"].model_dump() if \"plan\" in state else None,\n",
        "            \"tool_results\": state.get(\"tool_results\", []),\n",
        "        }\n",
        "        # 구조화 출력(권장): JSON 깨짐 방지\n",
        "        validator_llm = llm.with_structured_output(ValidationOut)\n",
        "\n",
        "        verdict = validator_llm.invoke([\n",
        "            VALIDATOR_SYS,\n",
        "            HumanMessage(content=json.dumps(payload, ensure_ascii=False))\n",
        "        ])\n",
        "\n",
        "        state[\"trace\"].append({\n",
        "            \"phase\": \"VALIDATE\",\n",
        "            \"ok\": True,\n",
        "            \"verdict\": verdict.model_dump()\n",
        "        })\n",
        "\n",
        "        if verdict.ok:\n",
        "            state[\"phase\"] = \"WRITE\"\n",
        "        else:\n",
        "            # replan 제한\n",
        "            state[\"replan_count\"] = state.get(\"replan_count\", 0) + 1\n",
        "            if state[\"replan_count\"] > state.get(\"max_replans\", 2):\n",
        "                state[\"error\"] = f\"VALIDATION_FAILED_MAX_REPLANS: {verdict.reason}\"\n",
        "                state[\"phase\"] = \"ERROR\"\n",
        "            else:\n",
        "                # planner에게 힌트 남겨두기\n",
        "                state[\"fix_hint\"] = verdict.fix_hint\n",
        "                state[\"trace\"].append({\n",
        "                    \"phase\": \"REPLAN_TRIGGER\",\n",
        "                    \"replan_count\": state[\"replan_count\"],\n",
        "                    \"reason\": verdict.reason,\n",
        "                    \"fix_hint\": verdict.fix_hint\n",
        "                })\n",
        "                # 힌트를 질문에 덧붙여 재계획 유도 (가장 단순한 방식)\n",
        "                state[\"user_question\"] = (\n",
        "                    state[\"user_question\"]\n",
        "                    + \"\\n\\n[Validator Hint]\\n\"\n",
        "                    + verdict.fix_hint\n",
        "                )\n",
        "                state[\"phase\"] = \"PLAN\"\n",
        "\n",
        "    except Exception as e:\n",
        "        state[\"error\"] = f\"VALIDATE_ERROR: {type(e).__name__}: {e}\"\n",
        "        state[\"trace\"].append({\"phase\":\"VALIDATE\", \"ok\": False, \"error\": state[\"error\"]})\n",
        "        state[\"phase\"] = \"ERROR\"\n",
        "\n",
        "    return state\n"
      ],
      "metadata": {
        "id": "VZqDntlFQ9Fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 2.1.4 Transition Function (상태 전이 로직)"
      ],
      "metadata": {
        "id": "VOMP0h8sJnNR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transition(state: AgentState) -> AgentState:\n",
        "    phase = state[\"phase\"]\n",
        "\n",
        "    if phase == \"PLAN\":\n",
        "        return action_plan(state)\n",
        "    elif phase == \"EXECUTE\":\n",
        "        return action_execute(state)\n",
        "    elif phase == \"VALIDATE\":\n",
        "        return action_validate(state)\n",
        "    elif phase == \"WRITE\":\n",
        "        return action_write(state)\n",
        "    elif phase in (\"DONE\", \"ERROR\"):\n",
        "        return state\n",
        "    else:\n",
        "        state[\"error\"] = f\"UNKNOWN_PHASE: {phase}\"\n",
        "        state[\"phase\"] = \"ERROR\"\n",
        "        return state"
      ],
      "metadata": {
        "id": "06zmFVMYJ0d1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 2.1.5 User Prompt"
      ],
      "metadata": {
        "id": "w8aAiDnmKUL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"State Machine 실행 모델로 Plan-Then-Execute를 돌린다는 게 무슨 의미인지 예시로 설명해줘.\""
      ],
      "metadata": {
        "id": "5ICb1jXeKSVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 2.1.6 Result"
      ],
      "metadata": {
        "id": "LyVKLZgsJ8jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_state_machine(question: str) -> str:\n",
        "    state: AgentState = {\n",
        "        \"user_question\": question,\n",
        "        \"phase\": \"PLAN\",\n",
        "        \"error\": None,\n",
        "        \"trace\": [],\n",
        "        \"replan_count\": 0,\n",
        "        \"max_replans\": 2,\n",
        "        \"fix_hint\": \"\",\n",
        "    }\n",
        "\n",
        "    while state[\"phase\"] not in (\"DONE\", \"ERROR\"):\n",
        "        state = transition(state)\n",
        "\n",
        "    if state[\"phase\"] == \"DONE\":\n",
        "        return state[\"final\"]\n",
        "\n",
        "    raise RuntimeError(state.get(\"error\", \"Unknown error\"))"
      ],
      "metadata": {
        "id": "JDel-JvyKBAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(run_state_machine(question))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUQojTKmKBpc",
        "outputId": "bf3bfc24-a7a3-4a00-c2fa-0a57b9d7c871"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1) **정의**: Plan-Then-Execute 모델은 계획을 세운 후 이를 실행하는 두 단계로 구성된 접근 방식입니다. 이 모델을 상태 기계(State Machine)와 결합하면, 계획 단계에서 설정된 초기 상태를 기반으로 상태 기계가 실행 단계에서 다양한 상태 전이를 통해 작업을 수행합니다. 상태 기계는 외부 이벤트에 따라 상태를 전이하며, 각 상태에서 수행할 작업을 결정합니다.\n",
            "\n",
            "2) **차이**: 단순 파이프라인 방식에서는 계획(plan) 단계에서 실행(execute) 단계로 넘어가고, 그 결과를 작성(write)하는 일련의 고정된 절차를 따릅니다. 반면, 상태기반 전이 방식에서는 각 단계가 상태에 따라 유동적으로 전이됩니다. 즉, 상태 기계는 각 상태에서 발생하는 이벤트에 따라 다음 상태로 전이하며, 이 과정에서 필요한 작업을 수행합니다. 이는 복잡한 작업을 보다 유연하게 처리할 수 있게 해줍니다.\n",
            "\n",
            "3) **구체 예시**: 로봇 청소기의 경우를 생각해봅시다. 로봇 청소기는 방 청소 계획을 세운 후, 상태 기계를 통해 이를 실행합니다. 초기 상태는 '대기' 상태로 시작하며, '청소 시작' 이벤트가 발생하면 '청소 중' 상태로 전이됩니다. 청소 중에 장애물을 만나면 '회피' 상태로 전이하여 장애물을 피하고, 다시 '청소 중' 상태로 돌아갑니다. 모든 청소가 완료되면 '완료' 상태로 전이하여 작업을 종료합니다.\n",
            "\n",
            "4) **상태 전이 로그**: \n",
            "   - 대기 → 청소 시작 → 청소 중 → 장애물 회피 → 청소 중 → 완료\n",
            "\n",
            "이와 같이 상태 기계는 각 상태에서의 이벤트에 따라 유연하게 전이하며, 복잡한 작업을 효율적으로 수행할 수 있습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 2.2 Verbose"
      ],
      "metadata": {
        "id": "fe5KwC1lK0eq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def run_state_machine_verbose(question: str, print_chars: int = 600, max_steps: int = 20) -> AgentState:\n",
        "    state: AgentState = {\n",
        "        \"user_question\": question,\n",
        "        \"phase\": \"PLAN\",\n",
        "        \"error\": None,\n",
        "        \"trace\": [],\n",
        "        \"replan_count\": 0,\n",
        "        \"max_replans\": 2,\n",
        "        \"fix_hint\": \"\",\n",
        "    }\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"USER QUESTION:\")\n",
        "    print(question)\n",
        "\n",
        "    steps = 0\n",
        "    while state[\"phase\"] not in (\"DONE\", \"ERROR\"):\n",
        "        steps += 1\n",
        "        if steps > max_steps:\n",
        "            state[\"error\"] = \"MAX_STEPS_EXCEEDED\"\n",
        "            state[\"phase\"] = \"ERROR\"\n",
        "            break\n",
        "\n",
        "        print(\"\\n\" + \"-\"*28 + f\" PHASE: {state['phase']} \" + \"-\"*28)\n",
        "        state = transition(state)\n",
        "\n",
        "        if state[\"phase\"] == \"EXECUTE\" and \"plan\" in state:\n",
        "            print(\"Plan ready. Steps:\")\n",
        "            for i, s in enumerate(state[\"plan\"].steps):\n",
        "                print(f\"  [{i}] {s.tool} :: {s.input}\")\n",
        "\n",
        "        if state[\"phase\"] == \"VALIDATE\":\n",
        "            print(f\"Executed {len(state.get('tool_results', []))} steps. (Next: VALIDATE)\")\n",
        "\n",
        "        if state[\"phase\"] == \"PLAN\" and state.get(\"replan_count\", 0) > 0:\n",
        "            print(f\"Replanning... (count={state['replan_count']}/{state['max_replans']})\")\n",
        "\n",
        "        if state[\"phase\"] == \"WRITE\":\n",
        "            print(\"Validation passed. Moving to WRITE.\")\n",
        "\n",
        "    print(\"\\n\" + \"-\"*28 + f\" PHASE: {state['phase']} \" + \"-\"*28)\n",
        "\n",
        "    if state[\"phase\"] == \"DONE\":\n",
        "        print(\"\\nFINAL:\")\n",
        "        print(state[\"final\"])\n",
        "    else:\n",
        "        print(\"\\nERROR:\")\n",
        "        print(state.get(\"error\"))\n",
        "\n",
        "    print(\"\\nTRACE (last 6):\")\n",
        "    trace = state.get(\"trace\", [])\n",
        "    print(json.dumps(trace[-6:], ensure_ascii=False, indent=2))\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    return state"
      ],
      "metadata": {
        "id": "luJETO-VK-bq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_state_machine_verbose(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVfnnnCXLCRz",
        "outputId": "21a117d2-878c-4957-d3ae-01d3014d84c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "USER QUESTION:\n",
            "State Machine 실행 모델로 Plan-Then-Execute를 돌린다는 게 무슨 의미인지 예시로 설명해줘.\n",
            "\n",
            "---------------------------- PHASE: PLAN ----------------------------\n",
            "Plan ready. Steps:\n",
            "  [0] wiki :: State machine\n",
            "  [1] wiki :: Plan-Then-Execute model\n",
            "  [2] final_answer :: A State Machine execution model involves defining a set of states and transitions between those states based on inputs or events. In a Plan-Then-Execute model, a plan is created first, detailing the sequence of actions or states needed to achieve a goal, and then this plan is executed step-by-step. For example, consider a robot vacuum cleaner: the planning phase involves mapping out the room and determining the optimal path to clean it, while the execution phase involves the vacuum following this path, transitioning between states like 'moving', 'cleaning', and 'charging' based on its current position and battery level.\n",
            "\n",
            "---------------------------- PHASE: EXECUTE ----------------------------\n",
            "Executed 3 steps. (Next: VALIDATE)\n",
            "\n",
            "---------------------------- PHASE: VALIDATE ----------------------------\n",
            "Replanning... (count=1/2)\n",
            "\n",
            "---------------------------- PHASE: PLAN ----------------------------\n",
            "Plan ready. Steps:\n",
            "  [0] search :: Plan-Then-Execute model in robotics or AI\n",
            "  [1] final_answer :: Using the information gathered, explain what it means to run a Plan-Then-Execute model as a state machine. Provide a concrete example, such as in robotics or AI, showing explicit state transitions.\n",
            "\n",
            "---------------------------- PHASE: EXECUTE ----------------------------\n",
            "Executed 2 steps. (Next: VALIDATE)\n",
            "\n",
            "---------------------------- PHASE: VALIDATE ----------------------------\n",
            "Validation passed. Moving to WRITE.\n",
            "\n",
            "---------------------------- PHASE: WRITE ----------------------------\n",
            "\n",
            "---------------------------- PHASE: DONE ----------------------------\n",
            "\n",
            "FINAL:\n",
            "1) **정의**: Plan-Then-Execute 모델은 전략적 의사결정(계획)과 전술적 작업 수행(실행)을 분리하는 아키텍처적 패러다임입니다. 이 모델을 상태 기계(State Machine)로 실행한다는 것은, 각 단계가 명확한 상태로 정의되고, 상태 전이에 따라 계획이 실행된다는 것을 의미합니다. 상태 기계는 각 상태에서 특정 조건이 충족되면 다음 상태로 전이하는 방식으로 작동합니다.\n",
            "\n",
            "2) **차이**: 단순 파이프라인 방식에서는 계획, 실행, 결과 작성이 순차적으로 진행됩니다. 반면, 상태 기반 전이 방식에서는 각 단계가 상태로 정의되고, 조건에 따라 상태가 전이됩니다. 이는 계획 단계에서의 오류 수정이나 환경 변화에 대한 적응을 용이하게 합니다.\n",
            "\n",
            "3) **구체 예시**: 로봇 공학에서의 예를 들어보겠습니다. 로봇이 차를 만드는 작업을 수행한다고 가정할 때, Plan-Then-Execute 모델은 먼저 차체 조립, 엔진 설치, 도장 등의 계획을 세웁니다. 각 작업은 상태로 정의되고, 로봇은 차체 조립 상태에서 엔진 설치 상태로 전이합니다. 만약 도중에 부품이 부족하다면, 상태 기계는 오류 상태로 전이하여 문제를 해결한 후 다시 정상 상태로 돌아옵니다.\n",
            "\n",
            "4) **상태 전이 로그**: \n",
            "   - 초기 상태: 계획 수립\n",
            "   - 상태 전이: 차체 조립 → 엔진 설치 → 도장\n",
            "   - 오류 발생 시: 엔진 설치 → 오류 상태 → 문제 해결 → 엔진 설치\n",
            "   - 최종 상태: 작업 완료\n",
            "\n",
            "이러한 방식은 로봇이 복잡한 작업을 수행할 때 유연성과 적응성을 제공합니다.\n",
            "\n",
            "TRACE (last 6):\n",
            "[\n",
            "  {\n",
            "    \"phase\": \"VALIDATE\",\n",
            "    \"ok\": true,\n",
            "    \"verdict\": {\n",
            "      \"ok\": false,\n",
            "      \"reason\": \"Plan-Then-Execute 모델에 대한 설명이 잘못된 개념인 데이터베이스 쿼리 계획으로 제공되었습니다.\",\n",
            "      \"fix_hint\": \"Plan-Then-Execute 모델에 대한 올바른 설명을 찾기 위해 추가적인 자료 조사를 수행하세요. 예를 들어, 로봇 공학이나 인공지능에서의 Plan-Then-Execute 모델에 대한 설명을 찾아보세요.\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"phase\": \"REPLAN_TRIGGER\",\n",
            "    \"replan_count\": 1,\n",
            "    \"reason\": \"Plan-Then-Execute 모델에 대한 설명이 잘못된 개념인 데이터베이스 쿼리 계획으로 제공되었습니다.\",\n",
            "    \"fix_hint\": \"Plan-Then-Execute 모델에 대한 올바른 설명을 찾기 위해 추가적인 자료 조사를 수행하세요. 예를 들어, 로봇 공학이나 인공지능에서의 Plan-Then-Execute 모델에 대한 설명을 찾아보세요.\"\n",
            "  },\n",
            "  {\n",
            "    \"phase\": \"PLAN\",\n",
            "    \"ok\": true,\n",
            "    \"used_replan_planner\": true,\n",
            "    \"steps\": [\n",
            "      {\n",
            "        \"tool\": \"search\",\n",
            "        \"input\": \"Plan-Then-Execute model in robotics or AI\"\n",
            "      },\n",
            "      {\n",
            "        \"tool\": \"final_answer\",\n",
            "        \"input\": \"Using the information gathered, explain what it means to run a Plan-Then-Execute model as a state machine. Provide a concrete example, such as in robotics or AI, showing explicit state transitions.\"\n",
            "      }\n",
            "    ]\n",
            "  },\n",
            "  {\n",
            "    \"phase\": \"EXECUTE\",\n",
            "    \"ok\": true,\n",
            "    \"num_results\": 2\n",
            "  },\n",
            "  {\n",
            "    \"phase\": \"VALIDATE\",\n",
            "    \"ok\": true,\n",
            "    \"verdict\": {\n",
            "      \"ok\": true,\n",
            "      \"reason\": \"검색 결과는 Plan-Then-Execute 모델의 개념과 이를 로봇 공학 및 AI에서 어떻게 사용하는지에 대한 설명을 포함하고 있습니다. 특히, 계획과 실행을 분리하여 작업을 수행하는 방법과 이로 인해 얻을 수 있는 이점에 대해 설명하고 있습니다. 이를 통해 Plan-Then-Execute 모델을 상태 기계로 실행하는 의미를 설명할 수 있는 충분한 정보가 제공되었습니다.\",\n",
            "      \"fix_hint\": \"현재 제공된 정보는 Plan-Then-Execute 모델의 개념과 예시를 설명하기에 충분합니다. 추가적인 자료 조사는 필요하지 않습니다.\"\n",
            "    }\n",
            "  },\n",
            "  {\n",
            "    \"phase\": \"WRITE\",\n",
            "    \"ok\": true,\n",
            "    \"final_chars\": 776\n",
            "  }\n",
            "]\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'user_question': 'State Machine 실행 모델로 Plan-Then-Execute를 돌린다는 게 무슨 의미인지 예시로 설명해줘.\\n\\n[Validator Hint]\\nPlan-Then-Execute 모델에 대한 올바른 설명을 찾기 위해 추가적인 자료 조사를 수행하세요. 예를 들어, 로봇 공학이나 인공지능에서의 Plan-Then-Execute 모델에 대한 설명을 찾아보세요.',\n",
              " 'phase': 'DONE',\n",
              " 'error': None,\n",
              " 'trace': [{'phase': 'PLAN',\n",
              "   'ok': True,\n",
              "   'used_replan_planner': False,\n",
              "   'steps': [{'tool': 'wiki', 'input': 'State machine'},\n",
              "    {'tool': 'wiki', 'input': 'Plan-Then-Execute model'},\n",
              "    {'tool': 'final_answer',\n",
              "     'input': \"A State Machine execution model involves defining a set of states and transitions between those states based on inputs or events. In a Plan-Then-Execute model, a plan is created first, detailing the sequence of actions or states needed to achieve a goal, and then this plan is executed step-by-step. For example, consider a robot vacuum cleaner: the planning phase involves mapping out the room and determining the optimal path to clean it, while the execution phase involves the vacuum following this path, transitioning between states like 'moving', 'cleaning', and 'charging' based on its current position and battery level.\"}]},\n",
              "  {'phase': 'EXECUTE', 'ok': True, 'num_results': 3},\n",
              "  {'phase': 'VALIDATE',\n",
              "   'ok': True,\n",
              "   'verdict': {'ok': False,\n",
              "    'reason': 'Plan-Then-Execute 모델에 대한 설명이 잘못된 개념인 데이터베이스 쿼리 계획으로 제공되었습니다.',\n",
              "    'fix_hint': 'Plan-Then-Execute 모델에 대한 올바른 설명을 찾기 위해 추가적인 자료 조사를 수행하세요. 예를 들어, 로봇 공학이나 인공지능에서의 Plan-Then-Execute 모델에 대한 설명을 찾아보세요.'}},\n",
              "  {'phase': 'REPLAN_TRIGGER',\n",
              "   'replan_count': 1,\n",
              "   'reason': 'Plan-Then-Execute 모델에 대한 설명이 잘못된 개념인 데이터베이스 쿼리 계획으로 제공되었습니다.',\n",
              "   'fix_hint': 'Plan-Then-Execute 모델에 대한 올바른 설명을 찾기 위해 추가적인 자료 조사를 수행하세요. 예를 들어, 로봇 공학이나 인공지능에서의 Plan-Then-Execute 모델에 대한 설명을 찾아보세요.'},\n",
              "  {'phase': 'PLAN',\n",
              "   'ok': True,\n",
              "   'used_replan_planner': True,\n",
              "   'steps': [{'tool': 'search',\n",
              "     'input': 'Plan-Then-Execute model in robotics or AI'},\n",
              "    {'tool': 'final_answer',\n",
              "     'input': 'Using the information gathered, explain what it means to run a Plan-Then-Execute model as a state machine. Provide a concrete example, such as in robotics or AI, showing explicit state transitions.'}]},\n",
              "  {'phase': 'EXECUTE', 'ok': True, 'num_results': 2},\n",
              "  {'phase': 'VALIDATE',\n",
              "   'ok': True,\n",
              "   'verdict': {'ok': True,\n",
              "    'reason': '검색 결과는 Plan-Then-Execute 모델의 개념과 이를 로봇 공학 및 AI에서 어떻게 사용하는지에 대한 설명을 포함하고 있습니다. 특히, 계획과 실행을 분리하여 작업을 수행하는 방법과 이로 인해 얻을 수 있는 이점에 대해 설명하고 있습니다. 이를 통해 Plan-Then-Execute 모델을 상태 기계로 실행하는 의미를 설명할 수 있는 충분한 정보가 제공되었습니다.',\n",
              "    'fix_hint': '현재 제공된 정보는 Plan-Then-Execute 모델의 개념과 예시를 설명하기에 충분합니다. 추가적인 자료 조사는 필요하지 않습니다.'}},\n",
              "  {'phase': 'WRITE', 'ok': True, 'final_chars': 776}],\n",
              " 'replan_count': 1,\n",
              " 'max_replans': 2,\n",
              " 'fix_hint': '',\n",
              " 'plan': Plan(goal='Explain the meaning of running a Plan-Then-Execute model as a state machine with an example.', steps=[Step(tool='search', input='Plan-Then-Execute model in robotics or AI'), Step(tool='final_answer', input='Using the information gathered, explain what it means to run a Plan-Then-Execute model as a state machine. Provide a concrete example, such as in robotics or AI, showing explicit state transitions.')]),\n",
              " 'tool_results': [{'step_index': 0,\n",
              "   'tool': 'search',\n",
              "   'input': 'Plan-Then-Execute model in robotics or AI',\n",
              "   'output': [{'title': 'Plan-and-Execute Coordination Model - Emergent Mind',\n",
              "     'url': 'https://www.emergentmind.com/topics/plan-and-execute-coordination-model',\n",
              "     'content': 'Contemporary instantiations, such as LLM-driven multi-agent systems (Hunt et al., 2024), smart contract auditing (Wei et al., 21 May 2025), and embodied agent cooperation (Liu et al., 2024), implement horizontal separation (planner, executor, supervisor) and vertical cycles (plan, act, monitor, replan). In model-based hierarchical robotics (Ma et al., 2018), temporal planning networks (e.g., Simple Temporal Networks, STNs) bridge discrete task-level planning and continuous motion-level execution. [...] A plan-and-execute coordination model is an architectural and algorithmic paradigm separating strategic decision-making (“planning”) from tactical task completion (“execution”), with explicit mechanisms for assigning, refining, and monitoring plans and their execution among agents or systems. This separation enables greater transparency, adaptivity, and diagnostic capability in multi-agent, human-robot, or autonomous settings, compared to reactive or monolithic agent architectures. Modern approaches draw on argumentation frameworks, formal belief hierarchies, hierarchical temporal planning, and closed-loop feedback to ensure robust, context-aware behavior under uncertainty, partial observability, and heterogeneous agent ability. [...] For example, Bayesian and epistemic methods define planning as a mapping from observations or belief states to a joint strategy, which is then executed under (potentially partial) common knowledge conditions. In multi-robot coordination, joint plans may be encoded as temporally-constrained graphs or STNs, explicitly capturing spatial, timing, and kinematic feasibility (Ma et al., 2018). Adaptive plan execution leverages model-derived slack, partial-order schedules, or DA (Dynamic Allocation)-based commit-dispatch policies to absorb minor deviations and adapt to stochastic state evolution without exhaustive global replanning (Lima et al., 2020, Ma et al., 2018).',\n",
              "     'score': 0.99992037},\n",
              "    {'title': 'Plan and Execute: AI Agents Architecture | by Shubham Kumar Singh',\n",
              "     'url': 'https://medium.com/@shubham.ksingh.cer14/plan-and-execute-ai-agents-architecture-f6c60b5b9598',\n",
              "     'content': '# Generates a comprehensive plan for the task await \"messages\" \"user\" \"input\" return \"plan\"\\n``` [...] 1. Planner, which prompts an LLM to generate a multi-step plan to complete a large task.\\n2. Executor(s), which accept the user query and a step in the plan and invoke 1 or more tools to complete that task.\\n\\n### Workflow:\\n\\n1. The planner generates a multi-step plan.\\n2. Executors tackle each step, invoking tools as needed.\\n3. If something goes wrong, the system replans.\\n\\n## Building a Simple Plan-and-Execute Agent\\n\\nHere’s how you can build your own Plan-and-Execute agent using Python and LangGraph:\\n\\n### Planner\\n\\nInitiate the planner and define the planning step [...] 1. First of all, they can execute multi-step workflow faster, since the larger agent doesn’t need to be consulted after each action.\\n2. Second, they offer cost savings over ReAct agents. If LLM calls are used for sub-tasks, they typically can be made to smaller, domain-specific models.\\n3. Third, they can perform better overall (in terms of task completions rate and quality) by forcing the planner to explicitly “think through” all the steps required to accomplish the entire task.\\n\\n### What is the Plan-and-Execute Architecture?\\n\\nThe Plan-and-Execute architecture consists of two basic components:',\n",
              "     'score': 0.9997508},\n",
              "    {'title': 'Plan-then-Execute – An Architectural Pattern for R... - SAP Community',\n",
              "     'url': 'https://community.sap.com/t5/security-and-compliance-blog-posts/plan-then-execute-an-architectural-pattern-for-responsible-agentic-ai/ba-p/14239753',\n",
              "     'content': 'Let’s update the diagram  from part 1 with the P-t-E pattern. The Chat Agent is the interface to the Buyer and passes the user’s instruction as part of the prompt to the Planner (after sensible input sanitation) to prepare an actionable plan for the Executor.\\n\\nUpdated diagram of the Discount agentic AI system from part 1 with the Plan-then-Execute pattern, including a Planner and Executor providing greater resilience to misalignment and errors\\n\\nConceivably, the plan looks like this for our example scenario: [...] The core idea is to separate strategic planning from the tactical execution of Agentic tasks. This allows better control over the behavior of the agentic systems and increases resilience against errors and misalignment. In the P-t-E pattern, the Planner establishes a plan of steps to meet the user’s instructions. Those instructions are passed one-by-one to an Executor that completes each task with the help of tools and other agents defined in the plan.\\n\\n# Plan-then-Execute\\n\\n## Planner and Executor [...] The Executor executes this pre-determined plan one task at the time, invoking the tools APIs or other agents to accomplish each subtask – ideally already specified by the Planner. The level of sophistication may differ by the criticality of the user scenario or agentic AI system. But in general, this means that the Executor can be implemented with a more cost-efficient, smaller, and faster LLM, or even a deterministic code component that directly executes Planner instructions.',\n",
              "     'score': 0.9997241},\n",
              "    {'title': 'Plan-Then-Execute: An Empirical Study of User Trust and Team ...',\n",
              "     'url': 'https://arxiv.org/html/2502.01390v1',\n",
              "     'content': 'In our work, we address this research gap and adopt LLM agents to assist humans in everyday tasks by following a plan-then-execute workflow (Wang et al., 2023b). First, the LLM agent generates a step-wise plan formulated with a hierarchical structure. Then, the LLM agent executes the generated plan by transforming it into a sequence of actions (leveraging external toolkits). The benefits of such a plan-then-execute framing are three-fold: (1) Compared to a dynamic process where planning and execution are bound closely, separating planning and execution into two stages provides more task clarity to the users, which reduces user cognitive load and contributes to the quality of task outcomes (Gadiraju et al., 2017). (2) With planning at the beginning of the task, users can develop a global [...] simulation environment (described in Section 3.3) where all required actions are implemented as backend APIs. In our study, all tasks are executed in a simulation setup, which has been a popular method for orchestrating meaningful human-centered AI studies (Doshi-Velez and Kim, 2017; Salimzadeh et al., 2024). [...] impact of user involvement in such AI systems by adjusting their intermediate outcomes (plan and step-by-step execution) to calibrate their trust and improve task outcomes. Our findings and implications can help advance the understanding of the effectiveness of LLM agents in human-AI collaboration.',\n",
              "     'score': 0.99971753},\n",
              "    {'title': 'Multiple AI models help robots execute complex plans ...',\n",
              "     'url': 'https://news.mit.edu/2024/multiple-ai-models-help-robots-execute-complex-plans-more-transparently-0108',\n",
              "     'content': 'In this case, the top of the hierarchy is an egocentric action model, or a sequence of first-person images that infer which actions should take place based on its surroundings. During this stage, the observation plan from the video model is mapped over the space visible to the robot, helping the machine decide how to execute each task within the long-horizon goal. If a robot uses HiP to make tea, this means it will have mapped out exactly where the pot, sink, and other key visual elements are, and begin completing each sub-goal. [...] These models also need some form of “eyes” to understand the environment they’re operating in and correctly execute each sub-goal. The team used a large video diffusion model to augment the initial planning completed by the LLM, which collects geometric and physical information about the world from footage on the internet. In turn, the video model generates an observation trajectory plan, refining the LLM’s outline to incorporate new physical knowledge.',\n",
              "     'score': 0.9997063}]},\n",
              "  {'step_index': 1,\n",
              "   'tool': 'final_answer',\n",
              "   'input': 'Using the information gathered, explain what it means to run a Plan-Then-Execute model as a state machine. Provide a concrete example, such as in robotics or AI, showing explicit state transitions.',\n",
              "   'output': '(final step - no tool execution)'}],\n",
              " 'final': '1) **정의**: Plan-Then-Execute 모델은 전략적 의사결정(계획)과 전술적 작업 수행(실행)을 분리하는 아키텍처적 패러다임입니다. 이 모델을 상태 기계(State Machine)로 실행한다는 것은, 각 단계가 명확한 상태로 정의되고, 상태 전이에 따라 계획이 실행된다는 것을 의미합니다. 상태 기계는 각 상태에서 특정 조건이 충족되면 다음 상태로 전이하는 방식으로 작동합니다.\\n\\n2) **차이**: 단순 파이프라인 방식에서는 계획, 실행, 결과 작성이 순차적으로 진행됩니다. 반면, 상태 기반 전이 방식에서는 각 단계가 상태로 정의되고, 조건에 따라 상태가 전이됩니다. 이는 계획 단계에서의 오류 수정이나 환경 변화에 대한 적응을 용이하게 합니다.\\n\\n3) **구체 예시**: 로봇 공학에서의 예를 들어보겠습니다. 로봇이 차를 만드는 작업을 수행한다고 가정할 때, Plan-Then-Execute 모델은 먼저 차체 조립, 엔진 설치, 도장 등의 계획을 세웁니다. 각 작업은 상태로 정의되고, 로봇은 차체 조립 상태에서 엔진 설치 상태로 전이합니다. 만약 도중에 부품이 부족하다면, 상태 기계는 오류 상태로 전이하여 문제를 해결한 후 다시 정상 상태로 돌아옵니다.\\n\\n4) **상태 전이 로그**: \\n   - 초기 상태: 계획 수립\\n   - 상태 전이: 차체 조립 → 엔진 설치 → 도장\\n   - 오류 발생 시: 엔진 설치 → 오류 상태 → 문제 해결 → 엔진 설치\\n   - 최종 상태: 작업 완료\\n\\n이러한 방식은 로봇이 복잡한 작업을 수행할 때 유연성과 적응성을 제공합니다.'}"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ㄴ 3. Graph Execution (DAG Workflow Engine)\n",
        "> Agent는 더 이상 **Loop**가 아닌 **Directed Graph** **(tool orchestration)**"
      ],
      "metadata": {
        "id": "JQfU0ZwCnz_o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 3.1 Description"
      ],
      "metadata": {
        "id": "OfcxNFvQmIea"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- State Machine은 **\"어떻게 상태가 바뀌는가?\"** 를 정의 (흐름을 관리하는 방식)\n",
        "- Graph Execution은 **\"작업들이 어떤 의존관계로 연결되는가?\"** 를 정의 (작업 구조를 표현하는 방식)\n",
        "\n",
        "- **Agent Framework Structure**\n",
        "| Framework             | internal structure\n",
        "| ----------------- | ---------------------------------------- |\n",
        "| LangGraph         | Graph + State control                    |\n",
        "| AutoGen           | Conversation State Machine + Tool Graph  |\n",
        "| CrewAI            | Role-based State + Task Graph            |\n",
        "| OpenAI Assistants | Run State Machine + Tool Execution Graph |\n",
        "\n",
        "- 구조 철학 :\n",
        "  - Execution = Graph\n",
        "  - Control = State Machine\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MhsQY8UYmMQY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 3.2 Code\n",
        "> State Machine의 **while-loop** 를 LangGraph의 **StateGraph(Node/Edge)** 로 실행 흐름으로 변경"
      ],
      "metadata": {
        "id": "3Oc8GmZKPPMJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 3.2.0 utils"
      ],
      "metadata": {
        "id": "geo7Uk6NR5oS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ㄴ 3.2.0.1 JSON Parser"
      ],
      "metadata": {
        "id": "YqKQ6U2hSG2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _strip_json_fence(text: str) -> str:\n",
        "    t = text.strip()\n",
        "    # ```json ... ``` 제거\n",
        "    if t.startswith(\"```\"):\n",
        "        t = re.sub(r\"^```[a-zA-Z0-9]*\\n\", \"\", t)\n",
        "        t = re.sub(r\"\\n```$\", \"\", t)\n",
        "    return t.strip()\n",
        "\n",
        "def parse_plan(text: str) -> Plan:\n",
        "    t = _strip_json_fence(text)\n",
        "    obj = json.loads(t)\n",
        "    return Plan.model_validate(obj)\n"
      ],
      "metadata": {
        "id": "-1Ya5lGeSM76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 3.2.1 Contract"
      ],
      "metadata": {
        "id": "r7SIuJiZScP7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ㄴ 3.2.1.1 StateGraph Schema and Type Definition"
      ],
      "metadata": {
        "id": "ji6nVy1sPtJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "from typing import TypedDict, List, Dict, Any, Optional\n",
        "\n",
        "from pydantic import BaseModel, Field, ValidationError\n",
        "from langchain_core.messages import SystemMessage, HumanMessage\n",
        "\n",
        "class Step(BaseModel):\n",
        "    tool: str\n",
        "    input: str\n",
        "\n",
        "class Plan(BaseModel):\n",
        "    goal: str\n",
        "    steps: List[Step]\n",
        "\n",
        "class GraphState(TypedDict, total=False):\n",
        "    user_question: str\n",
        "\n",
        "    plan: Plan\n",
        "    raw_plan_text: str\n",
        "\n",
        "    tool_results: List[Dict[str, Any]]\n",
        "\n",
        "    validation_ok: bool\n",
        "    validation_reason: str\n",
        "    fix_hint: str\n",
        "\n",
        "    replan_count: int\n",
        "    max_replans: int\n",
        "\n",
        "    final: str"
      ],
      "metadata": {
        "id": "gNsfpgYgPMzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ㄴ 3.2.1.2 System Prompt"
      ],
      "metadata": {
        "id": "PRPByRHET_mq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### ㄴ 3.2.1.2.1 Planner System Prompt"
      ],
      "metadata": {
        "id": "Q0q5_e61UaDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PLANNER_SYS = SystemMessage(content=\n",
        "\"\"\"You are a Planner for an LLM agent system.\n",
        "\n",
        "Output ONLY valid JSON matching this schema:\n",
        "{\n",
        "  \"goal\": string,\n",
        "  \"steps\": [\n",
        "    {\"tool\": \"wiki|search|calculator|docstore_lookup|final_answer\", \"input\": string}\n",
        "  ]\n",
        "}\n",
        "\n",
        "Rules:\n",
        "- Do NOT use markdown fences.\n",
        "- Prefer search over wiki if the term is ambiguous (e.g., Plan-and-Execute in LLM agents).\n",
        "- Ensure the last step is always tool=final_answer.\n",
        "\n",
        "Return ONLY JSON.\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "so8aj8bxUmjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### ㄴ 3.2.1.2.2 Replan Planner System Prompt"
      ],
      "metadata": {
        "id": "V7G9JGVWUooo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "REPLAN_PLANNER_SYS = SystemMessage(content=\n",
        "\"\"\"You are a Replanning Planner.\n",
        "\n",
        "You are given:\n",
        "- user question\n",
        "- validator fix_hint (what was wrong and what to fix)\n",
        "\n",
        "Output ONLY valid JSON matching this schema:\n",
        "{\n",
        "  \"goal\": string,\n",
        "  \"steps\": [\n",
        "    {\"tool\": \"wiki|search|calculator|docstore_lookup|final_answer\", \"input\": string}\n",
        "  ]\n",
        "}\n",
        "\n",
        "Rules:\n",
        "- Do NOT use markdown fences.\n",
        "- Fix the issue described by fix_hint.\n",
        "- Prefer search if Wikipedia is likely to be misleading/ambiguous.\n",
        "- Ensure the last step is always tool=final_answer.\n",
        "\n",
        "Return ONLY JSON.\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "BlbbZZmgUuLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### ㄴ 3.2.1.2.3 Validator System Prompt"
      ],
      "metadata": {
        "id": "JLVsdZ_oUv4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VALIDATOR_SYS = SystemMessage(content=\n",
        "\"\"\"You are a Validator.\n",
        "\n",
        "Input: JSON with keys:\n",
        "- user_question\n",
        "- plan\n",
        "- tool_results\n",
        "\n",
        "Decide whether the gathered information is sufficient and on-topic.\n",
        "\n",
        "Return ONLY JSON:\n",
        "{\n",
        "  \"ok\": boolean,\n",
        "  \"reason\": string (Korean),\n",
        "  \"fix_hint\": string (Korean, concrete instruction for replanning)\n",
        "}\n",
        "\n",
        "Mark ok=false if:\n",
        "- the info is about the wrong concept, OR\n",
        "- the answer would be too vague (missing concrete example / missing relationship).\n",
        "\n",
        "Return ONLY JSON.\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "wBNvqXDaUzob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### ㄴ 3.2.1.2.4 Writer System Prompt"
      ],
      "metadata": {
        "id": "fByclIo8VLyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GRAPH_WRITER_SYS = SystemMessage(content=\n",
        "\"\"\"You are a Writer that produces the final answer for the user in Korean.\n",
        "\n",
        "You receive a JSON payload with:\n",
        "- user_question\n",
        "- plan\n",
        "- tool_results\n",
        "\n",
        "Write a clear answer that MUST include:\n",
        "1) 정의: Plan-Then-Execute와 Graph/State-based 실행의 관계\n",
        "2) 예시 1개 (로봇/업무 자동화/리서치 중 택1)\n",
        "3) (선택) 실패 시 재계획이 왜 필요한지 한 문장\n",
        "\n",
        "Constraints:\n",
        "- Keep it practical and concrete.\n",
        "- Do not mention internal tool names.\n",
        "- Output plain Korean text only.\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "id": "HrtxFp4mVPhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 3.2.2 Fucntions"
      ],
      "metadata": {
        "id": "SqEtyM7cU3Dc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ㄴ 3.2.2.1. Planner Function"
      ],
      "metadata": {
        "id": "t_WiPz8xVcbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_plan(user_question: str) -> Plan:\n",
        "    resp = llm.invoke([PLANNER_SYS, HumanMessage(content=user_question)])\n",
        "    raw = resp.content or \"\"\n",
        "    return parse_plan(raw)"
      ],
      "metadata": {
        "id": "PCYdJvOaXi0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ㄴ 3.2.2.2. Replan Planner Function"
      ],
      "metadata": {
        "id": "w9Fygc2zXXeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_plan_replan(user_question: str, fix_hint: str) -> Plan:\n",
        "    payload = {\"user_question\": user_question, \"fix_hint\": fix_hint}\n",
        "    resp = llm.invoke([REPLAN_PLANNER_SYS, HumanMessage(content=json.dumps(payload, ensure_ascii=False))])\n",
        "    raw = resp.content or \"\"\n",
        "    return parse_plan(raw)"
      ],
      "metadata": {
        "id": "G5-bufHZXj4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ㄴ 3.2.2.3. Validator Function"
      ],
      "metadata": {
        "id": "42_7jZieXZxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_results(user_question: str, plan: Plan, tool_results: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
        "    payload = {\n",
        "        \"user_question\": user_question,\n",
        "        \"plan\": plan.model_dump(),\n",
        "        \"tool_results\": tool_results,\n",
        "    }\n",
        "    resp = llm.invoke([VALIDATOR_SYS, HumanMessage(content=json.dumps(payload, ensure_ascii=False))])\n",
        "    t = _strip_json_fence(resp.content or \"\")\n",
        "    return json.loads(t)"
      ],
      "metadata": {
        "id": "1aj2jBlpXlqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ㄴ 3.2.2.1. Writer Function"
      ],
      "metadata": {
        "id": "49wB1Tx0XcIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def write_final_graph(user_question: str, plan: Plan, tool_results: List[Dict[str, Any]]) -> str:\n",
        "    payload = {\n",
        "        \"user_question\": user_question,\n",
        "        \"plan\": plan.model_dump(),\n",
        "        \"tool_results\": tool_results,\n",
        "    }\n",
        "    resp = llm.invoke([GRAPH_WRITER_SYS, HumanMessage(content=json.dumps(payload, ensure_ascii=False))])\n",
        "    return (resp.content or \"\").strip()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "oghqRuQxXofP",
        "outputId": "3a8c7d93-ced8-46e0-9e09-c94eaf5c5abd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Plan' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2849986675.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mwrite_final_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_question\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplan\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPlan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtool_results\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     payload = {\n\u001b[1;32m      3\u001b[0m         \u001b[0;34m\"user_question\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muser_question\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;34m\"plan\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mplan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m\"tool_results\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtool_results\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Plan' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 3.2.3. Routing Tools"
      ],
      "metadata": {
        "id": "_5M6i8EPX4P9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tool_map = {\n",
        "    \"wiki\": wiki,                 # WikipediaQueryRun\n",
        "    \"search\": search_tool,        # TavilySearchResults\n",
        "    \"calculator\": calculator,     # tool\n",
        "    \"docstore_lookup\": docstore_lookup,  # tool\n",
        "}\n",
        "\n",
        "def run_tool(tool_name: str, tool_input: str) -> Any:\n",
        "    if tool_name not in tool_map:\n",
        "        raise ValueError(f\"Unknown tool: {tool_name}\")\n",
        "    return tool_map[tool_name].invoke(tool_input)"
      ],
      "metadata": {
        "id": "P6zpFvXfYI4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 3.2.4. Plan Executor"
      ],
      "metadata": {
        "id": "xNNROlbWYTjD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def execute_plan(plan: Plan) -> List[Dict[str, Any]]:\n",
        "    results: List[Dict[str, Any]] = []\n",
        "    for i, step in enumerate(plan.steps):\n",
        "        if step.tool == \"final_answer\":\n",
        "            results.append({\n",
        "                \"step_index\": i,\n",
        "                \"tool\": \"final_answer\",\n",
        "                \"input\": step.input,\n",
        "                \"output\": \"(final step - no tool execution)\"\n",
        "            })\n",
        "            continue\n",
        "\n",
        "        out = run_tool(step.tool, step.input)\n",
        "        results.append({\n",
        "            \"step_index\": i,\n",
        "            \"tool\": step.tool,\n",
        "            \"input\": step.input,\n",
        "            \"output\": out,\n",
        "        })\n",
        "    return results"
      ],
      "metadata": {
        "id": "95orfyHyYarp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 3.2.5. Nodes"
      ],
      "metadata": {
        "id": "tGSV9uGLZFSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END"
      ],
      "metadata": {
        "id": "NSaeed8paxSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ㄴ 3.2.5.1 Planner Node"
      ],
      "metadata": {
        "id": "cOx88lBlZN0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def node_plan(state: GraphState) -> GraphState:\n",
        "    q = state[\"user_question\"]\n",
        "    plan = make_plan(q)\n",
        "    return {\n",
        "        **state,\n",
        "        \"plan\": plan,\n",
        "        \"tool_results\": [],\n",
        "    }"
      ],
      "metadata": {
        "id": "1qva4Y1taz8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ㄴ 3.2.5.2 Executor Node"
      ],
      "metadata": {
        "id": "ATm0f-MuZVLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def node_execute(state: GraphState) -> GraphState:\n",
        "    plan = state[\"plan\"]\n",
        "    tool_results = execute_plan(plan)\n",
        "    return {**state, \"tool_results\": tool_results}"
      ],
      "metadata": {
        "id": "Yr9ELwxRa0Wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ㄴ 3.2.5.3 Validator Node"
      ],
      "metadata": {
        "id": "9NuietmhZp0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def node_validate(state: GraphState) -> GraphState:\n",
        "    q = state[\"user_question\"]\n",
        "    plan = state[\"plan\"]\n",
        "    tool_results = state.get(\"tool_results\", [])\n",
        "    verdict = validate_results(q, plan, tool_results)\n",
        "    return {\n",
        "        **state,\n",
        "        \"validation_ok\": bool(verdict.get(\"ok\", False)),\n",
        "        \"validation_reason\": verdict.get(\"reason\", \"\"),\n",
        "        \"fix_hint\": verdict.get(\"fix_hint\", \"\"),\n",
        "    }"
      ],
      "metadata": {
        "id": "vkemBrbGa0sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ㄴ 3.2.5.4 Replanner Node"
      ],
      "metadata": {
        "id": "25Yl8sloZ1A8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def node_replan(state: GraphState) -> GraphState:\n",
        "    # replan_count 증가\n",
        "    cnt = int(state.get(\"replan_count\", 0)) + 1\n",
        "    q = state[\"user_question\"]\n",
        "    fix_hint = state.get(\"fix_hint\", \"\").strip()\n",
        "\n",
        "    plan = make_plan_replan(q, fix_hint)\n",
        "    return {\n",
        "        **state,\n",
        "        \"replan_count\": cnt,\n",
        "        \"plan\": plan,\n",
        "        \"tool_results\": [],\n",
        "    }"
      ],
      "metadata": {
        "id": "-ij78VBra1I3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ㄴ 3.2.5.5 Writer Node"
      ],
      "metadata": {
        "id": "_vq7Qa8JZ1QH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def node_write(state: GraphState) -> GraphState:\n",
        "    q = state[\"user_question\"]\n",
        "    plan = state[\"plan\"]\n",
        "    tool_results = state.get(\"tool_results\", [])\n",
        "    final = write_final_graph(q, plan, tool_results)\n",
        "    return {**state, \"final\": final}"
      ],
      "metadata": {
        "id": "MIpz_zGba1xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 3.2.6 Condition function (Transition Function)\n",
        "> ***다음 노드 이름을 반환***\n",
        "\n",
        "- **Graph Execution**은 **Sate Machine** 과 다르게 상태를 변경하는 게 아니라\n",
        "**DAG 위에서 다음 Node를 선택**해야 하기 때문"
      ],
      "metadata": {
        "id": "obrLulVXbnVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def route_after_validate(state: GraphState) -> str:\n",
        "    ok = bool(state.get(\"validation_ok\", False))\n",
        "    if ok:\n",
        "        return \"WRITE\"\n",
        "\n",
        "    # fail이면 replan_count 확인\n",
        "    cnt = int(state.get(\"replan_count\", 0))\n",
        "    max_r = int(state.get(\"max_replans\", 2))\n",
        "    if cnt >= max_r:\n",
        "        return \"END_FAIL\"\n",
        "    return \"REPLAN\""
      ],
      "metadata": {
        "id": "5hre1Ge9cPE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 3.2.7 Edges"
      ],
      "metadata": {
        "id": "EX3SIzn3csE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph = StateGraph(GraphState)\n",
        "\n",
        "graph.add_node(\"PLAN\", node_plan)\n",
        "graph.add_node(\"EXECUTE\", node_execute)\n",
        "graph.add_node(\"VALIDATE\", node_validate)\n",
        "graph.add_node(\"REPLAN\", node_replan)\n",
        "graph.add_node(\"WRITE\", node_write)\n",
        "\n",
        "graph.set_entry_point(\"PLAN\")\n",
        "graph.add_edge(\"PLAN\", \"EXECUTE\")\n",
        "graph.add_edge(\"EXECUTE\", \"VALIDATE\")\n",
        "\n",
        "graph.add_conditional_edges(\n",
        "    \"VALIDATE\",\n",
        "    route_after_validate,\n",
        "    {\n",
        "        \"WRITE\": \"WRITE\",\n",
        "        \"REPLAN\": \"REPLAN\",\n",
        "        \"END_FAIL\": END,\n",
        "    }\n",
        ")\n",
        "\n",
        "graph.add_edge(\"REPLAN\", \"EXECUTE\")\n",
        "graph.add_edge(\"WRITE\", END)\n",
        "\n",
        "app = graph.compile()"
      ],
      "metadata": {
        "id": "rDsZu3fLcpy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 3.2.7 User Prompt"
      ],
      "metadata": {
        "id": "9RHOiK9Rdgzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Graph 실행(노드/엣지) 모델로 Plan-Then-Execute를 돌린다는 게 무슨 의미인지, 예시로 설명해줘.\""
      ],
      "metadata": {
        "id": "AxOHrEsYdjJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 3.2.8 Result"
      ],
      "metadata": {
        "id": "U9wj9R7TdKbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_graph(question: str, max_replans: int = 2) -> str:\n",
        "    init: GraphState = {\n",
        "        \"user_question\": question,\n",
        "        \"replan_count\": 0,\n",
        "        \"max_replans\": max_replans,\n",
        "    }\n",
        "    out = app.invoke(init)\n",
        "    if \"final\" in out and out[\"final\"]:\n",
        "        return out[\"final\"]\n",
        "    # 실패 케이스\n",
        "    raise RuntimeError(f\"GRAPH_FAILED: validation_reason={out.get('validation_reason')}\")"
      ],
      "metadata": {
        "id": "6Ccbz2SAdOkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(run_graph(question))"
      ],
      "metadata": {
        "id": "flKaNhn6dTE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 3.2.9 Verbose"
      ],
      "metadata": {
        "id": "B4_RbIpbdVkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_graph_verbose(question: str, max_replans: int = 2) -> Dict[str, Any]:\n",
        "    init: GraphState = {\n",
        "        \"user_question\": question,\n",
        "        \"replan_count\": 0,\n",
        "        \"max_replans\": max_replans,\n",
        "    }\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"USER QUESTION:\")\n",
        "    print(question)\n",
        "\n",
        "    last = None\n",
        "    for event in app.stream(init, stream_mode=\"values\"):\n",
        "        last = event\n",
        "        # 어떤 노드까지 갔는지 추적하기 쉽게 주요 필드만 출력\n",
        "        print(\"\\n--- STATE UPDATE ---\")\n",
        "        keys = [\"plan\", \"tool_results\", \"validation_ok\", \"validation_reason\", \"fix_hint\", \"replan_count\", \"final\"]\n",
        "        for k in keys:\n",
        "            if k in event:\n",
        "                if k == \"plan\":\n",
        "                    p = event[\"plan\"]\n",
        "                    print(\"plan.goal:\", p.goal)\n",
        "                    print(\"plan.steps:\", [f\"{s.tool}::{s.input}\" for s in p.steps])\n",
        "                elif k == \"tool_results\":\n",
        "                    print(\"tool_results.count:\", len(event[\"tool_results\"]))\n",
        "                    if event[\"tool_results\"]:\n",
        "                        sample = event[\"tool_results\"][-1]\n",
        "                        print(\"last_tool:\", sample.get(\"tool\"))\n",
        "                else:\n",
        "                    print(f\"{k}:\", event[k])\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    if last and \"final\" in last:\n",
        "        print(\"FINAL:\\n\", last[\"final\"])\n",
        "    return last"
      ],
      "metadata": {
        "id": "UzWDI9pjdZrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = run_graph_verbose(question)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "uSVBtOPwdcjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ㄴ 4. DAG-Orchestrated Stateful Execution (FSM + Graph)\n",
        "> **Planner**  → 전체 전략 생성 (FSM의 PLAN 역할)</br>\n",
        "**Executor** → 실제 작업 수행 (Graph/DAG 실행)\n"
      ],
      "metadata": {
        "id": "S9aob2Wqiblb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 4.1 Description\n",
        "\n",
        "- FSM이 **시스템 제어**\n",
        "- Graph가 **실제 작업 실행**\n",
        "- LLM은 **역할별로만 호출**됨"
      ],
      "metadata": {
        "id": "hbwMaR3_lFAE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 4.1.1 Architecture\n",
        "\n",
        "- FSM\n",
        "```text\n",
        "┌------┐\n",
        "│ PLAN │  LLM(Planner) → Plan(DAG spec)\n",
        "└--┬--┘\n",
        "    ▼\n",
        "┌--------┐\n",
        "│EXECUTE │  Graph Engine runs DAG nodes (tools/mini-LLMs) possibly in parallel\n",
        "└--┬----┘\n",
        "    ▼\n",
        "┌-----------------┐\n",
        "│     VALIDATE    │  LLM(Validator) checks quality/safety/coverage\n",
        "└┬------------┬-┘\n",
        "  │OK          │FAIL\n",
        "  ▼            ▼\n",
        "┌------┐   ┌-------┐\n",
        "│ WRITE│   │ REPLAN│  LLM(Replan Planner) adjusts plan with fix hints\n",
        "└-┬---┘   └-┬----┘\n",
        "   ▼           └----- back to EXECUTE (or PLAN)\n",
        "  DONE\n",
        "```\n",
        "\n",
        "- DAG\n",
        "```javascript\n",
        "search(A) ┐\n",
        "wiki(A)   ├─► merge_A ┐\n",
        "          │            │\n",
        "search(B) ┤            ├──► compare ─► write_inputs\n",
        "wiki(B)   ┘            │\n",
        "                        └──► citations_pack\n",
        "```\n",
        "\n",
        "- FSM은 **\"상태/재시도/검증/가드레일\"** 만 담당\n",
        "- EXECUTE는 **LangGraph DAG를 실행하는 함수** 로 캡슐화"
      ],
      "metadata": {
        "id": "zKL7qPuVlWXz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 4.2 Code"
      ],
      "metadata": {
        "id": "UbuC7egwo9_h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 4.2.0 utils"
      ],
      "metadata": {
        "id": "hjBrEQ1kuBte"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ㄴ 4.2.0.1 JSON Parser"
      ],
      "metadata": {
        "id": "ANzsEwAduiYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json, re\n",
        "from typing import Any, Dict, List, Literal, TypedDict\n",
        "\n",
        "def strip_json_fences(text: str) -> str:\n",
        "    text = text.strip()\n",
        "    m = re.match(r\"^```(?:json)?\\s*(.*?)\\s*```$\", text, flags=re.DOTALL | re.IGNORECASE)\n",
        "    return m.group(1).strip() if m else text\n",
        "\n",
        "def safe_load_json(text: str) -> Dict[str, Any]:\n",
        "    return json.loads(strip_json_fences(text))"
      ],
      "metadata": {
        "id": "gfkMMWTIudhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 4.2.1 Schema"
      ],
      "metadata": {
        "id": "cNuyzooBuunJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "ToolName = Literal[\"wiki\", \"search\", \"calculator\", \"docstore_lookup\", \"final_answer\"]\n",
        "\n",
        "class Step(BaseModel):\n",
        "    tool: ToolName\n",
        "    input: str\n",
        "\n",
        "class Plan(BaseModel):\n",
        "    goal: str\n",
        "    steps: List[Step] = Field(default_factory=list)\n",
        "\n",
        "class Verdict(BaseModel):\n",
        "    ok: bool\n",
        "    reason: str\n",
        "    fix_hint: str = \"\""
      ],
      "metadata": {
        "id": "nPPP04yCu2zY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 4.2.2 DAG (Data Plane)"
      ],
      "metadata": {
        "id": "ML3xmRpKvN_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, List, Dict, Any\n",
        "\n",
        "class ExecState(TypedDict, total=False):\n",
        "    # 입력\n",
        "    user_question: str\n",
        "    plan: Any\n",
        "\n",
        "    # lane별 중간 산출물\n",
        "    A_search: Any\n",
        "    A_wiki: Any\n",
        "    B_search: Any\n",
        "    B_wiki: Any\n",
        "\n",
        "    # join 결과\n",
        "    merged_A: str\n",
        "    merged_B: str\n",
        "    comparison: str\n",
        "\n",
        "    # 최종 tool_results로 합치기(기존 파이프라인 호환)\n",
        "    tool_results: List[Dict[str, Any]]\n",
        "\n",
        "\n",
        "def run_tool(tool: str, inp: str) -> str:\n",
        "    if tool == \"wiki\":\n",
        "        return wiki.run(inp)\n",
        "    if tool == \"search\":\n",
        "        return json.dumps(search_tool.invoke({\"query\": inp}), ensure_ascii=False)\n",
        "    if tool == \"calculator\":\n",
        "        return calculator(inp)\n",
        "    if tool == \"docstore_lookup\":\n",
        "        return docstore_lookup(inp)\n",
        "    if tool == \"final_answer\":\n",
        "        return \"(final step - no tool execution)\"\n",
        "    raise ValueError(f\"Unknown tool: {tool}\")\n",
        "\n",
        "def node_execute_steps(state: ExecState) -> Dict[str, Any]:\n",
        "    plan_obj = Plan.model_validate(state[\"plan\"])\n",
        "    results = []\n",
        "    for i, step in enumerate(plan_obj.steps):\n",
        "        out = run_tool(step.tool, step.input)\n",
        "        results.append({\n",
        "            \"step_index\": i,\n",
        "            \"tool\": step.tool,\n",
        "            \"input\": step.input,\n",
        "            \"output\": out\n",
        "        })\n",
        "    return {\"tool_results\": results}"
      ],
      "metadata": {
        "id": "iB-K-T3MvRUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ㄴ 4.2.2.2 Nodes"
      ],
      "metadata": {
        "id": "lGVlP5fLEY3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def node_search_A(state: ExecState) -> ExecState:\n",
        "    q = state[\"user_question\"]\n",
        "    out = search_tool.invoke({\"query\": f\"{q} A 관점\"})  # Tavily 형식에 맞게\n",
        "    return {\"A_search\": out}\n",
        "\n",
        "def node_wiki_A(state: ExecState) -> ExecState:\n",
        "    q = state[\"user_question\"]\n",
        "    out = wiki.invoke(f\"{q} A 키워드\")\n",
        "    return {\"A_wiki\": out}\n",
        "\n",
        "def node_search_B(state: ExecState) -> ExecState:\n",
        "    q = state[\"user_question\"]\n",
        "    out = search_tool.invoke({\"query\": f\"{q} B 관점\"})\n",
        "    return {\"B_search\": out}\n",
        "\n",
        "def node_wiki_B(state: ExecState) -> ExecState:\n",
        "    q = state[\"user_question\"]\n",
        "    out = wiki.invoke(f\"{q} B 키워드\")\n",
        "    return {\"B_wiki\": out}\n",
        "\n",
        "\n",
        "def node_merge_A(state: ExecState) -> ExecState:\n",
        "    # lane A 결과를 짧게 합치기\n",
        "    s = state.get(\"A_search\")\n",
        "    w = state.get(\"A_wiki\")\n",
        "    merged = f\"[A]\\n- search: {str(s)[:400]}\\n- wiki: {str(w)[:400]}\"\n",
        "    return {\"merged_A\": merged}\n",
        "\n",
        "def node_merge_B(state: ExecState) -> ExecState:\n",
        "    s = state.get(\"B_search\")\n",
        "    w = state.get(\"B_wiki\")\n",
        "    merged = f\"[B]\\n- search: {str(s)[:400]}\\n- wiki: {str(w)[:400]}\"\n",
        "    return {\"merged_B\": merged}\n",
        "\n",
        "def node_compare(state: ExecState) -> ExecState:\n",
        "    a = state.get(\"merged_A\", \"\")\n",
        "    b = state.get(\"merged_B\", \"\")\n",
        "    comparison = f\"COMPARE:\\n{a}\\n\\n{b}\"\n",
        "\n",
        "    tool_results = [\n",
        "        {\"tool\": \"search(A)\", \"input\": \"A 관점\", \"output\": state.get(\"A_search\")},\n",
        "        {\"tool\": \"wiki(A)\", \"input\": \"A 키워드\", \"output\": state.get(\"A_wiki\")},\n",
        "        {\"tool\": \"search(B)\", \"input\": \"B 관점\", \"output\": state.get(\"B_search\")},\n",
        "        {\"tool\": \"wiki(B)\", \"input\": \"B 키워드\", \"output\": state.get(\"B_wiki\")},\n",
        "        {\"tool\": \"compare\", \"input\": \"merge+compare\", \"output\": comparison},\n",
        "    ]\n",
        "    return {\"comparison\": comparison, \"tool_results\": tool_results}\n"
      ],
      "metadata": {
        "id": "Ja8xs7_YEgM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "exec_builder = StateGraph(ExecState)\n",
        "\n",
        "# fan-out nodes\n",
        "exec_builder.add_node(\"node_search_A\", node_search_A)\n",
        "exec_builder.add_node(\"node_wiki_A\", node_wiki_A)\n",
        "exec_builder.add_node(\"node_search_B\", node_search_B)\n",
        "exec_builder.add_node(\"node_wiki_B\", node_wiki_B)\n",
        "\n",
        "# join nodes\n",
        "exec_builder.add_node(\"node_merge_A\", node_merge_A)\n",
        "exec_builder.add_node(\"node_merge_B\", node_merge_B)\n",
        "exec_builder.add_node(\"node_compare\", node_compare)\n",
        "\n",
        "# entry\n",
        "exec_builder.set_entry_point(\"node_search_A\")\n",
        "\n",
        "# fan-out 구조(여기선 단순히 분기 엣지로 표현)\n",
        "exec_builder.add_edge(\"node_search_A\", \"node_wiki_A\")\n",
        "exec_builder.add_edge(\"node_search_A\", \"node_search_B\")   # 가지치기\n",
        "exec_builder.add_edge(\"node_search_A\", \"node_wiki_B\")     # 가지치기\n",
        "\n",
        "# A lane join\n",
        "exec_builder.add_edge(\"node_wiki_A\", \"node_merge_A\")\n",
        "\n",
        "# B lane join\n",
        "exec_builder.add_edge(\"node_search_B\", \"node_merge_B\")\n",
        "exec_builder.add_edge(\"node_wiki_B\", \"node_merge_B\")\n",
        "\n",
        "# final join\n",
        "exec_builder.add_edge(\"node_merge_A\", \"node_compare\")\n",
        "exec_builder.add_edge(\"node_merge_B\", \"node_compare\")\n",
        "\n",
        "exec_builder.add_edge(\"node_compare\", END)\n",
        "\n",
        "exec_graph = exec_builder.compile()"
      ],
      "metadata": {
        "id": "nu1sqziev0pM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 4.2.3 FSM(Control Plane)"
      ],
      "metadata": {
        "id": "3uOPeDwhv8j8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ㄴ 4.2.3.1 Contract"
      ],
      "metadata": {
        "id": "UdcKQie4wzT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage, HumanMessage"
      ],
      "metadata": {
        "id": "XbPr1Qc0xOIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### ㄴ 4.2.3.1.1 Planner System Prompt"
      ],
      "metadata": {
        "id": "DRpirtH4xBTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PLANNER_SYS = SystemMessage(content=\"\"\"\n",
        "You are the PLANNER.\n",
        "Return JSON ONLY matching:\n",
        "{\"goal\": \"...\", \"steps\":[{\"tool\":\"...\",\"input\":\"...\"}...]}\n",
        "\n",
        "Rules:\n",
        "- tools allowed: wiki, search, calculator, docstore_lookup, final_answer\n",
        "- prefer search for modern LLM-agent concepts; wiki can be ambiguous\n",
        "- steps <= 5\n",
        "- last step MUST be {\"tool\":\"final_answer\",\"input\":\"...\"}\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "Dlsh3C1-v8AX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### ㄴ 4.2.3.1.2 RePlanner System Prompt"
      ],
      "metadata": {
        "id": "kPShHFTExSZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "REPLANNER_SYS = SystemMessage(content=\"\"\"\n",
        "You are the REPLANNER.\n",
        "Input: JSON {\"user_question\": \"...\", \"fix_hint\": \"...\"}.\n",
        "Return a revised plan JSON in the same schema.\n",
        "Rules:\n",
        "- follow fix_hint precisely\n",
        "- steps <= 5, last step final_answer\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "-3e4utYrxSZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### ㄴ 4.2.3.1.3 Validator System Prompt"
      ],
      "metadata": {
        "id": "CFYz9cNpxSoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FIX : Miss Direction\n",
        "VALIDATOR_SYS = SystemMessage(content=\"\"\"\n",
        "You are the VALIDATOR for an agent pipeline (artifacts-only).\n",
        "\n",
        "Input JSON:\n",
        "{\n",
        "  \"user_question\": \"...\",\n",
        "  \"plan\": {...},\n",
        "  \"tool_results\": [...]\n",
        "}\n",
        "\n",
        "You must NOT evaluate any drafted/final answer text.\n",
        "Your job is to decide whether the collected artifacts are sufficient to write a good answer.\n",
        "\n",
        "Return JSON ONLY:\n",
        "{\"ok\": true/false, \"reason\":\"...\", \"fix_hint\":\"...\"}\n",
        "\n",
        "Rules:\n",
        "- ok=true if the artifacts contain enough material to answer the question well.\n",
        "- ok=false ONLY when missing required evidence/material.\n",
        "\n",
        "What to check (practical):\n",
        "1) COVERAGE: Do artifacts cover the key sub-questions implied by user_question?\n",
        "2) EXAMPLES: If the user asked for examples (\"예시 포함\"), do artifacts include at least one concrete example or case?\n",
        "3) DISAMBIGUATION: If there's a known confusion risk (e.g., Plan-Then-Execute vs DB query plan),\n",
        "   do artifacts contain a correct definition/source that resolves it?\n",
        "\n",
        "Do NOT require citations or stylistic constraints.\n",
        "Do NOT demand specific metaphors/phrases.\n",
        "Do NOT mention tools or internal node names.\n",
        "\n",
        "When ok=false:\n",
        "- reason: short label + 1 sentence (e.g., \"MISSING_EXAMPLE: ...\")\n",
        "- fix_hint: MUST be actionable and MUST start with one of:\n",
        "  - \"Search for ...\"\n",
        "  - \"Add a node to fetch ...\"\n",
        "  - \"Add a node to summarize ...\"\n",
        "  - \"Remove unrelated artifact ...\"\n",
        "\n",
        "Important:\n",
        "- Even when ok=true, you MUST still include non-empty \"reason\" and \"fix_hint\" (for schema compatibility).\n",
        "  Use:\n",
        "  reason=\"OK\"\n",
        "  fix_hint=\"\"\n",
        "\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "1Q4xvIimxSoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### ㄴ 4.2.3.1.4 Writer System Prompt"
      ],
      "metadata": {
        "id": "lcSe7esFxhPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "WRITER_SYS = SystemMessage(content=\"\"\"\n",
        "You are the WRITER. Output Korean only (plain text).\n",
        "Input JSON {\"user_question\":..., \"plan\":..., \"tool_results\":...}\n",
        "Write a practical, concrete answer. Do not mention internal tool names.\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "L1NrM1KAxhPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ㄴ 4.2.3.3 FSM State Definiton & Execution Actions\n",
        "\n"
      ],
      "metadata": {
        "id": "jL7yE3N6yI1l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### ㄴ 4.2.3.3.0 Normalize Utils"
      ],
      "metadata": {
        "id": "aiB3zny27q1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple\n",
        "\n",
        "def normalize_plan_dict(raw: Any, user_question: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Convert various LLM outputs into valid Plan dict:\n",
        "    { \"goal\": str, \"steps\": [ {\"tool\": \"...\", \"input\": \"...\"} ] }\n",
        "    \"\"\"\n",
        "    if not isinstance(raw, dict):\n",
        "        # raw가 그냥 문자열이면 -> 최소 플랜\n",
        "        return {\n",
        "            \"goal\": user_question,\n",
        "            \"steps\": [\n",
        "                {\"tool\": \"search\", \"input\": user_question},\n",
        "                {\"tool\": \"final_answer\", \"input\": \"도구 결과를 바탕으로 한국어로 답변해줘.\"},\n",
        "            ],\n",
        "        }\n",
        "\n",
        "    goal = raw.get(\"goal\") or raw.get(\"objective\") or raw.get(\"task\") or user_question\n",
        "    steps = raw.get(\"steps\", [])\n",
        "\n",
        "    # steps가 문자열 리스트인 경우: heuristic로 tool 추정\n",
        "    if isinstance(steps, list) and (len(steps) > 0) and isinstance(steps[0], str):\n",
        "        new_steps = []\n",
        "        for s in steps:\n",
        "            s = str(s).strip()\n",
        "            # \"final_answer: ....\" 같은 형식 지원\n",
        "            m = re.match(r\"^(wiki|search|calculator|docstore_lookup|final_answer)\\s*:\\s*(.*)$\", s, re.I)\n",
        "            if m:\n",
        "                tool = m.group(1).lower()\n",
        "                inp = m.group(2).strip()\n",
        "            else:\n",
        "                # 문장에 Search/wiki 같은 키워드가 있으면 search/wiki로\n",
        "                low = s.lower()\n",
        "                if \"wiki\" in low or \"wikipedia\" in low:\n",
        "                    tool, inp = \"wiki\", s\n",
        "                elif \"calc\" in low or \"calculate\" in low or re.search(r\"[\\d\\)\\(]\\s*[\\+\\-\\*/]\", s):\n",
        "                    tool, inp = \"calculator\", s\n",
        "                else:\n",
        "                    tool, inp = \"search\", s\n",
        "            new_steps.append({\"tool\": tool, \"input\": inp})\n",
        "\n",
        "        # 마지막은 final_answer 강제\n",
        "        if not new_steps or new_steps[-1][\"tool\"] != \"final_answer\":\n",
        "            new_steps.append({\"tool\": \"final_answer\", \"input\": \"도구 결과를 바탕으로 한국어로 최종 답변을 작성해줘.\"})\n",
        "\n",
        "        return {\"goal\": goal, \"steps\": new_steps}\n",
        "\n",
        "    # steps가 dict 리스트인데 tool/input 키가 다를 때 보정\n",
        "    if isinstance(steps, list) and (len(steps) > 0) and isinstance(steps[0], dict):\n",
        "        new_steps = []\n",
        "        for step in steps:\n",
        "            tool = step.get(\"tool\") or step.get(\"action\") or step.get(\"name\")\n",
        "            inp  = step.get(\"input\") or step.get(\"query\") or step.get(\"args\") or step.get(\"text\")\n",
        "            if tool is None or inp is None:\n",
        "                # 누락되면 search로 강제\n",
        "                new_steps.append({\"tool\": \"search\", \"input\": json.dumps(step, ensure_ascii=False)})\n",
        "            else:\n",
        "                tool = str(tool).strip()\n",
        "                inp = str(inp).strip()\n",
        "                # tool 정규화\n",
        "                tool_map = {\n",
        "                    \"tavily\": \"search\",\n",
        "                    \"tavily_search\": \"search\",\n",
        "                    \"wikipedia\": \"wiki\",\n",
        "                    \"calc\": \"calculator\",\n",
        "                }\n",
        "                tool = tool_map.get(tool.lower(), tool.lower())\n",
        "                if tool not in {\"wiki\",\"search\",\"calculator\",\"docstore_lookup\",\"final_answer\"}:\n",
        "                    tool = \"search\"\n",
        "                new_steps.append({\"tool\": tool, \"input\": inp})\n",
        "\n",
        "        if not new_steps or new_steps[-1][\"tool\"] != \"final_answer\":\n",
        "            new_steps.append({\"tool\": \"final_answer\", \"input\": \"도구 결과를 바탕으로 한국어로 최종 답변을 작성해줘.\"})\n",
        "\n",
        "        return {\"goal\": goal, \"steps\": new_steps}\n",
        "\n",
        "    # steps가 이상하면 최소 플랜\n",
        "    return {\n",
        "        \"goal\": goal,\n",
        "        \"steps\": [\n",
        "            {\"tool\": \"search\", \"input\": user_question},\n",
        "            {\"tool\": \"final_answer\", \"input\": \"도구 결과를 바탕으로 한국어로 답변해줘.\"},\n",
        "        ],\n",
        "    }\n",
        "\n",
        "def make_plan_safe(user_question: str, planner_sys: SystemMessage = None) -> Plan:\n",
        "    sys_msg = planner_sys or PLANNER_SYS\n",
        "    resp = llm.invoke([sys_msg, HumanMessage(content=user_question)])\n",
        "\n",
        "    try:\n",
        "        raw = safe_load_json(resp.content)\n",
        "    except Exception:\n",
        "        raw = {\"goal\": user_question, \"steps\": [resp.content]}\n",
        "\n",
        "    normalized = normalize_plan_dict(raw, user_question)\n",
        "    return Plan.model_validate(normalized)\n"
      ],
      "metadata": {
        "id": "cCc5hKES72_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### ㄴ 4.2.3.3.1 State Definition"
      ],
      "metadata": {
        "id": "7HCoITTg1bWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentState(TypedDict):\n",
        "    user_question: str\n",
        "    phase: str\n",
        "    plan: Dict[str, Any]\n",
        "    tool_results: List[Dict[str, Any]]\n",
        "    verdict: Dict[str, Any]\n",
        "    fix_hint: str\n",
        "    replan_count: int\n",
        "    max_replans: int\n",
        "    draft_answer: str\n",
        "    final: str\n",
        "    trace: List[Dict[str, Any]]"
      ],
      "metadata": {
        "id": "y8DXCGF81iU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### ㄴ 4.2.3.3.2 Planner Action"
      ],
      "metadata": {
        "id": "mOpdPfx9yorj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fsm_plan(state: AgentState) -> AgentState:\n",
        "    try:\n",
        "        plan_obj = make_plan_safe(state[\"user_question\"], PLANNER_SYS)\n",
        "        state[\"plan\"] = plan_obj.model_dump()\n",
        "        state[\"phase\"] = \"EXECUTE\"\n",
        "        state[\"trace\"].append({\"phase\":\"PLAN\",\"ok\":True,\"steps\":state[\"plan\"][\"steps\"]})\n",
        "        return state\n",
        "    except Exception as e:\n",
        "        state[\"phase\"] = \"DONE\"\n",
        "        state[\"final\"] = f\"PLAN_ERROR: {type(e).__name__}: {e}\"\n",
        "        state[\"trace\"].append({\"phase\":\"PLAN\",\"ok\":False,\"error\":state[\"final\"]})\n",
        "        return state"
      ],
      "metadata": {
        "id": "ITSR8ZtUyyW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### ㄴ 4.2.3.3.3 Executor Action"
      ],
      "metadata": {
        "id": "FufI81ZTy4TO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fsm_execute(state: AgentState) -> AgentState:\n",
        "    executed = []\n",
        "\n",
        "    gstate: ExecState = {\n",
        "        \"user_question\": state[\"user_question\"],\n",
        "        \"plan\": state[\"plan\"],\n",
        "        \"tool_results\": [],\n",
        "    }\n",
        "\n",
        "    for ev in exec_graph.stream(gstate, stream_mode=\"updates\"):\n",
        "        for node_name, upd in ev.items():\n",
        "            executed.append(node_name)\n",
        "            if isinstance(upd, dict) and \"tool_results\" in upd:\n",
        "                gstate[\"tool_results\"] = upd[\"tool_results\"]\n",
        "\n",
        "    state[\"tool_results\"] = gstate.get(\"tool_results\", [])\n",
        "    state[\"trace\"].append({\"phase\": \"EXECUTE\", \"ok\": True, \"executed_nodes\": executed})\n",
        "\n",
        "    # FIX : Cost 증가 이슈 있음\n",
        "    payload = {\n",
        "        \"user_question\": state[\"user_question\"],\n",
        "        \"plan\": state[\"plan\"],\n",
        "        \"tool_results\": state[\"tool_results\"],\n",
        "    }\n",
        "    draft = llm.invoke([WRITER_SYS, HumanMessage(content=json.dumps(payload, ensure_ascii=False))]).content\n",
        "    state[\"draft_answer\"] = draft\n",
        "\n",
        "    state[\"phase\"] = \"VALIDATE\"\n",
        "    return state\n",
        "\n"
      ],
      "metadata": {
        "id": "rxmsWIX7y4TO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### ㄴ 4.2.3.3.4 Validator Action"
      ],
      "metadata": {
        "id": "7Ge54zk2y48J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fsm_validate(state: AgentState) -> AgentState:\n",
        "    payload = {\n",
        "        \"user_question\": state[\"user_question\"],\n",
        "        \"plan\": state[\"plan\"],\n",
        "        \"tool_results\": state[\"tool_results\"],\n",
        "        \"draft_answer\": state.get(\"draft_answer\", \"\"),\n",
        "    }\n",
        "    resp = llm.invoke([VALIDATOR_SYS, HumanMessage(content=json.dumps(payload, ensure_ascii=False))])\n",
        "    verdict_dict = safe_load_json(resp.content)\n",
        "    verdict_obj = Verdict.model_validate(verdict_dict)\n",
        "\n",
        "    state[\"verdict\"] = verdict_obj.model_dump()\n",
        "    state[\"trace\"].append({\"phase\":\"VALIDATE\",\"ok\":True,\"verdict\":state[\"verdict\"]})\n",
        "\n",
        "    if verdict_obj.ok:\n",
        "        state[\"phase\"] = \"WRITE\"\n",
        "        return state\n",
        "\n",
        "    # fail → replan 가능하면\n",
        "    state[\"fix_hint\"] = verdict_obj.fix_hint\n",
        "    if state[\"replan_count\"] < state[\"max_replans\"]:\n",
        "        state[\"phase\"] = \"REPLAN\"\n",
        "        state[\"trace\"].append({\"phase\":\"REPLAN_TRIGGER\",\"replan_count\":state[\"replan_count\"]+1,\"fix_hint\":state[\"fix_hint\"]})\n",
        "        return state\n",
        "\n",
        "    state[\"phase\"] = \"WRITE\"  # 최후엔 write로\n",
        "    return state"
      ],
      "metadata": {
        "id": "nPohoZTZy48J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### ㄴ 4.2.3.3.5 Replanner Action"
      ],
      "metadata": {
        "id": "Y15c9521y5i5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fsm_replan(state: AgentState) -> AgentState:\n",
        "    payload = {\"user_question\": state[\"user_question\"], \"fix_hint\": state[\"fix_hint\"]}\n",
        "    msg = json.dumps(payload, ensure_ascii=False)\n",
        "\n",
        "    try:\n",
        "        # replan은 질문을 payload로 넣어서 안전하게\n",
        "        plan_obj = make_plan_safe(msg, REPLANNER_SYS)\n",
        "        state[\"plan\"] = plan_obj.model_dump()\n",
        "        state[\"replan_count\"] += 1\n",
        "        state[\"phase\"] = \"EXECUTE\"\n",
        "        state[\"trace\"].append({\"phase\":\"PLAN\",\"ok\":True,\"used_replan_planner\":True,\"steps\":state[\"plan\"][\"steps\"]})\n",
        "        return state\n",
        "    except Exception as e:\n",
        "        state[\"phase\"] = \"DONE\"\n",
        "        state[\"final\"] = f\"REPLAN_ERROR: {type(e).__name__}: {e}\"\n",
        "        state[\"trace\"].append({\"phase\":\"REPLAN\",\"ok\":False,\"error\":state[\"final\"]})\n",
        "        return state"
      ],
      "metadata": {
        "id": "TWFlgb-ay5i5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### ㄴ 4.2.3.3.6 Writer Action"
      ],
      "metadata": {
        "id": "Ys8EmUMFy5tg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fsm_write(state: AgentState) -> AgentState:\n",
        "    payload = {\n",
        "        \"user_question\": state[\"user_question\"],\n",
        "        \"plan\": state[\"plan\"],\n",
        "        \"tool_results\": state[\"tool_results\"],\n",
        "    }\n",
        "    resp = llm.invoke([WRITER_SYS, HumanMessage(content=json.dumps(payload, ensure_ascii=False))])\n",
        "    state[\"final\"] = resp.content\n",
        "    state[\"phase\"] = \"DONE\"\n",
        "    state[\"trace\"].append({\"phase\":\"WRITE\",\"ok\":True,\"final_chars\":len(state[\"final\"])})\n",
        "    return state"
      ],
      "metadata": {
        "id": "aFjaFTWvy5tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ㄴ 4.2.3.4 Transition Function"
      ],
      "metadata": {
        "id": "d572Xa-z1SNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Callable, Optional\n",
        "\n",
        "Phase = str  # \"PLAN\" | \"EXECUTE\" | \"VALIDATE\" | \"REPLAN\" | \"WRITE\" | \"DONE\"\n",
        "\n",
        "def transition(state: AgentState) -> AgentState:\n",
        "    \"\"\"FSM: advance exactly one step based on current phase.\"\"\"\n",
        "    phase = state[\"phase\"]\n",
        "\n",
        "    if phase == \"PLAN\":\n",
        "        return fsm_plan(state)\n",
        "    elif phase == \"EXECUTE\":\n",
        "        return fsm_execute(state)\n",
        "    elif phase == \"VALIDATE\":\n",
        "        return fsm_validate(state)\n",
        "    elif phase == \"REPLAN\":\n",
        "        return fsm_replan(state)\n",
        "    elif phase == \"WRITE\":\n",
        "        return fsm_write(state)\n",
        "    elif phase == \"DONE\":\n",
        "        return state\n",
        "    else:\n",
        "        raise RuntimeError(f\"Unknown phase: {phase}\")"
      ],
      "metadata": {
        "id": "l8suuMjU2G5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 4.2.4 User Prompt"
      ],
      "metadata": {
        "id": "tJJlGaga5mfe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Plan-Then-Execute와 ReAct(LLM 에이전트 패턴)의 차이를 예시 포함해서 설명해줘. 최신 관점이면 search도 활용해.\""
      ],
      "metadata": {
        "id": "Gdl67dVe5pzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 4.2.5 Result"
      ],
      "metadata": {
        "id": "0LVtzWhK2RcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_state(question: str, max_replans: int = 2) -> AgentState:\n",
        "    return {\n",
        "        \"user_question\": question,\n",
        "        \"phase\": \"PLAN\",\n",
        "        \"plan\": {},\n",
        "        \"tool_results\": [],\n",
        "        \"verdict\": {},\n",
        "        \"fix_hint\": \"\",\n",
        "        \"replan_count\": 0,\n",
        "        \"max_replans\": max_replans,\n",
        "        \"draft_answer\": \"\",\n",
        "        \"final\": \"\",\n",
        "        \"trace\": [],\n",
        "    }\n",
        "\n",
        "def run_loop(\n",
        "    question: str,\n",
        "    max_replans: int = 2,\n",
        "    on_step: Optional[Callable[[AgentState, Phase], None]] = None,\n",
        ") -> AgentState:\n",
        "    \"\"\"\n",
        "    on_step(state, prev_phase): called after each transition.\n",
        "    \"\"\"\n",
        "    state = init_state(question, max_replans=max_replans)\n",
        "\n",
        "    while state[\"phase\"] != \"DONE\":\n",
        "        prev_phase = state[\"phase\"]\n",
        "        state = transition(state)\n",
        "\n",
        "        if on_step:\n",
        "            on_step(state, prev_phase)\n",
        "\n",
        "    return state"
      ],
      "metadata": {
        "id": "OiKDUi8Z45sz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_fsm_graph(question: str, max_replans: int = 2) -> str:\n",
        "    final_state = run_loop(question, max_replans=max_replans)\n",
        "    return final_state[\"final\"]"
      ],
      "metadata": {
        "id": "G6AFLizG5M9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(run_fsm_graph(question, max_replans=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4y-JM0j5a-l",
        "outputId": "95fe76da-8108-41e0-9bd8-e5063da79226"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PLAN_ERROR: NameError: name 'llm' is not defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 4.3 Verbose"
      ],
      "metadata": {
        "id": "_FYZ_-oI5BtF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_execute_pretty(executed_nodes: List[str]):\n",
        "    print(\"FSM: EXECUTE\")\n",
        "    print(\"  DAG: fan-out\")\n",
        "    for n in executed_nodes:\n",
        "        if n.startswith(\"node_search_\") or n.startswith(\"node_wiki_\"):\n",
        "            lane = n.split(\"_\")[-1]\n",
        "            print(f\"    {n}({lane}) ...\")\n",
        "\n",
        "    print(\"  DAG: join\")\n",
        "    for n in executed_nodes:\n",
        "        if n.startswith(\"node_merge_\") or n == \"node_compare\":\n",
        "            lane = n.split(\"_\")[-1] if n.startswith(\"node_merge_\") else \"\"\n",
        "            suffix = f\"({lane})\" if lane else \"\"\n",
        "            print(f\"    {n}{suffix} ...\")\n",
        "\n",
        "    print(\"  DAG done → artifacts 저장\")\n",
        "\n",
        "def short(text: str, n: int = 40) -> str:\n",
        "    if text is None:\n",
        "        return \"\"\n",
        "    text = str(text).replace(\"\\n\", \" \").strip()\n",
        "    return text[:n] + (\"...\" if len(text) > n else \"\")\n",
        "\n",
        "def short(text: str, n: int = 40) -> str:\n",
        "    if text is None:\n",
        "        return \"\"\n",
        "    text = str(text).replace(\"\\n\", \" \").strip()\n",
        "    return text[:n] + (\"...\" if len(text) > n else \"\")\n",
        "\n",
        "def print_search_results(results, limit=3, width=40):\n",
        "    # results: Tavily/Wiki 등의 list[dict] 형태를 가정\n",
        "    for i, r in enumerate((results or [])[:limit]):\n",
        "        title = r.get(\"title\") or r.get(\"name\") or \"\"\n",
        "        content = r.get(\"content\") or r.get(\"snippet\") or r.get(\"summary\") or \"\"\n",
        "        print(f\"      ({i}) {short(title, width)}\")\n",
        "        if content:\n",
        "            print(f\"           {short(content, width)}\")\n",
        "\n",
        "def print_tool_results_compact(tool_results, width=40, per_tool_limit=3):\n",
        "    if not tool_results:\n",
        "        print(\"TOOL RESULTS: (empty)\")\n",
        "        return\n",
        "\n",
        "    print(\"TOOL RESULTS (compact):\")\n",
        "    for i, tr in enumerate(tool_results):\n",
        "        tool = tr.get(\"tool\", \"\")\n",
        "        inp = tr.get(\"input\", \"\")\n",
        "        out = tr.get(\"output\")\n",
        "\n",
        "        print(f\"  - [{i}] tool={tool} | input={short(inp, width)}\")\n",
        "\n",
        "        if isinstance(out, list):\n",
        "            print_search_results(out, limit=per_tool_limit, width=width)\n",
        "        else:\n",
        "            print(f\"      output={short(out, width)}\")"
      ],
      "metadata": {
        "id": "jxBZv_XVE5T7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def verbose_hook(state: AgentState, prev_phase: Phase):\n",
        "    print(\"\\n\" + \"-\"*28 + f\" PHASE: {prev_phase} \" + \"-\"*28)\n",
        "\n",
        "    if prev_phase == \"PLAN\":\n",
        "        print(\"GOAL:\", state[\"plan\"].get(\"goal\"))\n",
        "        print(\"STEPS:\")\n",
        "        for i, s in enumerate(state[\"plan\"].get(\"steps\", [])):\n",
        "            print(f\"  [{i}] {s['tool']} :: {s['input']}\")\n",
        "\n",
        "    elif prev_phase == \"EXECUTE\":\n",
        "      exec_events = [x for x in state.get(\"trace\", []) if x.get(\"phase\") == \"EXECUTE\"]\n",
        "      if not exec_events:\n",
        "          print(\"Executed. (no EXECUTE trace found)\")\n",
        "          return\n",
        "\n",
        "      t = exec_events[-1]\n",
        "      executed_nodes = t.get(\"executed_nodes\", [])\n",
        "\n",
        "      # 1) 실행 노드 출력\n",
        "      if executed_nodes:\n",
        "          print_execute_pretty(executed_nodes)\n",
        "      else:\n",
        "          print(\"Executed steps:\", len(state.get(\"tool_results\", [])))\n",
        "\n",
        "      # 2) tool_results를 40자 요약으로 출력\n",
        "      print_tool_results_compact(state.get(\"tool_results\", []), width=40, per_tool_limit=3)\n",
        "\n",
        "    elif prev_phase == \"VALIDATE\":\n",
        "        print(\"VERDICT:\", state[\"verdict\"])\n",
        "        if not state[\"verdict\"].get(\"ok\", False):\n",
        "            print(\"FIX_HINT:\", state.get(\"fix_hint\", \"\"))\n",
        "\n",
        "    elif prev_phase == \"REPLAN\":\n",
        "        print(\"Replanned. replan_count:\", state[\"replan_count\"])\n",
        "        print(\"STEPS:\")\n",
        "        for i, s in enumerate(state[\"plan\"].get(\"steps\", [])):\n",
        "            print(f\"  [{i}] {s['tool']} :: {s['input']}\")\n",
        "\n",
        "    elif prev_phase == \"WRITE\":\n",
        "        print(\"FINAL(trunc):\")\n",
        "        print(state[\"final\"][:2000])\n",
        "\n",
        "\n",
        "def run_fsm_graph_verbose(question: str, max_replans: int = 2) -> AgentState:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"USER QUESTION:\")\n",
        "    print(question)\n",
        "\n",
        "    final_state = run_loop(question, max_replans=max_replans, on_step=verbose_hook)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    return final_state"
      ],
      "metadata": {
        "id": "Nez07iyM5T0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_fsm_graph_verbose(question, max_replans=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvlN5Pv3FYxK",
        "outputId": "53f4e195-3f16-4602-c7a3-a7a7e283bccb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "USER QUESTION:\n",
            "Plan-Then-Execute와 ReAct(LLM 에이전트 패턴)의 차이를 예시 포함해서 설명해줘. 최신 관점이면 search도 활용해.\n",
            "\n",
            "---------------------------- PHASE: PLAN ----------------------------\n",
            "GOAL: None\n",
            "STEPS:\n",
            "\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'user_question': 'Plan-Then-Execute와 ReAct(LLM 에이전트 패턴)의 차이를 예시 포함해서 설명해줘. 최신 관점이면 search도 활용해.',\n",
              " 'phase': 'DONE',\n",
              " 'plan': {},\n",
              " 'tool_results': [],\n",
              " 'verdict': {},\n",
              " 'fix_hint': '',\n",
              " 'replan_count': 0,\n",
              " 'max_replans': 2,\n",
              " 'draft_answer': '',\n",
              " 'final': \"PLAN_ERROR: NameError: name 'llm' is not defined\",\n",
              " 'trace': [{'phase': 'PLAN',\n",
              "   'ok': False,\n",
              "   'error': \"PLAN_ERROR: NameError: name 'llm' is not defined\"}]}"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ㄴ 5. Role-Specialized Multi-Agent System\n",
        "\n",
        "\n",
        "*   **System**이 **역할**을 **정의**\n",
        "*   **LLM**은 **Role Function**으로 **호출**\n",
        "\n"
      ],
      "metadata": {
        "id": "TT35tciCpIRs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 5.1 Description"
      ],
      "metadata": {
        "id": "oHXvtV5k9gFS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "하나의 LLM(싱글 에이전트)이 “기획/조사/구현/검수”를 다 하는 것과 달리\n",
        "\n",
        "- **Planner**: 요구사항을 작업 단위로 분해, 실행계획 수립\n",
        "\n",
        "- **Researcher**: 근거/레퍼런스/리스크 확인(선택)\n",
        "\n",
        "- **Builder(Implementer)**: 실제 산출물(코드/설계/문서) 생성\n",
        "\n",
        "- **Validator(Critic/QA)**: 산출물만 검사(형식/제약/정합성), 필요 시 수정 요청\n",
        "\n",
        "역할별로 **system prompt + 책임 범위**를 분리하고,\n",
        "상위 **Supervisor(Orchestrator)** 가 \"지금 누구에게 넘길지\" 라우팅"
      ],
      "metadata": {
        "id": "dEnBDs3P9jWJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 5.1.1 Architecture"
      ],
      "metadata": {
        "id": "02401unQ-IgH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```javascript    \n",
        "\n",
        "                    ┌----------------------┐\n",
        "                    │         USER         │\n",
        "                    └----------┬----------┘\n",
        "                                │\n",
        "                                ▼\n",
        "                   ┌-----------------------┐\n",
        "                   │      SUPERVISOR       │   (LLM Router / Orchestrator)\n",
        "                   │-----------------------│\n",
        "                   │ reads Shared State    │\n",
        "                   │ decides next action   │\n",
        "                   │ stop / retry control  │\n",
        "                   └----┬-----┬-----┬---┘\n",
        "                         │     │     │\n",
        "            ┌-----------┘     │     └-----------------┐\n",
        "            │                  │                        │\n",
        "            ▼                  ▼                        ▼\n",
        "┌--------------------┐  ┌-------------------┐  ┌-------------------┐\n",
        "│      PLANNER       │  │    RESEARCHER     │  │      CRITIC       │\n",
        "│--------------------│  │-------------------│  │-------------------│\n",
        "│ make plan +        │  │ gather evidence   │  │ evaluate draft    │\n",
        "│ acceptance criteria│  │ using tools       │  │ vs criteria       │\n",
        "│ OUTPUT: plan       │  │ OUTPUT: notes     │  │ OUTPUT: feedback  │\n",
        "└---------┬---------┘  └--------┬---------┘  └---------┬--------┘\n",
        "           │                       │                        │\n",
        "           │                       │                        │\n",
        "           ▼                       ▼                        ▼\n",
        "┌----------------------------------------------------------------┐\n",
        "│                           SHARED STATE                         │\n",
        "│----------------------------------------------------------------│\n",
        "│ goal / plan / criteria / notes / draft / feedback / approved   │\n",
        "│ iter / max_iters / traces(tool results)                        │\n",
        "└---------------------------┬-----------------------------------┘\n",
        "                             │\n",
        "                             │ (uses state inputs)\n",
        "                             ▼\n",
        "                   ┌-------------------┐\n",
        "                   │      BUILDER      │\n",
        "                   │-------------------│\n",
        "                   │ produce artifact  │\n",
        "                   │ apply feedback    │\n",
        "                   │ tools (optional): │\n",
        "                   │   - calculator    │\n",
        "                   │ OUTPUT: draft     │\n",
        "                   └---------┬--------┘\n",
        "                              │\n",
        "                              ▼\n",
        "                           (back to SUPERVISOR)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "mG_BhXiYHv_L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ㄴ 5.1.1.1 Component"
      ],
      "metadata": {
        "id": "LevAC_J9-cmF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### ㄴ **1) Supervisor (Orchestrator / Router)**\n",
        "> 현재 Shared State를 읽고 \"다음에 누구(어떤 역할 에이전트)를 호출할지\" 를 결정"
      ],
      "metadata": {
        "id": "uVxtzNAx-bSI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **결정 포인트**\n",
        "  - 지금 정보가 부족한가? → Researcher\n",
        "  - 계획이 필요한가? → Planner\n",
        "  - 산출물을 만들어야 하나? → Builder\n",
        "  - 검수/품질 체크가 필요한가? → Critic/Validator\n",
        "  - 종료 조건(approved, max_iter 등)을 만족했는가? → DONE\n",
        "- **핵심**: 단일 에이전트처럼 한 번에 끝내지 않고, **흐름 제어(제어 plane)** 를 담당"
      ],
      "metadata": {
        "id": "7-b5wU3_DyYd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### ㄴ **2) Specialized Agents (Role-Specialized Workers)**\n",
        "> 각자 좁은 책임 범위 + 필요 시, 도구 사용"
      ],
      "metadata": {
        "id": "6PeHqJgXD2u3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Planner**\n",
        "> 목표를 단계로 분해해서 plan 생성\n",
        "  - Input: goal, constraints\n",
        "  - Output: plan(단계/체크리스트/해야 할 일)\n",
        "- **Researcher**\n",
        "> wiki/search/docstore_lookup로 근거/정보 수집 → notes 생성\n",
        "  - Input: goal, plan\n",
        "  - Output: notes(필요한정보/가정/근거)\n",
        "- **Builder**\n",
        "> goal + plan + notes + feedback로 draft 생성 (필요 시 calculator로 수치 계산)\n",
        "  - Input goal, plan, notes, feedback\n",
        "  - Output: draft(초안 산출물)\n",
        "- **Critic/Validator**\n",
        "> draft를 평가해서 approved + feedback 생성 (지금은 안전/정확성/완성도 중심)\n",
        "  - Input: draft + acceptance criteria\n",
        "  - Output: review(approved 여부 + 수정 지시)"
      ],
      "metadata": {
        "id": "jB-tj6Y6D672"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### ㄴ **3) Shared State**\n",
        "> **공유 작업공간**에 결과를 기록하고 읽음"
      ],
      "metadata": {
        "id": "xR4HMPbUD9kc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Field**\n",
        "  - goal: 사용자 목표\n",
        "  - plan: 계획(steps)\n",
        "  - notes: 조사 결과(근거/요약)\n",
        "  - draft: 산출물 초안\n",
        "  - approved: 통과 여부\n",
        "  - feedback: 수정 지시\n",
        "  - iter: 반복 횟수"
      ],
      "metadata": {
        "id": "L4Yu7Kt3E3Hq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### ㄴ **4) Tools**\n",
        "> 검색, 코드 실행, DB 조회, 파일 읽기 등"
      ],
      "metadata": {
        "id": "QyrYX_loFS7r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Wikipedia Query / docstore_lookup\n",
        "- Tavily Search\n",
        "- calculator"
      ],
      "metadata": {
        "id": "IyTKxI0yF_2X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ㄴ 5.1.1.2 Workflow\n"
      ],
      "metadata": {
        "id": "W_stsA8n-MrT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.  User Goal 입력\n",
        "2.  Supervisor → **Planner** (plan 생성)\n",
        "3.  Supervisor → **Researcher** (tools 사용해서 notes 생성)\n",
        "4.  Supervisor → **Builder** (draft 생성)\n",
        "5.  Supervisor → **Critic** (approved/feedback)\n",
        "6.  approved=false면 **Builder ↔ Critic** 1~2회 반복\n",
        "7.  DONE (draft 반환)"
      ],
      "metadata": {
        "id": "dpOMl2-9AF1o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ㄴ 5.2 Code"
      ],
      "metadata": {
        "id": "xcqP3B4WLcZy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ㄴ 5.2.1 dd"
      ],
      "metadata": {
        "id": "3EVAS2-kL893"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ㄴ 6. Deterministic Guardrail Pattern\n",
        "\n",
        "**Post-ReAct에서는 반드시 아래 항목이 존재**\n",
        "*   Validation Step\n",
        "*   Structured Output\n",
        "*   JSON Contracts\n",
        "*   Retry Policy\n",
        "\n"
      ],
      "metadata": {
        "id": "uIT-Z7HPppHM"
      }
    }
  ]
}